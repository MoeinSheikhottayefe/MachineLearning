{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIzwt7fKEpzVQZF3a9lp+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoeinSheikhottayefe/MachineLearning/blob/main/policy_gnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yl4o1WVFvo4",
        "outputId": "06769e6e-afe0-43ec-8e11-fad9b9d2f3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Policy-GNN'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 166 (delta 65), reused 121 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (166/166), 15.75 MiB | 14.00 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Eversee22/Policy-GNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l9pScmf23kxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w0M8BnU43lCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wBCR1MA410Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmRYZyC43kST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/Policy-GNN\")\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oua5CipNHb6",
        "outputId": "97292822-d2da-4b33-9e03-63f03da2ee1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Policy-GNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nykvIzCYOObJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKQi0c5MOOYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z06AYe7VN9Zv",
        "outputId": "843dcf78-8381-48b8-889c-cdeef67043db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/661.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m655.4/661.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910460 sha256=09a03826c9cf8554a0cba5fb3ee8d9a4d30772541fe20d8715e1462edaf67035\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/pyg_lib-0.2.0%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (627 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m627.0/627.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (504 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.1/504.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.17%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.3/732.3 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.7/205.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.22.4)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.2.0+pt20cpu torch_cluster-1.6.1+pt20cpu torch_scatter-2.1.1+pt20cpu torch_sparse-0.6.17+pt20cpu torch_spline_conv-1.2.2+pt20cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_citeseer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg2voXwtOWtN",
        "outputId": "c94b2606-253b-4956-cb29-f00e1d1246df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "/content/Policy-GNN/env/gcn.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.adj = (adj/norm).T\n",
            "Training Meta-policy on Validation Set\n",
            "Training Meta-policy: 1 Val_Acc: 0.46205755673634924 Avg_reward: -1.4291050796468723\n",
            "Training Meta-policy: 2 Val_Acc: 0.5505718005072809 Avg_reward: -2.5419981133308664\n",
            "Training Meta-policy: 3 Val_Acc: 0.632052065133815 Avg_reward: -0.5536592850900763\n",
            "Training Meta-policy: 4 Val_Acc: 0.6515710468850177 Avg_reward: -0.8949870715154153\n",
            "Training Meta-policy: 5 Val_Acc: 0.6500661712096822 Avg_reward: -0.3807918294787268\n",
            "Training Meta-policy: 6 Val_Acc: 0.6214292858322563 Avg_reward: -0.25464627946550755\n",
            "Training Meta-policy: 7 Val_Acc: 0.6422912898913088 Avg_reward: -0.2247680576481079\n",
            "Training Meta-policy: 8 Val_Acc: 0.6616694467406952 Avg_reward: -0.06562369385394594\n",
            "Training Meta-policy: 9 Val_Acc: 0.6156030919217538 Avg_reward: 0.5345234671451059\n",
            "Training Meta-policy: 10 Val_Acc: 0.6277899999757981 Avg_reward: -0.2651519277848944\n",
            "Training Meta-policy: 11 Val_Acc: 0.6263357749516919 Avg_reward: 0.5266998956445337\n",
            "Training Meta-policy: 12 Val_Acc: 0.6147904546433959 Avg_reward: -1.0304264070725904\n",
            "Training Meta-policy: 13 Val_Acc: 0.623411655745865 Avg_reward: 1.3917443906791005\n",
            "Training Meta-policy: 14 Val_Acc: 0.5941696092769685 Avg_reward: -1.0834839487439327\n",
            "Training Meta-policy: 15 Val_Acc: 0.6300940596750456 Avg_reward: 1.291920554366952\n",
            "Training Meta-policy: 16 Val_Acc: 0.6043656885262325 Avg_reward: -2.7314550648885203\n",
            "Training Meta-policy: 17 Val_Acc: 0.6652398324473642 Avg_reward: 1.7327836853042835\n",
            "Training Meta-policy: 18 Val_Acc: 0.6465018859327591 Avg_reward: 0.3870093912468496\n",
            "Training Meta-policy: 19 Val_Acc: 0.6372077416977137 Avg_reward: 1.1434482631300342\n",
            "Training Meta-policy: 20 Val_Acc: 0.6096941480441896 Avg_reward: -2.5025918072251345\n",
            "Training Meta-policy: 21 Val_Acc: 0.6348475755567399 Avg_reward: -1.057025475821792\n",
            "Training Meta-policy: 22 Val_Acc: 0.6411338826310666 Avg_reward: -0.19521102767347054\n",
            "Training Meta-policy: 23 Val_Acc: 0.6365039659088555 Avg_reward: 1.792758047626307\n",
            "Training Meta-policy: 24 Val_Acc: 0.6320191567532363 Avg_reward: -2.569890317041088\n",
            "Training Meta-policy: 25 Val_Acc: 0.6485927410859145 Avg_reward: 1.0037137759264945\n",
            "Training Meta-policy: 26 Val_Acc: 0.6243261534868384 Avg_reward: -0.4223677760276295\n",
            "Training Meta-policy: 27 Val_Acc: 0.615348300320433 Avg_reward: -2.8045086032119815\n",
            "Training Meta-policy: 28 Val_Acc: 0.6429061829269088 Avg_reward: -0.20453614581015825\n",
            "Training Meta-policy: 29 Val_Acc: 0.636177137288975 Avg_reward: -0.5278907655260897\n",
            "Training Meta-policy: 30 Val_Acc: 0.6585174751556696 Avg_reward: -0.12980489484719784\n",
            "Training Meta-policy: 31 Val_Acc: 0.6673793679868482 Avg_reward: -0.0026671747885142795\n",
            "Training Meta-policy: 32 Val_Acc: 0.6806191798406457 Avg_reward: 0.8516800418410615\n",
            "Training Meta-policy: 33 Val_Acc: 0.6723557096426046 Avg_reward: 0.6038522159487718\n",
            "Training Meta-policy: 34 Val_Acc: 0.6847739491675472 Avg_reward: 0.946482534545584\n",
            "Training Meta-policy: 35 Val_Acc: 0.672900555416005 Avg_reward: 1.4117506224173098\n",
            "Training Meta-policy: 36 Val_Acc: 0.6435670660099869 Avg_reward: -3.604904549645232\n",
            "Training Meta-policy: 37 Val_Acc: 0.6729285394838953 Avg_reward: 2.11639801647507\n",
            "Training Meta-policy: 38 Val_Acc: 0.6410077770113198 Avg_reward: -4.137080322259384\n",
            "Training Meta-policy: 39 Val_Acc: 0.696046916860694 Avg_reward: -0.5519076393469257\n",
            "Training Meta-policy: 40 Val_Acc: 0.6647278394065391 Avg_reward: -0.1835355912390094\n",
            "Training Meta-policy: 41 Val_Acc: 0.6603376039170692 Avg_reward: -4.038418235080969\n",
            "Training Meta-policy: 42 Val_Acc: 0.6606630496593171 Avg_reward: -0.05032388710567103\n",
            "Training Meta-policy: 43 Val_Acc: 0.684059948765831 Avg_reward: 2.1299265005147365\n",
            "Training Meta-policy: 44 Val_Acc: 0.7037837301138454 Avg_reward: 0.9505813689242312\n",
            "Training Meta-policy: 45 Val_Acc: 0.6807776267868421 Avg_reward: 0.02081969463704419\n",
            "Training Meta-policy: 46 Val_Acc: 0.6884912115236785 Avg_reward: -0.3975497049725728\n",
            "Training Meta-policy: 47 Val_Acc: 0.6739563818671325 Avg_reward: -0.4631062718497325\n",
            "Training Meta-policy: 48 Val_Acc: 0.67857489138713 Avg_reward: -0.4936958832153735\n",
            "Training Meta-policy: 49 Val_Acc: 0.6509727190169076 Avg_reward: 0.28002056439228723\n",
            "Training Meta-policy: 50 Val_Acc: 0.6817047051948009 Avg_reward: -0.2953271327024\n",
            "Training Meta-policy: 51 Val_Acc: 0.6423613837814078 Avg_reward: -0.25787864136936905\n",
            "Training Meta-policy: 52 Val_Acc: 0.6431321796822363 Avg_reward: 0.2342442651911511\n",
            "Training Meta-policy: 53 Val_Acc: 0.6453294476449327 Avg_reward: -0.4996868064045533\n",
            "Training Meta-policy: 54 Val_Acc: 0.6491688615744806 Avg_reward: 0.10740313776387479\n",
            "Training Meta-policy: 55 Val_Acc: 0.649548017820272 Avg_reward: -0.33855724638241946\n",
            "Training Meta-policy: 56 Val_Acc: 0.6518932082265606 Avg_reward: -0.716739185595623\n",
            "Training Meta-policy: 57 Val_Acc: 0.6761156700391089 Avg_reward: 0.16515677437521484\n",
            "Training Meta-policy: 58 Val_Acc: 0.656088676605394 Avg_reward: 0.21285163613013158\n",
            "Training Meta-policy: 59 Val_Acc: 0.655690200862067 Avg_reward: -1.4854601068239932\n",
            "Training Meta-policy: 60 Val_Acc: 0.6846891342466956 Avg_reward: -0.05977578953200863\n",
            "Training Meta-policy: 61 Val_Acc: 0.6500169987884894 Avg_reward: -1.3751485433522252\n",
            "Training Meta-policy: 62 Val_Acc: 0.637077579782357 Avg_reward: -2.992016887054175\n",
            "Training Meta-policy: 63 Val_Acc: 0.7261229831299036 Avg_reward: -1.3534418292203692\n",
            "Training Meta-policy: 64 Val_Acc: 0.6739939666813818 Avg_reward: -7.829814980938568\n",
            "Training Meta-policy: 65 Val_Acc: 0.7232396444672659 Avg_reward: 5.173161469836659\n",
            "Training Meta-policy: 66 Val_Acc: 0.7180325450505946 Avg_reward: -0.6463819688546745\n",
            "Training Meta-policy: 67 Val_Acc: 0.7398835922817238 Avg_reward: 2.5719494716324958\n",
            "Training Meta-policy: 68 Val_Acc: 0.707202891257513 Avg_reward: 4.492228760190943\n",
            "Training Meta-policy: 69 Val_Acc: 0.6923139728454835 Avg_reward: -7.369590255544866\n",
            "Training Meta-policy: 70 Val_Acc: 0.6934722022901508 Avg_reward: 4.748443083748369\n",
            "Training Meta-policy: 71 Val_Acc: 0.7258922739261472 Avg_reward: 1.1326671577961627\n",
            "Training Meta-policy: 72 Val_Acc: 0.653458956597859 Avg_reward: 1.139259159031777\n",
            "Training Meta-policy: 73 Val_Acc: 0.6548008378609178 Avg_reward: -0.6398554267067639\n",
            "Training Meta-policy: 74 Val_Acc: 0.7132742401773546 Avg_reward: 0.785094874269249\n",
            "Training Meta-policy: 75 Val_Acc: 0.6946769224602757 Avg_reward: 1.3653172407356833\n",
            "Training Meta-policy: 76 Val_Acc: 0.656393705628372 Avg_reward: 1.6782895358742773\n",
            "Training Meta-policy: 77 Val_Acc: 0.6618314408653267 Avg_reward: 0.683155103737744\n",
            "Training Meta-policy: 78 Val_Acc: 0.6478572211667777 Avg_reward: -0.8396912296658087\n",
            "Training Meta-policy: 79 Val_Acc: 0.6591891106107812 Avg_reward: 0.19945220668774286\n",
            "Training Meta-policy: 80 Val_Acc: 0.6390115001135045 Avg_reward: 1.3254103030351525\n",
            "Training Meta-policy: 81 Val_Acc: 0.6245110039658139 Avg_reward: 0.5192563511382591\n",
            "Training Meta-policy: 82 Val_Acc: 0.6565663286868073 Avg_reward: 0.380505212118298\n",
            "Training Meta-policy: 83 Val_Acc: 0.6420107242706561 Avg_reward: -0.46073480594905736\n",
            "Training Meta-policy: 84 Val_Acc: 0.6704125588461843 Avg_reward: -0.26178334341442533\n",
            "Training Meta-policy: 85 Val_Acc: 0.6595679401335793 Avg_reward: 0.9440684485542004\n",
            "Training Meta-policy: 86 Val_Acc: 0.670609958269022 Avg_reward: -2.4204763517128445\n",
            "Training Meta-policy: 87 Val_Acc: 0.6444225043979233 Avg_reward: 1.254848442066075\n",
            "Training Meta-policy: 88 Val_Acc: 0.6339209210651434 Avg_reward: -0.8717331772006024\n",
            "Training Meta-policy: 89 Val_Acc: 0.6417046502453837 Avg_reward: 0.5360947933219659\n",
            "Training Meta-policy: 90 Val_Acc: 0.6611233133255332 Avg_reward: 0.1674780933134077\n",
            "Training Meta-policy: 91 Val_Acc: 0.6443018401303751 Avg_reward: -2.0458875323164243\n",
            "Training Meta-policy: 92 Val_Acc: 0.630761760927409 Avg_reward: -4.500875338583329\n",
            "Training Meta-policy: 93 Val_Acc: 0.6380873878344501 Avg_reward: 0.22964896705522705\n",
            "Training Meta-policy: 94 Val_Acc: 0.6443399837585099 Avg_reward: 0.7321767720330128\n",
            "Training Meta-policy: 95 Val_Acc: 0.6408897799125477 Avg_reward: -0.6585690107833506\n",
            "Training Meta-policy: 96 Val_Acc: 0.6049218323305454 Avg_reward: -0.6073329370498893\n",
            "Training Meta-policy: 97 Val_Acc: 0.6124505402324826 Avg_reward: -8.388060701689026\n",
            "Training Meta-policy: 98 Val_Acc: 0.6127321999368086 Avg_reward: 5.100374711048763\n",
            "Training Meta-policy: 99 Val_Acc: 0.615092644953595 Avg_reward: -4.2498102015891295\n",
            "Training Meta-policy: 100 Val_Acc: 0.5974672386437091 Avg_reward: -1.407763315116247\n",
            "Training Meta-policy: 101 Val_Acc: 0.5776568409915187 Avg_reward: -2.5956462303005456\n",
            "Training Meta-policy: 102 Val_Acc: 0.5994288426425299 Avg_reward: -7.4739697019263085\n",
            "Training Meta-policy: 103 Val_Acc: 0.5997605374223806 Avg_reward: 0.6226791202179748\n",
            "Training Meta-policy: 104 Val_Acc: 0.5739594534982034 Avg_reward: 0.9199274192767424\n",
            "Training Meta-policy: 105 Val_Acc: 0.5477961204869416 Avg_reward: 0.17898537174572632\n",
            "Training Meta-policy: 106 Val_Acc: 0.5890269004525379 Avg_reward: 0.7690856938960643\n",
            "Training Meta-policy: 107 Val_Acc: 0.6656182849315276 Avg_reward: 2.953678022933321\n",
            "Training Meta-policy: 108 Val_Acc: 0.6352701387853477 Avg_reward: 1.8172522786323226\n",
            "Training Meta-policy: 109 Val_Acc: 0.6876840225679138 Avg_reward: -0.7455341181661342\n",
            "Training Meta-policy: 110 Val_Acc: 0.6912193706311355 Avg_reward: 0.7285436697201332\n",
            "Training Meta-policy: 111 Val_Acc: 0.6528372564396623 Avg_reward: 0.5614395892405246\n",
            "Training Meta-policy: 112 Val_Acc: 0.6002611657929754 Avg_reward: -0.28955300768618153\n",
            "Training Meta-policy: 113 Val_Acc: 0.6109620404246142 Avg_reward: -5.405029820510744\n",
            "Training Meta-policy: 114 Val_Acc: 0.6956009070294785 Avg_reward: -4.789115646258509\n",
            "Training Meta-policy: 115 Val_Acc: 0.7465403795040506 Avg_reward: 4.869728122812601\n",
            "Training Meta-policy: 116 Val_Acc: 0.7072322262238228 Avg_reward: -6.961856742697062\n",
            "Training Meta-policy: 117 Val_Acc: 0.7169590643274856 Avg_reward: 3.893065998329161\n",
            "Training Meta-policy: 118 Val_Acc: 0.6652810856963111 Avg_reward: -0.8985530040893313\n",
            "Training Meta-policy: 119 Val_Acc: 0.5549702233834711 Avg_reward: -2.547328735415741\n",
            "Training Meta-policy: 120 Val_Acc: 0.699264838143233 Avg_reward: 5.130810704800709\n",
            "Training Meta-policy: 121 Val_Acc: 0.7046696393613474 Avg_reward: 4.829192336917347\n",
            "Training Meta-policy: 122 Val_Acc: 0.7279624582707588 Avg_reward: -1.8857824867744248\n",
            "Training Meta-policy: 123 Val_Acc: 0.6544939919479544 Avg_reward: -2.0630111021299586\n",
            "Training Meta-policy: 124 Val_Acc: 0.6548208257160033 Avg_reward: -0.3824506864731268\n",
            "Training Meta-policy: 125 Val_Acc: 0.6696887390648768 Avg_reward: 0.08275772250722521\n",
            "Training Meta-policy: 126 Val_Acc: 0.6592927606738168 Avg_reward: 1.845379359371053\n",
            "Training Meta-policy: 127 Val_Acc: 0.6464428762159069 Avg_reward: -0.5752889077989211\n",
            "Training Meta-policy: 128 Val_Acc: 0.6759698341760293 Avg_reward: -1.9172793782132758\n",
            "Training Meta-policy: 129 Val_Acc: 0.6261572930584066 Avg_reward: 0.7768217288886299\n",
            "Training Meta-policy: 130 Val_Acc: 0.6892274754121798 Avg_reward: -0.3570182176850962\n",
            "Training Meta-policy: 131 Val_Acc: 0.6402625219714473 Avg_reward: -4.30969547533972\n",
            "Training Meta-policy: 132 Val_Acc: 0.6836790218479738 Avg_reward: 4.6557581884428405\n",
            "Training Meta-policy: 133 Val_Acc: 0.6645610094554527 Avg_reward: -1.1396578578559524\n",
            "Training Meta-policy: 134 Val_Acc: 0.624731779402428 Avg_reward: 0.7677747280502163\n",
            "Training Meta-policy: 135 Val_Acc: 0.6372578243755255 Avg_reward: -0.2870163807087183\n",
            "Training GNNs with learned meta-policy\n",
            "Training GNN 1 ; Val_Acc: 0.23625184049729275 ; Test_Acc: 0.29725583817583\n",
            "Training GNN 2 ; Val_Acc: 0.24490000722686817 ; Test_Acc: 0.29725583817583\n",
            "Training GNN 3 ; Val_Acc: 0.20623666436239252 ; Test_Acc: 0.2706948347222654\n",
            "Training GNN 4 ; Val_Acc: 0.2160606387910227 ; Test_Acc: 0.2706948347222654\n",
            "Training GNN 5 ; Val_Acc: 0.3189832794363341 ; Test_Acc: 0.3333604989343031\n",
            "Training GNN 6 ; Val_Acc: 0.3225212879753062 ; Test_Acc: 0.3379142952374182\n",
            "Training GNN 7 ; Val_Acc: 0.3091332188307125 ; Test_Acc: 0.33531107971463925\n",
            "Training GNN 8 ; Val_Acc: 0.30999888862857294 ; Test_Acc: 0.33531107971463925\n",
            "Training GNN 9 ; Val_Acc: 0.3230636116195332 ; Test_Acc: 0.3464296993785457\n",
            "Training GNN 10 ; Val_Acc: 0.34070532035605583 ; Test_Acc: 0.34747499960624334\n",
            "Training GNN 11 ; Val_Acc: 0.34286491042555955 ; Test_Acc: 0.34747499960624334\n",
            "Training GNN 12 ; Val_Acc: 0.3591883146045108 ; Test_Acc: 0.3508020683076172\n",
            "Training GNN 13 ; Val_Acc: 0.3725035059244073 ; Test_Acc: 0.3640706643674119\n",
            "Training GNN 14 ; Val_Acc: 0.38067881314609325 ; Test_Acc: 0.38712917080820564\n",
            "Training GNN 15 ; Val_Acc: 0.37871697240752067 ; Test_Acc: 0.4054007273216421\n",
            "Training GNN 16 ; Val_Acc: 0.39814683785686705 ; Test_Acc: 0.4054007273216421\n",
            "Training GNN 17 ; Val_Acc: 0.40610698418988783 ; Test_Acc: 0.4082533180484827\n",
            "Training GNN 18 ; Val_Acc: 0.4259170509138877 ; Test_Acc: 0.4082533180484827\n",
            "Training GNN 19 ; Val_Acc: 0.4282220434305021 ; Test_Acc: 0.4358039768139089\n",
            "Training GNN 20 ; Val_Acc: 0.42748553057585903 ; Test_Acc: 0.43301645664186506\n",
            "Training GNN 21 ; Val_Acc: 0.4325144462975868 ; Test_Acc: 0.4376475480883224\n",
            "Training GNN 22 ; Val_Acc: 0.47284554081955366 ; Test_Acc: 0.4376475480883224\n",
            "Training GNN 23 ; Val_Acc: 0.49593113617426027 ; Test_Acc: 0.4585472017953599\n",
            "Training GNN 24 ; Val_Acc: 0.4939383968100455 ; Test_Acc: 0.46774651440276493\n",
            "Training GNN 25 ; Val_Acc: 0.4719100381933244 ; Test_Acc: 0.46986543332168385\n",
            "Training GNN 26 ; Val_Acc: 0.4943952053364618 ; Test_Acc: 0.47026161358473023\n",
            "Training GNN 27 ; Val_Acc: 0.49345321935001535 ; Test_Acc: 0.47277984511105425\n",
            "Training GNN 28 ; Val_Acc: 0.4816591906537367 ; Test_Acc: 0.4778480532035399\n",
            "Training GNN 29 ; Val_Acc: 0.48480764679304816 ; Test_Acc: 0.48660343517510685\n",
            "Training GNN 30 ; Val_Acc: 0.4900052831568851 ; Test_Acc: 0.48660343517510685\n",
            "Training GNN 31 ; Val_Acc: 0.49825137816793186 ; Test_Acc: 0.4857728878364118\n",
            "Training GNN 32 ; Val_Acc: 0.4932417403384911 ; Test_Acc: 0.4857728878364118\n",
            "Training GNN 33 ; Val_Acc: 0.49735945486777616 ; Test_Acc: 0.4833456499261228\n",
            "Training GNN 34 ; Val_Acc: 0.4885975094530872 ; Test_Acc: 0.48115654408562697\n",
            "Training GNN 35 ; Val_Acc: 0.48373525747898904 ; Test_Acc: 0.48115654408562697\n",
            "Training GNN 36 ; Val_Acc: 0.5007666211428969 ; Test_Acc: 0.48115654408562697\n",
            "Training GNN 37 ; Val_Acc: 0.5038860619217745 ; Test_Acc: 0.5280962696990039\n",
            "Training GNN 38 ; Val_Acc: 0.5220136293070244 ; Test_Acc: 0.5375162171101501\n",
            "Training GNN 39 ; Val_Acc: 0.5071350247336339 ; Test_Acc: 0.54791621711015\n",
            "Training GNN 40 ; Val_Acc: 0.5167286500350814 ; Test_Acc: 0.5672432858115238\n",
            "Training GNN 41 ; Val_Acc: 0.5030503554209196 ; Test_Acc: 0.5672432858115238\n",
            "Training GNN 42 ; Val_Acc: 0.5128924870765608 ; Test_Acc: 0.565006135366281\n",
            "Training GNN 43 ; Val_Acc: 0.5201539575071248 ; Test_Acc: 0.56007816319572\n",
            "Training GNN 44 ; Val_Acc: 0.5154920994683045 ; Test_Acc: 0.56007816319572\n",
            "Training GNN 45 ; Val_Acc: 0.5243985928723627 ; Test_Acc: 0.5595332040676546\n",
            "Training GNN 46 ; Val_Acc: 0.5387787659844925 ; Test_Acc: 0.5559590282002088\n",
            "Training GNN 47 ; Val_Acc: 0.5372555408828814 ; Test_Acc: 0.5559590282002088\n",
            "Training GNN 48 ; Val_Acc: 0.5608863928476383 ; Test_Acc: 0.5559590282002088\n",
            "Training GNN 49 ; Val_Acc: 0.5379128267370576 ; Test_Acc: 0.5512383465287909\n",
            "Training GNN 50 ; Val_Acc: 0.5283372725684388 ; Test_Acc: 0.5512383465287909\n",
            "Training GNN 51 ; Val_Acc: 0.5303959979000512 ; Test_Acc: 0.5511721954207598\n",
            "Training GNN 52 ; Val_Acc: 0.5274780468660849 ; Test_Acc: 0.5521959625688595\n",
            "Training GNN 53 ; Val_Acc: 0.5247540820547874 ; Test_Acc: 0.5508510034407941\n",
            "Training GNN 54 ; Val_Acc: 0.535791015623241 ; Test_Acc: 0.5508510034407941\n",
            "Training GNN 55 ; Val_Acc: 0.5560755614343913 ; Test_Acc: 0.5530969910610868\n",
            "Training GNN 56 ; Val_Acc: 0.5209417554773784 ; Test_Acc: 0.5530969910610868\n",
            "Training GNN 57 ; Val_Acc: 0.5245001083597948 ; Test_Acc: 0.5762700473827531\n",
            "Training GNN 58 ; Val_Acc: 0.5591036099967838 ; Test_Acc: 0.5762700473827531\n",
            "Training GNN 59 ; Val_Acc: 0.5598823199876376 ; Test_Acc: 0.5724417341125598\n",
            "Training GNN 60 ; Val_Acc: 0.5464702426337943 ; Test_Acc: 0.5596374040670586\n",
            "Training GNN 61 ; Val_Acc: 0.5512571094252228 ; Test_Acc: 0.5601735260200743\n",
            "Training GNN 62 ; Val_Acc: 0.5637924713497833 ; Test_Acc: 0.5601735260200743\n",
            "Training GNN 63 ; Val_Acc: 0.5504286823856007 ; Test_Acc: 0.5687273223231895\n",
            "Training GNN 64 ; Val_Acc: 0.5609837952665648 ; Test_Acc: 0.5687273223231895\n",
            "Training GNN 65 ; Val_Acc: 0.5723288982773893 ; Test_Acc: 0.5798208832322266\n",
            "Training GNN 66 ; Val_Acc: 0.5671672862049648 ; Test_Acc: 0.5734297204072762\n",
            "Training GNN 67 ; Val_Acc: 0.5597681009253785 ; Test_Acc: 0.5734297204072762\n",
            "Training GNN 68 ; Val_Acc: 0.5553415802530234 ; Test_Acc: 0.5734297204072762\n",
            "Training GNN 69 ; Val_Acc: 0.5610779279077001 ; Test_Acc: 0.5753100751032174\n",
            "Training GNN 70 ; Val_Acc: 0.5598646843688936 ; Test_Acc: 0.5762500167931865\n",
            "Training GNN 71 ; Val_Acc: 0.5556192743361291 ; Test_Acc: 0.5747639182740094\n",
            "Training GNN 72 ; Val_Acc: 0.5646927367799481 ; Test_Acc: 0.5723550810989597\n",
            "Training GNN 73 ; Val_Acc: 0.5653178855490741 ; Test_Acc: 0.5723550810989597\n",
            "Training GNN 74 ; Val_Acc: 0.5503107700990596 ; Test_Acc: 0.5712210161303986\n",
            "Training GNN 75 ; Val_Acc: 0.5628371213128482 ; Test_Acc: 0.5774851102539752\n",
            "Training GNN 76 ; Val_Acc: 0.5566367018807241 ; Test_Acc: 0.5774851102539752\n",
            "Training GNN 77 ; Val_Acc: 0.5626023741778374 ; Test_Acc: 0.5852389065570903\n",
            "Training GNN 78 ; Val_Acc: 0.5616071153448284 ; Test_Acc: 0.5895994830508006\n",
            "Training GNN 79 ; Val_Acc: 0.57367107667965 ; Test_Acc: 0.5830194304619467\n",
            "Training GNN 80 ; Val_Acc: 0.5806171333287139 ; Test_Acc: 0.5818982384819811\n",
            "Training GNN 81 ; Val_Acc: 0.5780382968320056 ; Test_Acc: 0.5818982384819811\n",
            "Training GNN 82 ; Val_Acc: 0.5748569628014272 ; Test_Acc: 0.5841442261022737\n",
            "Training GNN 83 ; Val_Acc: 0.5690342178337422 ; Test_Acc: 0.5811723232958746\n",
            "Training GNN 84 ; Val_Acc: 0.5787549336379201 ; Test_Acc: 0.5803462830867281\n",
            "Training GNN 85 ; Val_Acc: 0.568747107424596 ; Test_Acc: 0.5803462830867281\n",
            "Training GNN 86 ; Val_Acc: 0.5769571075397965 ; Test_Acc: 0.582021271369809\n",
            "Training GNN 87 ; Val_Acc: 0.576216755388943 ; Test_Acc: 0.582021271369809\n",
            "Training GNN 88 ; Val_Acc: 0.5691531580271826 ; Test_Acc: 0.5820702194437433\n",
            "Training GNN 89 ; Val_Acc: 0.5865690094834073 ; Test_Acc: 0.5829712479359705\n",
            "Training GNN 90 ; Val_Acc: 0.5725145362461947 ; Test_Acc: 0.5829712479359705\n",
            "Training GNN 91 ; Val_Acc: 0.5812969908080446 ; Test_Acc: 0.5917787103258305\n",
            "Training GNN 92 ; Val_Acc: 0.5881424289341693 ; Test_Acc: 0.5952024774739301\n",
            "Training GNN 93 ; Val_Acc: 0.5764299917664422 ; Test_Acc: 0.5952024774739301\n",
            "Training GNN 94 ; Val_Acc: 0.5865365784533666 ; Test_Acc: 0.5971012329051106\n",
            "Training GNN 95 ; Val_Acc: 0.6012558704254748 ; Test_Acc: 0.6015843709706462\n",
            "Training GNN 96 ; Val_Acc: 0.6020087955689755 ; Test_Acc: 0.6051753177190042\n",
            "Training GNN 97 ; Val_Acc: 0.6126051248689488 ; Test_Acc: 0.5990781089637305\n",
            "Training GNN 98 ; Val_Acc: 0.6112838961711078 ; Test_Acc: 0.5990781089637305\n",
            "Training GNN 99 ; Val_Acc: 0.6188533607937513 ; Test_Acc: 0.5998781089637306\n",
            "Training GNN 100 ; Val_Acc: 0.6210074547043197 ; Test_Acc: 0.6023129863479266\n",
            "Training GNN 101 ; Val_Acc: 0.6147791499429316 ; Test_Acc: 0.6018778928871383\n",
            "Training GNN 102 ; Val_Acc: 0.6313570393387948 ; Test_Acc: 0.6035127702713345\n",
            "Training GNN 103 ; Val_Acc: 0.6241485188115534 ; Test_Acc: 0.6040837696085464\n",
            "Training GNN 104 ; Val_Acc: 0.62895267648477 ; Test_Acc: 0.6040837696085464\n",
            "Training GNN 105 ; Val_Acc: 0.6290055067928274 ; Test_Acc: 0.6135698681277236\n",
            "Training GNN 106 ; Val_Acc: 0.6250285025777211 ; Test_Acc: 0.6213461009796238\n",
            "Training GNN 107 ; Val_Acc: 0.6213865221654229 ; Test_Acc: 0.6308582397079475\n",
            "Training GNN 108 ; Val_Acc: 0.6126886481131999 ; Test_Acc: 0.6308582397079475\n",
            "Training GNN 109 ; Val_Acc: 0.6044439212431746 ; Test_Acc: 0.6217683214518168\n",
            "Training GNN 110 ; Val_Acc: 0.6154371519277955 ; Test_Acc: 0.6217683214518168\n",
            "Training GNN 111 ; Val_Acc: 0.5995063262329311 ; Test_Acc: 0.6200324155753933\n",
            "Training GNN 112 ; Val_Acc: 0.6000782156639958 ; Test_Acc: 0.6381902476920543\n",
            "Training GNN 113 ; Val_Acc: 0.6060739251045889 ; Test_Acc: 0.6381902476920543\n",
            "Training GNN 114 ; Val_Acc: 0.6098905688189308 ; Test_Acc: 0.6381902476920543\n",
            "Training GNN 115 ; Val_Acc: 0.624278323442385 ; Test_Acc: 0.6323784500633629\n",
            "Training GNN 116 ; Val_Acc: 0.6191061016128498 ; Test_Acc: 0.616084201761731\n",
            "Training GNN 117 ; Val_Acc: 0.6181823434578487 ; Test_Acc: 0.616084201761731\n",
            "Training GNN 118 ; Val_Acc: 0.6156488778747253 ; Test_Acc: 0.6047659702354069\n",
            "Training GNN 119 ; Val_Acc: 0.5964767893939117 ; Test_Acc: 0.6015399300262604\n",
            "Training GNN 120 ; Val_Acc: 0.59691247638777 ; Test_Acc: 0.6015399300262604\n",
            "Training GNN 121 ; Val_Acc: 0.6130888958238135 ; Test_Acc: 0.5914166810618402\n",
            "Training GNN 122 ; Val_Acc: 0.5988752965827506 ; Test_Acc: 0.5914166810618402\n",
            "Training GNN 123 ; Val_Acc: 0.6051999890044402 ; Test_Acc: 0.5865906408526937\n",
            "Training GNN 124 ; Val_Acc: 0.5924717644043006 ; Test_Acc: 0.5761958743673821\n",
            "Training GNN 125 ; Val_Acc: 0.6035987090800565 ; Test_Acc: 0.579505740034659\n",
            "Training GNN 126 ; Val_Acc: 0.5989076431396289 ; Test_Acc: 0.5770047115424318\n",
            "Training GNN 127 ; Val_Acc: 0.6009518407083853 ; Test_Acc: 0.5770047115424318\n",
            "Training GNN 128 ; Val_Acc: 0.6003550722200148 ; Test_Acc: 0.578639588926628\n",
            "Training GNN 129 ; Val_Acc: 0.601144360087916 ; Test_Acc: 0.5802083152027931\n",
            "Training GNN 130 ; Val_Acc: 0.6079196964764375 ; Test_Acc: 0.589579314540005\n",
            "Training GNN 131 ; Val_Acc: 0.6214434997635221 ; Test_Acc: 0.5925414767021672\n",
            "Training GNN 132 ; Val_Acc: 0.6151884560943554 ; Test_Acc: 0.5956135045316062\n",
            "Training GNN 133 ; Val_Acc: 0.6218878878533003 ; Test_Acc: 0.5956135045316062\n",
            "Training GNN 134 ; Val_Acc: 0.6118772239541161 ; Test_Acc: 0.5987256432599299\n",
            "Training GNN 135 ; Val_Acc: 0.6210163054744352 ; Test_Acc: 0.5984706023879954\n",
            "Training GNN 136 ; Val_Acc: 0.6186296618117496 ; Test_Acc: 0.5988266717521573\n",
            "Training GNN 137 ; Val_Acc: 0.6245214649402769 ; Test_Acc: 0.6005277002443845\n",
            "Training GNN 138 ; Val_Acc: 0.6241009903201249 ; Test_Acc: 0.5936837696085463\n",
            "Training GNN 139 ; Val_Acc: 0.6295672961875673 ; Test_Acc: 0.5947648506896275\n",
            "Training GNN 140 ; Val_Acc: 0.6291803287747341 ; Test_Acc: 0.5947648506896275\n",
            "Training GNN 141 ; Val_Acc: 0.6281385045163894 ; Test_Acc: 0.5952749324334967\n",
            "Training GNN 142 ; Val_Acc: 0.6254552219078988 ; Test_Acc: 0.5949938513524156\n",
            "Training GNN 143 ; Val_Acc: 0.625564653197036 ; Test_Acc: 0.6010065082644188\n",
            "Training GNN 144 ; Val_Acc: 0.6257605450189687 ; Test_Acc: 0.6083304446214338\n",
            "Training GNN 145 ; Val_Acc: 0.6306600979279178 ; Test_Acc: 0.6083304446214338\n",
            "Training GNN 146 ; Val_Acc: 0.6254700884639698 ; Test_Acc: 0.6083304446214338\n",
            "Training GNN 147 ; Val_Acc: 0.6275870849677747 ; Test_Acc: 0.6197277002443845\n",
            "Training GNN 148 ; Val_Acc: 0.6395243988787124 ; Test_Acc: 0.6166817126240919\n",
            "Training GNN 149 ; Val_Acc: 0.6472986118570307 ; Test_Acc: 0.6166817126240919\n",
            "Training GNN 150 ; Val_Acc: 0.6393890863815784 ; Test_Acc: 0.6152617652129457\n",
            "Training GNN 151 ; Val_Acc: 0.6426841182263755 ; Test_Acc: 0.6152617652129457\n",
            "Training GNN 152 ; Val_Acc: 0.6370575217421492 ; Test_Acc: 0.6163516834690765\n",
            "Training GNN 153 ; Val_Acc: 0.6325832969678473 ; Test_Acc: 0.6152966425971419\n",
            "Training GNN 154 ; Val_Acc: 0.6309914043712548 ; Test_Acc: 0.6152966425971419\n",
            "Training GNN 155 ; Val_Acc: 0.6322359064021804 ; Test_Acc: 0.6026907658757339\n",
            "Training GNN 156 ; Val_Acc: 0.6505513665952886 ; Test_Acc: 0.595706599317971\n",
            "Training GNN 157 ; Val_Acc: 0.6368405485529365 ; Test_Acc: 0.5966565758841325\n",
            "Training GNN 158 ; Val_Acc: 0.6329022427721791 ; Test_Acc: 0.5954166810618402\n",
            "Training GNN 159 ; Val_Acc: 0.6369243156706663 ; Test_Acc: 0.5954166810618402\n",
            "Training GNN 160 ; Val_Acc: 0.6336783450819232 ; Test_Acc: 0.5893238023520678\n",
            "Training GNN 161 ; Val_Acc: 0.6312097530861361 ; Test_Acc: 0.5744547349762703\n",
            "Training GNN 162 ; Val_Acc: 0.6275369486151232 ; Test_Acc: 0.5744547349762703\n",
            "Training GNN 163 ; Val_Acc: 0.6328255355575061 ; Test_Acc: 0.5744547349762703\n",
            "Training GNN 164 ; Val_Acc: 0.632806960827745 ; Test_Acc: 0.5733996941043357\n",
            "Training GNN 165 ; Val_Acc: 0.6349063941183741 ; Test_Acc: 0.57249343209742\n",
            "Training GNN 166 ; Val_Acc: 0.6309507825064201 ; Test_Acc: 0.57249343209742\n",
            "Training GNN 167 ; Val_Acc: 0.6237411501394571 ; Test_Acc: 0.5829013658032826\n",
            "Training GNN 168 ; Val_Acc: 0.6235660421375475 ; Test_Acc: 0.5829013658032826\n",
            "Training GNN 169 ; Val_Acc: 0.6333593742418353 ; Test_Acc: 0.5884135045316063\n",
            "Training GNN 170 ; Val_Acc: 0.6287876640163513 ; Test_Acc: 0.5910556724149454\n",
            "Training GNN 171 ; Val_Acc: 0.6365419294409399 ; Test_Acc: 0.5988756198260916\n",
            "Training GNN 172 ; Val_Acc: 0.6175360839629659 ; Test_Acc: 0.5999655380822223\n",
            "Training GNN 173 ; Val_Acc: 0.6142766088353195 ; Test_Acc: 0.5929988687905117\n",
            "Training GNN 174 ; Val_Acc: 0.6162439808549306 ; Test_Acc: 0.5929988687905117\n",
            "Training GNN 175 ; Val_Acc: 0.6088440363975658 ; Test_Acc: 0.5847089505343809\n",
            "Training GNN 176 ; Val_Acc: 0.6068872382925081 ; Test_Acc: 0.584775101642412\n",
            "Training GNN 177 ; Val_Acc: 0.607054255422534 ; Test_Acc: 0.5940539096624462\n",
            "Training GNN 178 ; Val_Acc: 0.6245364193916633 ; Test_Acc: 0.6089367534960265\n",
            "Training GNN 179 ; Val_Acc: 0.6229409508245812 ; Test_Acc: 0.6156006315430107\n",
            "Training GNN 180 ; Val_Acc: 0.6266641470489785 ; Test_Acc: 0.6153195504619297\n",
            "Training GNN 181 ; Val_Acc: 0.6351417770535173 ; Test_Acc: 0.6134468352398957\n",
            "Training GNN 182 ; Val_Acc: 0.6390334732811677 ; Test_Acc: 0.6134468352398957\n",
            "Training GNN 183 ; Val_Acc: 0.6401877743653182 ; Test_Acc: 0.6134468352398957\n",
            "Training GNN 184 ; Val_Acc: 0.6331194855910794 ; Test_Acc: 0.6150728754490422\n",
            "Training GNN 185 ; Val_Acc: 0.6174375686236373 ; Test_Acc: 0.6229320302898858\n",
            "Training GNN 186 ; Val_Acc: 0.6194135046729077 ; Test_Acc: 0.6229320302898858\n",
            "Training GNN 187 ; Val_Acc: 0.6223327244253251 ; Test_Acc: 0.623442112033755\n",
            "Training GNN 188 ; Val_Acc: 0.620314214983052 ; Test_Acc: 0.623442112033755\n",
            "Training GNN 189 ; Val_Acc: 0.6316226566415384 ; Test_Acc: 0.6253231931148361\n",
            "Training GNN 190 ; Val_Acc: 0.6289791798042846 ; Test_Acc: 0.6126600024604467\n",
            "Training GNN 191 ; Val_Acc: 0.6354955429113901 ; Test_Acc: 0.6126600024604467\n",
            "Training GNN 192 ; Val_Acc: 0.6349618508393292 ; Test_Acc: 0.6126600024604467\n",
            "Training GNN 193 ; Val_Acc: 0.6382075934045688 ; Test_Acc: 0.6208042741959171\n",
            "Training GNN 194 ; Val_Acc: 0.6369627716724435 ; Test_Acc: 0.624404961588512\n",
            "Training GNN 195 ; Val_Acc: 0.6372744794416134 ; Test_Acc: 0.624404961588512\n",
            "Training GNN 196 ; Val_Acc: 0.6359055208856165 ; Test_Acc: 0.6222600024604467\n",
            "Training GNN 197 ; Val_Acc: 0.633077664711661 ; Test_Acc: 0.618132933759073\n",
            "Training GNN 198 ; Val_Acc: 0.630875063933936 ; Test_Acc: 0.618132933759073\n",
            "Training GNN 199 ; Val_Acc: 0.6277826329533185 ; Test_Acc: 0.6078878496079675\n",
            "Training GNN 200 ; Val_Acc: 0.628593922387615 ; Test_Acc: 0.6078878496079675\n",
            "Training GNN 201 ; Val_Acc: 0.6378911416298217 ; Test_Acc: 0.6020857926235129\n",
            "Training GNN 202 ; Val_Acc: 0.6325000655072263 ; Test_Acc: 0.6039580365295444\n",
            "Training GNN 203 ; Val_Acc: 0.6355738086468976 ; Test_Acc: 0.6039580365295444\n",
            "Training GNN 204 ; Val_Acc: 0.624587358689638 ; Test_Acc: 0.6023408334954475\n",
            "Training GNN 205 ; Val_Acc: 0.6228757168304276 ; Test_Acc: 0.602366873704594\n",
            "Training GNN 206 ; Val_Acc: 0.6266014344616395 ; Test_Acc: 0.602366873704594\n",
            "Training GNN 207 ; Val_Acc: 0.6252200839269144 ; Test_Acc: 0.5987186130232546\n",
            "Training GNN 208 ; Val_Acc: 0.6322756570587312 ; Test_Acc: 0.5921385604344007\n",
            "Training GNN 209 ; Val_Acc: 0.639375538435357 ; Test_Acc: 0.5896277912979367\n",
            "Training GNN 210 ; Val_Acc: 0.6361610428349823 ; Test_Acc: 0.5896277912979367\n",
            "Training GNN 211 ; Val_Acc: 0.6393783676558896 ; Test_Acc: 0.5917727504260021\n",
            "Training GNN 212 ; Val_Acc: 0.6379452781199069 ; Test_Acc: 0.5917727504260021\n",
            "Training GNN 213 ; Val_Acc: 0.6484445045294579 ; Test_Acc: 0.5825765701629556\n",
            "Training GNN 214 ; Val_Acc: 0.6471303926504931 ; Test_Acc: 0.5825765701629556\n",
            "Training GNN 215 ; Val_Acc: 0.6524146673190037 ; Test_Acc: 0.5836664884190864\n",
            "Training GNN 216 ; Val_Acc: 0.637310107663765 ; Test_Acc: 0.583921529291021\n",
            "Training GNN 217 ; Val_Acc: 0.6465779763545895 ; Test_Acc: 0.5841765701629555\n",
            "Training GNN 218 ; Val_Acc: 0.6289724696813574 ; Test_Acc: 0.5974508710534415\n",
            "Training GNN 219 ; Val_Acc: 0.6386488525651969 ; Test_Acc: 0.6151559353592145\n",
            "Training GNN 220 ; Val_Acc: 0.6255959199743697 ; Test_Acc: 0.6123040710175138\n",
            "Training GNN 221 ; Val_Acc: 0.6388439526088342 ; Test_Acc: 0.6137901695366911\n",
            "Training GNN 222 ; Val_Acc: 0.6355165425072088 ; Test_Acc: 0.6193644235595\n",
            "Training GNN 223 ; Val_Acc: 0.6299725288954233 ; Test_Acc: 0.6193644235595\n",
            "Training GNN 224 ; Val_Acc: 0.6352972645875445 ; Test_Acc: 0.6193644235595\n",
            "Training GNN 225 ; Val_Acc: 0.6275439078348164 ; Test_Acc: 0.6065383833503536\n",
            "Training GNN 226 ; Val_Acc: 0.6277769575815981 ; Test_Acc: 0.6051100700801604\n",
            "Training GNN 227 ; Val_Acc: 0.6262857314180965 ; Test_Acc: 0.6037739481271447\n",
            "Training GNN 228 ; Val_Acc: 0.6231165046070366 ; Test_Acc: 0.6136987437674717\n",
            "Training GNN 229 ; Val_Acc: 0.6329954906965295 ; Test_Acc: 0.6136987437674717\n",
            "Training GNN 230 ; Val_Acc: 0.6214506281096526 ; Test_Acc: 0.6081909350846492\n",
            "Training GNN 231 ; Val_Acc: 0.6272902134956329 ; Test_Acc: 0.6069598774374065\n",
            "Training GNN 232 ; Val_Acc: 0.6234632190271803 ; Test_Acc: 0.606876051979276\n",
            "Training GNN 233 ; Val_Acc: 0.6229606271276024 ; Test_Acc: 0.606876051979276\n",
            "Training GNN 234 ; Val_Acc: 0.6268946381054823 ; Test_Acc: 0.6216529280378961\n",
            "Training GNN 235 ; Val_Acc: 0.6360473423190635 ; Test_Acc: 0.6216529280378961\n",
            "Training GNN 236 ; Val_Acc: 0.628256540000463 ; Test_Acc: 0.6183607367207185\n",
            "Training GNN 237 ; Val_Acc: 0.6486253558058216 ; Test_Acc: 0.6233799967392697\n",
            "Training GNN 238 ; Val_Acc: 0.6529306247099768 ; Test_Acc: 0.6266148741234658\n",
            "Training GNN 239 ; Val_Acc: 0.6484280563980435 ; Test_Acc: 0.6193584636596717\n",
            "Training GNN 240 ; Val_Acc: 0.6496613415097492 ; Test_Acc: 0.6193584636596717\n",
            "Training GNN 241 ; Val_Acc: 0.6507859152453855 ; Test_Acc: 0.6105584636596716\n",
            "Training GNN 242 ; Val_Acc: 0.6510276579829867 ; Test_Acc: 0.6116884928146871\n",
            "Training GNN 243 ; Val_Acc: 0.6469852529887634 ; Test_Acc: 0.6116884928146871\n",
            "Training GNN 244 ; Val_Acc: 0.6443611253686842 ; Test_Acc: 0.6116884928146871\n",
            "Training GNN 245 ; Val_Acc: 0.641167404402551 ; Test_Acc: 0.61552564325993\n",
            "Training GNN 246 ; Val_Acc: 0.6403245184033732 ; Test_Acc: 0.6164006315430107\n",
            "Training GNN 247 ; Val_Acc: 0.6377013140443363 ; Test_Acc: 0.6164006315430107\n",
            "Training GNN 248 ; Val_Acc: 0.627995262168708 ; Test_Acc: 0.6082117417791072\n",
            "Training GNN 249 ; Val_Acc: 0.6323603940868614 ; Test_Acc: 0.6029850141773658\n",
            "Training GNN 250 ; Val_Acc: 0.6336747123757273 ; Test_Acc: 0.603604961588512\n",
            "Training GNN 251 ; Val_Acc: 0.6274302923323993 ; Test_Acc: 0.618004961588512\n",
            "Training GNN 252 ; Val_Acc: 0.6313006660209913 ; Test_Acc: 0.618004961588512\n",
            "Training GNN 253 ; Val_Acc: 0.6291167966716434 ; Test_Acc: 0.618004961588512\n",
            "Training GNN 254 ; Val_Acc: 0.6269726446578766 ; Test_Acc: 0.6416828661393592\n",
            "Training GNN 255 ; Val_Acc: 0.6265271793101401 ; Test_Acc: 0.6416828661393592\n",
            "Training GNN 256 ; Val_Acc: 0.6324954151605919 ; Test_Acc: 0.6416828661393592\n",
            "Training GNN 257 ; Val_Acc: 0.6339594391647738 ; Test_Acc: 0.6403780179101783\n",
            "Training GNN 258 ; Val_Acc: 0.6356444427995692 ; Test_Acc: 0.6437148272557891\n",
            "Training GNN 259 ; Val_Acc: 0.6442802874343972 ; Test_Acc: 0.6442509492088047\n",
            "Training GNN 260 ; Val_Acc: 0.6401297132052938 ; Test_Acc: 0.6442509492088047\n",
            "Training GNN 261 ; Val_Acc: 0.6397726213742635 ; Test_Acc: 0.6442509492088047\n",
            "Training GNN 262 ; Val_Acc: 0.6304090926810788 ; Test_Acc: 0.6428398389727084\n",
            "Training GNN 263 ; Val_Acc: 0.646686058774834 ; Test_Acc: 0.6455646346130351\n",
            "Training GNN 264 ; Val_Acc: 0.6376739798619294 ; Test_Acc: 0.6455646346130351\n",
            "Training GNN 265 ; Val_Acc: 0.6506973704408819 ; Test_Acc: 0.6421313039047459\n",
            "Training GNN 266 ; Val_Acc: 0.6422005562029989 ; Test_Acc: 0.6322674258577615\n",
            "Training GNN 267 ; Val_Acc: 0.644905200255032 ; Test_Acc: 0.6311863447766805\n",
            "Training GNN 268 ; Val_Acc: 0.637494855692498 ; Test_Acc: 0.6266458927781635\n",
            "Training GNN 269 ; Val_Acc: 0.6378926342291694 ; Test_Acc: 0.6266458927781635\n",
            "Training GNN 270 ; Val_Acc: 0.6353311835339854 ; Test_Acc: 0.6243999051578709\n",
            "Training GNN 271 ; Val_Acc: 0.6458604108842327 ; Test_Acc: 0.6304177955845625\n",
            "Training GNN 272 ; Val_Acc: 0.6349150269513334 ; Test_Acc: 0.6304177955845625\n",
            "Training GNN 273 ; Val_Acc: 0.6398439113196496 ; Test_Acc: 0.6304177955845625\n",
            "Training GNN 274 ; Val_Acc: 0.6219215679694368 ; Test_Acc: 0.6207917553754161\n",
            "Training GNN 275 ; Val_Acc: 0.622142419359344 ; Test_Acc: 0.6254148351309209\n",
            "Training GNN 276 ; Val_Acc: 0.6232430064993327 ; Test_Acc: 0.6254148351309209\n",
            "Training GNN 277 ; Val_Acc: 0.620837066933025 ; Test_Acc: 0.6258719329873099\n",
            "Training GNN 278 ; Val_Acc: 0.6274214819076749 ; Test_Acc: 0.6258719329873099\n",
            "Training GNN 279 ; Val_Acc: 0.6280496275828641 ; Test_Acc: 0.6253269738592446\n",
            "Training GNN 280 ; Val_Acc: 0.6249763394095199 ; Test_Acc: 0.6255070264480984\n",
            "Training GNN 281 ; Val_Acc: 0.6202023276682475 ; Test_Acc: 0.6255070264480984\n",
            "Training GNN 282 ; Val_Acc: 0.626303240957494 ; Test_Acc: 0.6242282184280641\n",
            "Training GNN 283 ; Val_Acc: 0.630716021322568 ; Test_Acc: 0.6242282184280641\n",
            "Training GNN 284 ; Val_Acc: 0.6242744030951658 ; Test_Acc: 0.6277365374194341\n",
            "Training GNN 285 ; Val_Acc: 0.6303669594851079 ; Test_Acc: 0.6197811554478673\n",
            "Training GNN 286 ; Val_Acc: 0.6323111411902008 ; Test_Acc: 0.6197811554478673\n",
            "Training GNN 287 ; Val_Acc: 0.6320515935273052 ; Test_Acc: 0.6197811554478673\n",
            "Training GNN 288 ; Val_Acc: 0.6333409281130077 ; Test_Acc: 0.6295784110708179\n",
            "Training GNN 289 ; Val_Acc: 0.6360837842933392 ; Test_Acc: 0.6242214824233441\n",
            "Training GNN 290 ; Val_Acc: 0.6343883513750118 ; Test_Acc: 0.6242214824233441\n",
            "Training GNN 291 ; Val_Acc: 0.6276087434182347 ; Test_Acc: 0.6217954422141977\n",
            "Training GNN 292 ; Val_Acc: 0.6243495737628333 ; Test_Acc: 0.6225954422141977\n",
            "Training GNN 293 ; Val_Acc: 0.6243040976630504 ; Test_Acc: 0.6225954422141977\n",
            "Training GNN 294 ; Val_Acc: 0.6309371785449462 ; Test_Acc: 0.6230482100250855\n",
            "Training GNN 295 ; Val_Acc: 0.6241607407632774 ; Test_Acc: 0.6243093436950204\n",
            "Training GNN 296 ; Val_Acc: 0.6220118940949916 ; Test_Acc: 0.6151532743308585\n",
            "Training GNN 297 ; Val_Acc: 0.6310659920120015 ; Test_Acc: 0.6178780699711856\n",
            "Training GNN 298 ; Val_Acc: 0.6364687139037082 ; Test_Acc: 0.6187129473553817\n",
            "Training GNN 299 ; Val_Acc: 0.6314847137690122 ; Test_Acc: 0.6187129473553817\n",
            "Training GNN 300 ; Val_Acc: 0.648674772425519 ; Test_Acc: 0.6227208810612443\n",
            "Training GNN 301 ; Val_Acc: 0.6509725166405104 ; Test_Acc: 0.6227208810612443\n",
            "Training GNN 302 ; Val_Acc: 0.6389689725284703 ; Test_Acc: 0.6227208810612443\n",
            "Training GNN 303 ; Val_Acc: 0.6571378777291287 ; Test_Acc: 0.614729718236294\n",
            "Training GNN 304 ; Val_Acc: 0.6510507067284098 ; Test_Acc: 0.614729718236294\n",
            "Training GNN 305 ; Val_Acc: 0.6669605620058189 ; Test_Acc: 0.6114948408520978\n",
            "Training GNN 306 ; Val_Acc: 0.6472475765586392 ; Test_Acc: 0.6097276612518395\n",
            "Training GNN 307 ; Val_Acc: 0.6588566688276185 ; Test_Acc: 0.6097276612518395\n",
            "Training GNN 308 ; Val_Acc: 0.6504686290054785 ; Test_Acc: 0.6102726203799048\n",
            "Training GNN 309 ; Val_Acc: 0.6439569070592263 ; Test_Acc: 0.6080567087823046\n",
            "Training GNN 310 ; Val_Acc: 0.6484815313317871 ; Test_Acc: 0.6080567087823046\n",
            "Training GNN 311 ; Val_Acc: 0.645842965465188 ; Test_Acc: 0.6080567087823046\n",
            "Training GNN 312 ; Val_Acc: 0.6464566105746378 ; Test_Acc: 0.6011563676826722\n",
            "Training GNN 313 ; Val_Acc: 0.640531738814804 ; Test_Acc: 0.5971563676826722\n",
            "Training GNN 314 ; Val_Acc: 0.6279159939222835 ; Test_Acc: 0.5955074196087379\n",
            "Training GNN 315 ; Val_Acc: 0.6262408071856231 ; Test_Acc: 0.5955074196087379\n",
            "Training GNN 316 ; Val_Acc: 0.6303742746087844 ; Test_Acc: 0.5955074196087379\n",
            "Training GNN 317 ; Val_Acc: 0.630459347007976 ; Test_Acc: 0.5919826239684108\n",
            "Training GNN 318 ; Val_Acc: 0.6185308199269143 ; Test_Acc: 0.5931386933325727\n",
            "Training GNN 319 ; Val_Acc: 0.6265547267467559 ; Test_Acc: 0.5931386933325727\n",
            "Training GNN 320 ; Val_Acc: 0.6148137904234612 ; Test_Acc: 0.5985498035686693\n",
            "Training GNN 321 ; Val_Acc: 0.6108908070656683 ; Test_Acc: 0.6012970357577815\n",
            "Training GNN 322 ; Val_Acc: 0.6251630360846077 ; Test_Acc: 0.6026419948858467\n",
            "Training GNN 323 ; Val_Acc: 0.6239989602488462 ; Test_Acc: 0.605499996211423\n",
            "Training GNN 324 ; Val_Acc: 0.6232706148142613 ; Test_Acc: 0.6109989677191958\n",
            "Training GNN 325 ; Val_Acc: 0.629166353059302 ; Test_Acc: 0.6084979392269686\n",
            "Training GNN 326 ; Val_Acc: 0.6210812262514691 ; Test_Acc: 0.6106340611799842\n",
            "Training GNN 327 ; Val_Acc: 0.6263876532412502 ; Test_Acc: 0.6106340611799842\n",
            "Training GNN 328 ; Val_Acc: 0.6223328859870016 ; Test_Acc: 0.6106340611799842\n",
            "Training GNN 329 ; Val_Acc: 0.6278868668915711 ; Test_Acc: 0.6136800488002769\n",
            "Training GNN 330 ; Val_Acc: 0.6182302662174046 ; Test_Acc: 0.6171960072655541\n",
            "Training GNN 331 ; Val_Acc: 0.6214844510556768 ; Test_Acc: 0.6150510481374888\n",
            "Training GNN 332 ; Val_Acc: 0.6150372237382686 ; Test_Acc: 0.6134510481374889\n",
            "Training GNN 333 ; Val_Acc: 0.6168896517393789 ; Test_Acc: 0.6134510481374889\n",
            "Training GNN 334 ; Val_Acc: 0.6157711968145355 ; Test_Acc: 0.6038956661659218\n",
            "Training GNN 335 ; Val_Acc: 0.6239650571523804 ; Test_Acc: 0.6033194333140216\n",
            "Training GNN 336 ; Val_Acc: 0.6195493829060802 ; Test_Acc: 0.6033194333140216\n",
            "Training GNN 337 ; Val_Acc: 0.6243272051254267 ; Test_Acc: 0.5985724172015017\n",
            "Training GNN 338 ; Val_Acc: 0.6074759973202304 ; Test_Acc: 0.593703133749112\n",
            "Training GNN 339 ; Val_Acc: 0.6260390874359619 ; Test_Acc: 0.593703133749112\n",
            "Training GNN 340 ; Val_Acc: 0.6217079560555985 ; Test_Acc: 0.59233959680176\n",
            "Training GNN 341 ; Val_Acc: 0.6225951023894333 ; Test_Acc: 0.59233959680176\n",
            "Training GNN 342 ; Val_Acc: 0.6115502946254584 ; Test_Acc: 0.5913237633595227\n",
            "Training GNN 343 ; Val_Acc: 0.6119051337787959 ; Test_Acc: 0.5921237633595228\n",
            "Training GNN 344 ; Val_Acc: 0.6098989120296201 ; Test_Acc: 0.592633845103392\n",
            "Training GNN 345 ; Val_Acc: 0.6082268095539989 ; Test_Acc: 0.592633845103392\n",
            "Training GNN 346 ; Val_Acc: 0.6082265296578501 ; Test_Acc: 0.5982598853125384\n",
            "Training GNN 347 ; Val_Acc: 0.6123278101045622 ; Test_Acc: 0.5982598853125384\n",
            "Training GNN 348 ; Val_Acc: 0.6037397826828662 ; Test_Acc: 0.5982598853125384\n",
            "Training GNN 349 ; Val_Acc: 0.632936680985414 ; Test_Acc: 0.5988798327236846\n",
            "Training GNN 350 ; Val_Acc: 0.6281112416588697 ; Test_Acc: 0.5988136816156535\n",
            "Training GNN 351 ; Val_Acc: 0.6385651067008428 ; Test_Acc: 0.5988136816156535\n",
            "Training GNN 352 ; Val_Acc: 0.6234451351063033 ; Test_Acc: 0.5991609138047657\n",
            "Training GNN 353 ; Val_Acc: 0.6174934505922165 ; Test_Acc: 0.5983609138047656\n",
            "Training GNN 354 ; Val_Acc: 0.6230908915878212 ; Test_Acc: 0.6267747684179116\n",
            "Training GNN 355 ; Val_Acc: 0.6229027930905143 ; Test_Acc: 0.6267358552201696\n",
            "Training GNN 356 ; Val_Acc: 0.6226029947764025 ; Test_Acc: 0.6267358552201696\n",
            "Training GNN 357 ; Val_Acc: 0.621138706726047 ; Test_Acc: 0.6236237164918459\n",
            "Training GNN 358 ; Val_Acc: 0.6221469097653215 ; Test_Acc: 0.6240504440935873\n",
            "Training GNN 359 ; Val_Acc: 0.6210132829922758 ; Test_Acc: 0.6240504440935873\n",
            "Training GNN 360 ; Val_Acc: 0.6277048160602839 ; Test_Acc: 0.6237782001875558\n",
            "Training GNN 361 ; Val_Acc: 0.630520112209754 ; Test_Acc: 0.6237782001875558\n",
            "Training GNN 362 ; Val_Acc: 0.6282279507882198 ; Test_Acc: 0.6259491995247677\n",
            "Training GNN 363 ; Val_Acc: 0.6530012734518301 ; Test_Acc: 0.6266599634679016\n",
            "Training GNN 364 ; Val_Acc: 0.6496261131392396 ; Test_Acc: 0.6266599634679016\n",
            "Training GNN 365 ; Val_Acc: 0.649451177145581 ; Test_Acc: 0.6266599634679016\n",
            "Training GNN 366 ; Val_Acc: 0.6512637804635527 ; Test_Acc: 0.6217056568562389\n",
            "Training GNN 367 ; Val_Acc: 0.6515978592116031 ; Test_Acc: 0.6280349986186594\n",
            "Training GNN 368 ; Val_Acc: 0.6552045800937811 ; Test_Acc: 0.6310148351309208\n",
            "Training GNN 369 ; Val_Acc: 0.6597921451572984 ; Test_Acc: 0.6377047533870518\n",
            "Training GNN 370 ; Val_Acc: 0.6595364756950969 ; Test_Acc: 0.6377047533870518\n",
            "Training GNN 371 ; Val_Acc: 0.6638434916987664 ; Test_Acc: 0.6396608227512135\n",
            "Training GNN 372 ; Val_Acc: 0.6602064267599568 ; Test_Acc: 0.6361797416701325\n",
            "Training GNN 373 ; Val_Acc: 0.6627918934092644 ; Test_Acc: 0.6361797416701325\n",
            "Training GNN 374 ; Val_Acc: 0.6529398429113302 ; Test_Acc: 0.623516551015743\n",
            "Training GNN 375 ; Val_Acc: 0.663344044218087 ; Test_Acc: 0.6194644705974501\n",
            "Training GNN 376 ; Val_Acc: 0.6503642446725766 ; Test_Acc: 0.6185290360370292\n",
            "Training GNN 377 ; Val_Acc: 0.661403177499237 ; Test_Acc: 0.615746926463721\n",
            "Training GNN 378 ; Val_Acc: 0.6558440287823729 ; Test_Acc: 0.615746926463721\n",
            "Training GNN 379 ; Val_Acc: 0.6571186041595621 ; Test_Acc: 0.615746926463721\n",
            "Training GNN 380 ; Val_Acc: 0.6468821888867311 ; Test_Acc: 0.6294501838311197\n",
            "Training GNN 381 ; Val_Acc: 0.6456748163227453 ; Test_Acc: 0.6294501838311197\n",
            "Training GNN 382 ; Val_Acc: 0.6581992698622575 ; Test_Acc: 0.6307201546761043\n",
            "Training GNN 383 ; Val_Acc: 0.6569623727573914 ; Test_Acc: 0.6283863057841355\n",
            "Training GNN 384 ; Val_Acc: 0.6634163471209645 ; Test_Acc: 0.6296345664654748\n",
            "Training GNN 385 ; Val_Acc: 0.6698661403331856 ; Test_Acc: 0.6273573051213472\n",
            "Training GNN 386 ; Val_Acc: 0.6645179895450827 ; Test_Acc: 0.6273573051213472\n",
            "Training GNN 387 ; Val_Acc: 0.6600134443089983 ; Test_Acc: 0.6194406592634751\n",
            "Training GNN 388 ; Val_Acc: 0.6581812311498318 ; Test_Acc: 0.6263591068663914\n",
            "Training GNN 389 ; Val_Acc: 0.6576221928064298 ; Test_Acc: 0.6263591068663914\n",
            "Training GNN 390 ; Val_Acc: 0.6582496961974058 ; Test_Acc: 0.6244691886102606\n",
            "Training GNN 391 ; Val_Acc: 0.6737530826490243 ; Test_Acc: 0.6333613799274381\n",
            "Training GNN 392 ; Val_Acc: 0.6670019396262781 ; Test_Acc: 0.6320914090824535\n",
            "Training GNN 393 ; Val_Acc: 0.6706403669424823 ; Test_Acc: 0.6320914090824535\n",
            "Training GNN 394 ; Val_Acc: 0.6751416389786217 ; Test_Acc: 0.6343113564935997\n",
            "Training GNN 395 ; Val_Acc: 0.6711679146276543 ; Test_Acc: 0.6412964265205496\n",
            "Training GNN 396 ; Val_Acc: 0.666649781640298 ; Test_Acc: 0.6402943695360952\n",
            "Training GNN 397 ; Val_Acc: 0.6750273291392329 ; Test_Acc: 0.636993341043868\n",
            "Training GNN 398 ; Val_Acc: 0.6608743207502228 ; Test_Acc: 0.636993341043868\n",
            "Training GNN 399 ; Val_Acc: 0.6709533976442225 ; Test_Acc: 0.6384044512799643\n",
            "Training GNN 400 ; Val_Acc: 0.6523350010220713 ; Test_Acc: 0.6374112314705596\n",
            "Training GNN 401 ; Val_Acc: 0.6537373900570991 ; Test_Acc: 0.6391872482458676\n",
            "Training GNN 402 ; Val_Acc: 0.6516431195355907 ; Test_Acc: 0.6391872482458676\n",
            "Training GNN 403 ; Val_Acc: 0.6457150176229028 ; Test_Acc: 0.6358601795444938\n",
            "Training GNN 404 ; Val_Acc: 0.6474246006063868 ; Test_Acc: 0.6272402321333477\n",
            "Training GNN 405 ; Val_Acc: 0.6482314136835472 ; Test_Acc: 0.627165243850267\n",
            "Training GNN 406 ; Val_Acc: 0.6434833667228665 ; Test_Acc: 0.627165243850267\n",
            "Training GNN 407 ; Val_Acc: 0.6512105420186404 ; Test_Acc: 0.627165243850267\n",
            "Training GNN 408 ; Val_Acc: 0.6525776086639882 ; Test_Acc: 0.615106732216143\n",
            "Training GNN 409 ; Val_Acc: 0.6477123623054138 ; Test_Acc: 0.615106732216143\n",
            "Training GNN 410 ; Val_Acc: 0.6392603363144231 ; Test_Acc: 0.615106732216143\n",
            "Training GNN 411 ; Val_Acc: 0.6487195010548917 ; Test_Acc: 0.6131595000270308\n",
            "Training GNN 412 ; Val_Acc: 0.6399667961756116 ; Test_Acc: 0.6093572269659842\n",
            "Training GNN 413 ; Val_Acc: 0.6550281306076268 ; Test_Acc: 0.6118494182831615\n",
            "Training GNN 414 ; Val_Acc: 0.638060611543475 ; Test_Acc: 0.6117572269659841\n",
            "Training GNN 415 ; Val_Acc: 0.6412605521838778 ; Test_Acc: 0.6109572269659842\n",
            "Training GNN 416 ; Val_Acc: 0.6302279559250525 ; Test_Acc: 0.6109572269659842\n",
            "Training GNN 417 ; Val_Acc: 0.6344225527391887 ; Test_Acc: 0.6087377508708406\n",
            "Training GNN 418 ; Val_Acc: 0.6364170374017839 ; Test_Acc: 0.6087377508708406\n",
            "Training GNN 419 ; Val_Acc: 0.6378189255415795 ; Test_Acc: 0.6073927917427752\n",
            "Training GNN 420 ; Val_Acc: 0.6360338765045309 ; Test_Acc: 0.6093488611069371\n",
            "Training GNN 421 ; Val_Acc: 0.6443410427299404 ; Test_Acc: 0.6086723261479495\n",
            "Training GNN 422 ; Val_Acc: 0.6373942368093323 ; Test_Acc: 0.6086723261479495\n",
            "Training GNN 423 ; Val_Acc: 0.6382034821371972 ; Test_Acc: 0.6082023553029648\n",
            "Training GNN 424 ; Val_Acc: 0.6371146086690532 ; Test_Acc: 0.628764517465127\n",
            "Training GNN 425 ; Val_Acc: 0.6378523605234444 ; Test_Acc: 0.628764517465127\n",
            "Training GNN 426 ; Val_Acc: 0.6281378815043047 ; Test_Acc: 0.625165204857722\n",
            "Training GNN 427 ; Val_Acc: 0.6296109084743845 ; Test_Acc: 0.6138694098801831\n",
            "Training GNN 428 ; Val_Acc: 0.628489989058546 ; Test_Acc: 0.6097815486085068\n",
            "Training GNN 429 ; Val_Acc: 0.6191370933570948 ; Test_Acc: 0.6080014960196529\n",
            "Training GNN 430 ; Val_Acc: 0.6018195605564179 ; Test_Acc: 0.6080014960196529\n",
            "Training GNN 431 ; Val_Acc: 0.6040962034115471 ; Test_Acc: 0.6055004675274257\n",
            "Training GNN 432 ; Val_Acc: 0.6214248848684836 ; Test_Acc: 0.6065414377096222\n",
            "Training GNN 433 ; Val_Acc: 0.6163574825257089 ; Test_Acc: 0.6065414377096222\n",
            "Training GNN 434 ; Val_Acc: 0.6230077912497205 ; Test_Acc: 0.6082513033768991\n",
            "Training GNN 435 ; Val_Acc: 0.6206962618792234 ; Test_Acc: 0.6082513033768991\n",
            "Training GNN 436 ; Val_Acc: 0.6281659377611395 ; Test_Acc: 0.6150907268831889\n",
            "Training GNN 437 ; Val_Acc: 0.6240443468322937 ; Test_Acc: 0.616237959072301\n",
            "Training GNN 438 ; Val_Acc: 0.6346026426764133 ; Test_Acc: 0.6082379590723009\n",
            "Training GNN 439 ; Val_Acc: 0.6338466997337008 ; Test_Acc: 0.6082379590723009\n",
            "Training GNN 440 ; Val_Acc: 0.649282047826276 ; Test_Acc: 0.620519040153382\n",
            "Training GNN 441 ; Val_Acc: 0.643941107335879 ; Test_Acc: 0.620519040153382\n",
            "Training GNN 442 ; Val_Acc: 0.6374127007693811 ; Test_Acc: 0.620519040153382\n",
            "Training GNN 443 ; Val_Acc: 0.6406535446116741 ; Test_Acc: 0.6297629707892202\n",
            "Training GNN 444 ; Val_Acc: 0.6478123151294038 ; Test_Acc: 0.630299092742236\n",
            "Training GNN 445 ; Val_Acc: 0.6594535583521618 ; Test_Acc: 0.6322150512075132\n",
            "Training GNN 446 ; Val_Acc: 0.6660558416520066 ; Test_Acc: 0.6321011497266904\n",
            "Training GNN 447 ; Val_Acc: 0.6651880421938725 ; Test_Acc: 0.6321011497266904\n",
            "Training GNN 448 ; Val_Acc: 0.6601909879837664 ; Test_Acc: 0.6321011497266904\n",
            "Training GNN 449 ; Val_Acc: 0.6668284270684401 ; Test_Acc: 0.6295829182003663\n",
            "Training GNN 450 ; Val_Acc: 0.6544860209380616 ; Test_Acc: 0.6304089584095128\n",
            "Training GNN 451 ; Val_Acc: 0.6645078098986563 ; Test_Acc: 0.6304089584095128\n",
            "Training GNN 452 ; Val_Acc: 0.6482648256109026 ; Test_Acc: 0.6304177955845625\n",
            "Training GNN 453 ; Val_Acc: 0.6505875207484281 ; Test_Acc: 0.6280177955845625\n",
            "Training GNN 454 ; Val_Acc: 0.6408495317135704 ; Test_Acc: 0.6249806451393196\n",
            "Training GNN 455 ; Val_Acc: 0.6453528060698432 ; Test_Acc: 0.6221985355660113\n",
            "Training GNN 456 ; Val_Acc: 0.6360751363308582 ; Test_Acc: 0.6221985355660113\n",
            "Training GNN 457 ; Val_Acc: 0.6480589746012869 ; Test_Acc: 0.6220044122874193\n",
            "Training GNN 458 ; Val_Acc: 0.6430459030909044 ; Test_Acc: 0.6220044122874193\n",
            "Training GNN 459 ; Val_Acc: 0.6410999955396728 ; Test_Acc: 0.6125813325319146\n",
            "Training GNN 460 ; Val_Acc: 0.6334211815794674 ; Test_Acc: 0.6040945908060176\n",
            "Training GNN 461 ; Val_Acc: 0.6466322221734794 ; Test_Acc: 0.6008336732126749\n",
            "Training GNN 462 ; Val_Acc: 0.639939788898938 ; Test_Acc: 0.6008336732126749\n",
            "Training GNN 463 ; Val_Acc: 0.6316085191843163 ; Test_Acc: 0.6123439268472611\n",
            "Training GNN 464 ; Val_Acc: 0.6210369704196458 ; Test_Acc: 0.6123439268472611\n",
            "Training GNN 465 ; Val_Acc: 0.6227736327251439 ; Test_Acc: 0.6098737399256844\n",
            "Training GNN 466 ; Val_Acc: 0.6304126650493018 ; Test_Acc: 0.6087265077365722\n",
            "Training GNN 467 ; Val_Acc: 0.6279080127394319 ; Test_Acc: 0.6087265077365722\n",
            "Training GNN 468 ; Val_Acc: 0.6286730888699956 ; Test_Acc: 0.6089992229586062\n",
            "Training GNN 469 ; Val_Acc: 0.6394977792059725 ; Test_Acc: 0.6118660614592322\n",
            "Training GNN 470 ; Val_Acc: 0.629254773585593 ; Test_Acc: 0.6118660614592322\n",
            "Training GNN 471 ; Val_Acc: 0.6388724440195276 ; Test_Acc: 0.6118660614592322\n",
            "Training GNN 472 ; Val_Acc: 0.6358481203813668 ; Test_Acc: 0.6159931301606059\n",
            "Training GNN 473 ; Val_Acc: 0.6342235584647689 ; Test_Acc: 0.6138080601336559\n",
            "Training GNN 474 ; Val_Acc: 0.6273547075841359 ; Test_Acc: 0.6138080601336559\n",
            "Training GNN 475 ; Val_Acc: 0.6246415800131124 ; Test_Acc: 0.6111040711877871\n",
            "Training GNN 476 ; Val_Acc: 0.6175474583012556 ; Test_Acc: 0.6111040711877871\n",
            "Training GNN 477 ; Val_Acc: 0.625728471874158 ; Test_Acc: 0.6064007696345131\n",
            "Training GNN 478 ; Val_Acc: 0.6209907626994268 ; Test_Acc: 0.5873953642291075\n",
            "Training GNN 479 ; Val_Acc: 0.6219612725169695 ; Test_Acc: 0.5909946768365126\n",
            "Training GNN 480 ; Val_Acc: 0.6007858842658889 ; Test_Acc: 0.5909946768365126\n",
            "Training GNN 481 ; Val_Acc: 0.6248661781209667 ; Test_Acc: 0.5877602707683192\n",
            "Training GNN 482 ; Val_Acc: 0.6325211839778571 ; Test_Acc: 0.570846075055541\n",
            "Training GNN 483 ; Val_Acc: 0.6202423164346494 ; Test_Acc: 0.5705649939744599\n",
            "Training GNN 484 ; Val_Acc: 0.6247546126687221 ; Test_Acc: 0.5705649939744599\n",
            "Training GNN 485 ; Val_Acc: 0.6175698136102741 ; Test_Acc: 0.5706399822575408\n",
            "Training GNN 486 ; Val_Acc: 0.6144264988065941 ; Test_Acc: 0.5763181028849801\n",
            "Training GNN 487 ; Val_Acc: 0.6224465387728825 ; Test_Acc: 0.5706562818224502\n",
            "Training GNN 488 ; Val_Acc: 0.6180159556438739 ; Test_Acc: 0.5736272811596621\n",
            "Training GNN 489 ; Val_Acc: 0.6231837728013866 ; Test_Acc: 0.5736272811596621\n",
            "Training GNN 490 ; Val_Acc: 0.617220271590618 ; Test_Acc: 0.5769283096518893\n",
            "Training GNN 491 ; Val_Acc: 0.6244651755552953 ; Test_Acc: 0.5786205009690668\n",
            "Training GNN 492 ; Val_Acc: 0.6272992814824506 ; Test_Acc: 0.5802465411782134\n",
            "Training GNN 493 ; Val_Acc: 0.6329486752738609 ; Test_Acc: 0.5975120048936495\n",
            "Training GNN 494 ; Val_Acc: 0.6447459975228939 ; Test_Acc: 0.6122062531952815\n",
            "Training GNN 495 ; Val_Acc: 0.6425188982673752 ; Test_Acc: 0.6122062531952815\n",
            "Training GNN 496 ; Val_Acc: 0.638301400580877 ; Test_Acc: 0.6113974160202319\n",
            "Training GNN 497 ; Val_Acc: 0.6516511462871206 ; Test_Acc: 0.6250146190543286\n",
            "Training GNN 498 ; Val_Acc: 0.6361376349435353 ; Test_Acc: 0.6266146190543286\n",
            "Training GNN 499 ; Val_Acc: 0.6508914948104916 ; Test_Acc: 0.6266146190543286\n",
            "Training GNN 500 ; Val_Acc: 0.6545381774420692 ; Test_Acc: 0.6337135905621014\n",
            "Training GNN 501 ; Val_Acc: 0.65429873835424 ; Test_Acc: 0.6351247007981978\n",
            "Training GNN 502 ; Val_Acc: 0.6421523684967022 ; Test_Acc: 0.6339686314340359\n",
            "Training GNN 503 ; Val_Acc: 0.6513974903120814 ; Test_Acc: 0.6364696599262631\n",
            "Training GNN 504 ; Val_Acc: 0.6514805014940729 ; Test_Acc: 0.6364696599262631\n",
            "Training GNN 505 ; Val_Acc: 0.6538027440067447 ; Test_Acc: 0.6364696599262631\n",
            "Training GNN 506 ; Val_Acc: 0.6375205038338172 ; Test_Acc: 0.6360830432234065\n",
            "Training GNN 507 ; Val_Acc: 0.6554795604090132 ; Test_Acc: 0.6366280023514718\n",
            "Training GNN 508 ; Val_Acc: 0.6466705643436181 ; Test_Acc: 0.6383201936686494\n",
            "Training GNN 509 ; Val_Acc: 0.6472952053732051 ; Test_Acc: 0.6383201936686494\n",
            "Training GNN 510 ; Val_Acc: 0.6483920776753096 ; Test_Acc: 0.6374540425606183\n",
            "Training GNN 511 ; Val_Acc: 0.649707422069942 ; Test_Acc: 0.6408212221608767\n",
            "Training GNN 512 ; Val_Acc: 0.650618500244965 ; Test_Acc: 0.6408212221608767\n",
            "Training GNN 513 ; Val_Acc: 0.653064666687526 ; Test_Acc: 0.6378979731964564\n",
            "Training GNN 514 ; Val_Acc: 0.6533264443338326 ; Test_Acc: 0.6249709044950827\n",
            "Training GNN 515 ; Val_Acc: 0.6637993639275362 ; Test_Acc: 0.6240698760028555\n",
            "Training GNN 516 ; Val_Acc: 0.6579450481511795 ; Test_Acc: 0.6240698760028555\n",
            "Training GNN 517 ; Val_Acc: 0.668629362103132 ; Test_Acc: 0.622443835793709\n",
            "Training GNN 518 ; Val_Acc: 0.6633575963069155 ; Test_Acc: 0.622443835793709\n",
            "Training GNN 519 ; Val_Acc: 0.6710988386355906 ; Test_Acc: 0.626900933650098\n",
            "Training GNN 520 ; Val_Acc: 0.6600307555435951 ; Test_Acc: 0.6290198525690169\n",
            "Training GNN 521 ; Val_Acc: 0.6757579355367249 ; Test_Acc: 0.6290198525690169\n",
            "Training GNN 522 ; Val_Acc: 0.6655052895292952 ; Test_Acc: 0.6290198525690169\n",
            "Training GNN 523 ; Val_Acc: 0.6677862104367603 ; Test_Acc: 0.6228259453670174\n",
            "Training GNN 524 ; Val_Acc: 0.6638004907166661 ; Test_Acc: 0.618900933650098\n",
            "Training GNN 525 ; Val_Acc: 0.6586436026572368 ; Test_Acc: 0.6169537014609859\n",
            "Training GNN 526 ; Val_Acc: 0.6541510475669924 ; Test_Acc: 0.6169537014609859\n",
            "Training GNN 527 ; Val_Acc: 0.6549379952221115 ; Test_Acc: 0.6229976320968241\n",
            "Training GNN 528 ; Val_Acc: 0.6536785090210964 ; Test_Acc: 0.6229226438137434\n",
            "Training GNN 529 ; Val_Acc: 0.6605927724214992 ; Test_Acc: 0.621858765766759\n",
            "Training GNN 530 ; Val_Acc: 0.6642219883806573 ; Test_Acc: 0.621858765766759\n",
            "Training GNN 531 ; Val_Acc: 0.6633416634798012 ; Test_Acc: 0.6256655459573542\n",
            "Training GNN 532 ; Val_Acc: 0.6601044867453538 ; Test_Acc: 0.6289004233415504\n",
            "Training GNN 533 ; Val_Acc: 0.6676142996269615 ; Test_Acc: 0.6289004233415504\n",
            "Training GNN 534 ; Val_Acc: 0.6597871088277512 ; Test_Acc: 0.6306014518337777\n",
            "Training GNN 535 ; Val_Acc: 0.6631600314120571 ; Test_Acc: 0.6306014518337777\n",
            "Training GNN 536 ; Val_Acc: 0.6592204797872439 ; Test_Acc: 0.6328386022790207\n",
            "Training GNN 537 ; Val_Acc: 0.6642620556764808 ; Test_Acc: 0.6261835614070861\n",
            "Training GNN 538 ; Val_Acc: 0.6580269357860813 ; Test_Acc: 0.626917410299055\n",
            "Training GNN 539 ; Val_Acc: 0.6629567311677316 ; Test_Acc: 0.6252252189818774\n",
            "Training GNN 540 ; Val_Acc: 0.6523932241039997 ; Test_Acc: 0.6258363292179738\n",
            "Training GNN 541 ; Val_Acc: 0.6643436671976148 ; Test_Acc: 0.6258363292179738\n",
            "Training GNN 542 ; Val_Acc: 0.6517714980289009 ; Test_Acc: 0.6272474394540704\n",
            "Training GNN 543 ; Val_Acc: 0.6623031169242353 ; Test_Acc: 0.6272474394540704\n",
            "Training GNN 544 ; Val_Acc: 0.6616852652674504 ; Test_Acc: 0.6284696599262631\n",
            "Training GNN 545 ; Val_Acc: 0.6670902691953264 ; Test_Acc: 0.6304746773643595\n",
            "Training GNN 546 ; Val_Acc: 0.6556080977622998 ; Test_Acc: 0.6258375269191164\n",
            "Training GNN 547 ; Val_Acc: 0.6635424433979924 ; Test_Acc: 0.6258375269191164\n",
            "Training GNN 548 ; Val_Acc: 0.6662753391298472 ; Test_Acc: 0.6227915392988238\n",
            "Training GNN 549 ; Val_Acc: 0.6641586243233241 ; Test_Acc: 0.6204044122874193\n",
            "Training GNN 550 ; Val_Acc: 0.6553616749593617 ; Test_Acc: 0.6182594531593539\n",
            "Training GNN 551 ; Val_Acc: 0.6720990250096827 ; Test_Acc: 0.6196705633954503\n",
            "Training GNN 552 ; Val_Acc: 0.6729657225343293 ; Test_Acc: 0.6196705633954503\n",
            "Training GNN 553 ; Val_Acc: 0.6541793561626335 ; Test_Acc: 0.6222377429957088\n",
            "Training GNN 554 ; Val_Acc: 0.651618787842761 ; Test_Acc: 0.6222377429957088\n",
            "Training GNN 555 ; Val_Acc: 0.6581579280843552 ; Test_Acc: 0.6222377429957088\n",
            "Training GNN 556 ; Val_Acc: 0.6528598336785759 ; Test_Acc: 0.6239387714879359\n",
            "Training GNN 557 ; Val_Acc: 0.6543867885674794 ; Test_Acc: 0.6241276612518395\n",
            "Training GNN 558 ; Val_Acc: 0.6512841977529045 ; Test_Acc: 0.6227827021237741\n",
            "Training GNN 559 ; Val_Acc: 0.656712897753591 ; Test_Acc: 0.6271247007981978\n",
            "Training GNN 560 ; Val_Acc: 0.6573741983343823 ; Test_Acc: 0.635990851906229\n",
            "Training GNN 561 ; Val_Acc: 0.6556862516474159 ; Test_Acc: 0.635990851906229\n",
            "Training GNN 562 ; Val_Acc: 0.652825747586944 ; Test_Acc: 0.6212392896716155\n",
            "Training GNN 563 ; Val_Acc: 0.6631600868869691 ; Test_Acc: 0.6212392896716155\n",
            "Training GNN 564 ; Val_Acc: 0.6474684092167577 ; Test_Acc: 0.6212392896716155\n",
            "Training GNN 565 ; Val_Acc: 0.6248689594313479 ; Test_Acc: 0.5916238935758931\n",
            "Training GNN 566 ; Val_Acc: 0.6238326372756786 ; Test_Acc: 0.5916238935758931\n",
            "Training GNN 567 ; Val_Acc: 0.6207212895300448 ; Test_Acc: 0.5916238935758931\n",
            "Training GNN 568 ; Val_Acc: 0.6155520105725671 ; Test_Acc: 0.5867629759825503\n",
            "Training GNN 569 ; Val_Acc: 0.6056690270473412 ; Test_Acc: 0.5711548262000956\n",
            "Training GNN 570 ; Val_Acc: 0.6047520204413379 ; Test_Acc: 0.567212140133077\n",
            "Training GNN 571 ; Val_Acc: 0.6088431882437911 ; Test_Acc: 0.567212140133077\n",
            "Training GNN 572 ; Val_Acc: 0.6060951316506485 ; Test_Acc: 0.567212140133077\n",
            "Training GNN 573 ; Val_Acc: 0.6071444749209843 ; Test_Acc: 0.576794033629793\n",
            "Training GNN 574 ; Val_Acc: 0.6061309014418944 ; Test_Acc: 0.5758758021034691\n",
            "Training GNN 575 ; Val_Acc: 0.6221273852978555 ; Test_Acc: 0.5668900446839241\n",
            "Training GNN 576 ; Val_Acc: 0.6145526498380804 ; Test_Acc: 0.5668900446839241\n",
            "Training GNN 577 ; Val_Acc: 0.6229652909827383 ; Test_Acc: 0.5721763150938184\n",
            "Training GNN 578 ; Val_Acc: 0.6056997781601481 ; Test_Acc: 0.5721763150938184\n",
            "Training GNN 579 ; Val_Acc: 0.6236504645076517 ; Test_Acc: 0.5754071566644687\n",
            "Training GNN 580 ; Val_Acc: 0.6179568627945691 ; Test_Acc: 0.5754071566644687\n",
            "Training GNN 581 ; Val_Acc: 0.6376951230080892 ; Test_Acc: 0.5775420809163418\n",
            "Training GNN 582 ; Val_Acc: 0.6297443953425826 ; Test_Acc: 0.5811991787727309\n",
            "Training GNN 583 ; Val_Acc: 0.6322331494071015 ; Test_Acc: 0.5811991787727309\n",
            "Training GNN 584 ; Val_Acc: 0.621387198310946 ; Test_Acc: 0.5811991787727309\n",
            "Training GNN 585 ; Val_Acc: 0.6363490822551094 ; Test_Acc: 0.5910052715707311\n",
            "Training GNN 586 ; Val_Acc: 0.6293889223703598 ; Test_Acc: 0.5910052715707311\n",
            "Training GNN 587 ; Val_Acc: 0.6510165098670668 ; Test_Acc: 0.5951323402721049\n",
            "Training GNN 588 ; Val_Acc: 0.6492700086896048 ; Test_Acc: 0.6138222585282358\n",
            "Training GNN 589 ; Val_Acc: 0.6615860979177882 ; Test_Acc: 0.6122623694271204\n",
            "Training GNN 590 ; Val_Acc: 0.6503163997219886 ; Test_Acc: 0.6122623694271204\n",
            "Training GNN 591 ; Val_Acc: 0.6583867779479962 ; Test_Acc: 0.6103063000629585\n",
            "Training GNN 592 ; Val_Acc: 0.6516878989569284 ; Test_Acc: 0.6103063000629585\n",
            "Training GNN 593 ; Val_Acc: 0.6583459718272029 ; Test_Acc: 0.6125835614070859\n",
            "Training GNN 594 ; Val_Acc: 0.6478248038290024 ; Test_Acc: 0.623634782542067\n",
            "Training GNN 595 ; Val_Acc: 0.6547994277164811 ; Test_Acc: 0.623634782542067\n",
            "Training GNN 596 ; Val_Acc: 0.6523173268590701 ; Test_Acc: 0.6283249168747902\n",
            "Training GNN 597 ; Val_Acc: 0.6517871650087077 ; Test_Acc: 0.6283249168747902\n",
            "Training GNN 598 ; Val_Acc: 0.6473987773948896 ; Test_Acc: 0.6281276612518395\n",
            "Training GNN 599 ; Val_Acc: 0.648845857775826 ; Test_Acc: 0.6271215684538392\n",
            "Training GNN 600 ; Val_Acc: 0.6455999235699799 ; Test_Acc: 0.6279965567369199\n",
            "Training GNN 601 ; Val_Acc: 0.6489954703725388 ; Test_Acc: 0.6279965567369199\n",
            "Training GNN 602 ; Val_Acc: 0.6528544144280422 ; Test_Acc: 0.6277154756558389\n",
            "Training GNN 603 ; Val_Acc: 0.65813460520641 ; Test_Acc: 0.6277154756558389\n",
            "Training GNN 604 ; Val_Acc: 0.6524597226739965 ; Test_Acc: 0.6277154756558389\n",
            "Training GNN 605 ; Val_Acc: 0.6552282867932798 ; Test_Acc: 0.6271043654197423\n",
            "Training GNN 606 ; Val_Acc: 0.6467195706650999 ; Test_Acc: 0.6270554173458082\n",
            "Training GNN 607 ; Val_Acc: 0.6556240959705611 ; Test_Acc: 0.6280703473188581\n",
            "Training GNN 608 ; Val_Acc: 0.6560578921344508 ; Test_Acc: 0.6287953590357774\n",
            "Training GNN 609 ; Val_Acc: 0.653121446881392 ; Test_Acc: 0.6287953590357774\n",
            "Training GNN 610 ; Val_Acc: 0.6448788273375846 ; Test_Acc: 0.6272615101438085\n",
            "Training GNN 611 ; Val_Acc: 0.6528785204388418 ; Test_Acc: 0.6281625386360357\n",
            "Training GNN 612 ; Val_Acc: 0.6513943060881319 ; Test_Acc: 0.6281625386360357\n",
            "Training GNN 613 ; Val_Acc: 0.663117122287766 ; Test_Acc: 0.6224354699346619\n",
            "Training GNN 614 ; Val_Acc: 0.6468101013994227 ; Test_Acc: 0.6196794005705002\n",
            "Training GNN 615 ; Val_Acc: 0.6486745076588918 ; Test_Acc: 0.6196794005705002\n",
            "Training GNN 616 ; Val_Acc: 0.6520964570976013 ; Test_Acc: 0.6194243596985655\n",
            "Training GNN 617 ; Val_Acc: 0.6519951826018343 ; Test_Acc: 0.6194243596985655\n",
            "Training GNN 618 ; Val_Acc: 0.6448733684621133 ; Test_Acc: 0.6194243596985655\n",
            "Training GNN 619 ; Val_Acc: 0.6457453996834518 ; Test_Acc: 0.6116750705249989\n",
            "Training GNN 620 ; Val_Acc: 0.6420194666366711 ; Test_Acc: 0.6116750705249989\n",
            "Training GNN 621 ; Val_Acc: 0.6343585555834234 ; Test_Acc: 0.61334122163303\n",
            "Training GNN 622 ; Val_Acc: 0.6293655861640265 ; Test_Acc: 0.6108662333499492\n",
            "Training GNN 623 ; Val_Acc: 0.6516024693929596 ; Test_Acc: 0.6097101639857874\n",
            "Training GNN 624 ; Val_Acc: 0.6333889823553106 ; Test_Acc: 0.6107912450668684\n",
            "Training GNN 625 ; Val_Acc: 0.6457303258169128 ; Test_Acc: 0.6080440128777562\n",
            "Training GNN 626 ; Val_Acc: 0.6382084583088848 ; Test_Acc: 0.6027608748122206\n",
            "Training GNN 627 ; Val_Acc: 0.6442251565384953 ; Test_Acc: 0.5993588178277662\n",
            "Training GNN 628 ; Val_Acc: 0.6363656915879737 ; Test_Acc: 0.5993588178277662\n",
            "Training GNN 629 ; Val_Acc: 0.6408225287596174 ; Test_Acc: 0.6057318741494326\n",
            "Training GNN 630 ; Val_Acc: 0.6337524727131694 ; Test_Acc: 0.6019162567837876\n",
            "Training GNN 631 ; Val_Acc: 0.6425554382233141 ; Test_Acc: 0.6019162567837876\n",
            "Training GNN 632 ; Val_Acc: 0.6303044655553787 ; Test_Acc: 0.6199115335776468\n",
            "Training GNN 633 ; Val_Acc: 0.6337342185851751 ; Test_Acc: 0.6199115335776468\n",
            "Training GNN 634 ; Val_Acc: 0.638295049243747 ; Test_Acc: 0.625134657519027\n",
            "Training GNN 635 ; Val_Acc: 0.6476526442826646 ; Test_Acc: 0.6276268488362045\n",
            "Training GNN 636 ; Val_Acc: 0.6478256431572226 ; Test_Acc: 0.6299389875645283\n",
            "Training GNN 637 ; Val_Acc: 0.6454205312117673 ; Test_Acc: 0.6299389875645283\n",
            "Training GNN 638 ; Val_Acc: 0.6517127299239697 ; Test_Acc: 0.6342549460298055\n",
            "Training GNN 639 ; Val_Acc: 0.6443501777189251 ; Test_Acc: 0.6326200686456093\n",
            "Training GNN 640 ; Val_Acc: 0.6350132784246012 ; Test_Acc: 0.6323301503894785\n",
            "Training GNN 641 ; Val_Acc: 0.6347710486604966 ; Test_Acc: 0.6309851912614131\n",
            "Training GNN 642 ; Val_Acc: 0.6341785971289456 ; Test_Acc: 0.6309851912614131\n",
            "Training GNN 643 ; Val_Acc: 0.644687048404044 ; Test_Acc: 0.6337360271108866\n",
            "Training GNN 644 ; Val_Acc: 0.636947289128709 ; Test_Acc: 0.6284920964750484\n",
            "Training GNN 645 ; Val_Acc: 0.641932025566788 ; Test_Acc: 0.6284920964750484\n",
            "Training GNN 646 ; Val_Acc: 0.6394811882446703 ; Test_Acc: 0.6284920964750484\n",
            "Training GNN 647 ; Val_Acc: 0.6487786722535044 ; Test_Acc: 0.6313007175735058\n",
            "Training GNN 648 ; Val_Acc: 0.6519722907351402 ; Test_Acc: 0.6291734327955398\n",
            "Training GNN 649 ; Val_Acc: 0.6553386143264569 ; Test_Acc: 0.6291734327955398\n",
            "Training GNN 650 ; Val_Acc: 0.649440270381553 ; Test_Acc: 0.6265312649122008\n",
            "Training GNN 651 ; Val_Acc: 0.6471034053664023 ; Test_Acc: 0.6265312649122008\n",
            "Training GNN 652 ; Val_Acc: 0.6399435428214201 ; Test_Acc: 0.6243201546761044\n",
            "Training GNN 653 ; Val_Acc: 0.6295699335873801 ; Test_Acc: 0.6218279633589268\n",
            "Training GNN 654 ; Val_Acc: 0.6309443387711404 ; Test_Acc: 0.6218279633589268\n",
            "Training GNN 655 ; Val_Acc: 0.633228294048246 ; Test_Acc: 0.6175597552664412\n",
            "Training GNN 656 ; Val_Acc: 0.6308531149606393 ; Test_Acc: 0.6125488611069371\n",
            "Training GNN 657 ; Val_Acc: 0.6453240070255446 ; Test_Acc: 0.6128700530869027\n",
            "Training GNN 658 ; Val_Acc: 0.6317939026529553 ; Test_Acc: 0.6101801348307719\n",
            "Training GNN 659 ; Val_Acc: 0.6365744845690806 ; Test_Acc: 0.6101801348307719\n",
            "Training GNN 660 ; Val_Acc: 0.6337351434672375 ; Test_Acc: 0.6101801348307719\n",
            "Training GNN 661 ; Val_Acc: 0.6505782411284214 ; Test_Acc: 0.6167821918152264\n",
            "Training GNN 662 ; Val_Acc: 0.6454733663828846 ; Test_Acc: 0.6167821918152264\n",
            "Training GNN 663 ; Val_Acc: 0.6474312583163286 ; Test_Acc: 0.6167910289902762\n",
            "Training GNN 664 ; Val_Acc: 0.6463196657101951 ; Test_Acc: 0.6139339311338871\n",
            "Training GNN 665 ; Val_Acc: 0.6538620578551322 ; Test_Acc: 0.6124879435135944\n",
            "Training GNN 666 ; Val_Acc: 0.652378673646861 ; Test_Acc: 0.6176395057482078\n",
            "Training GNN 667 ; Val_Acc: 0.6447787401490335 ; Test_Acc: 0.6196044122874194\n",
            "Training GNN 668 ; Val_Acc: 0.657344817523957 ; Test_Acc: 0.6273493714154847\n",
            "Training GNN 669 ; Val_Acc: 0.6566806985294344 ; Test_Acc: 0.6273493714154847\n",
            "Training GNN 670 ; Val_Acc: 0.6383871631744333 ; Test_Acc: 0.6241410055564377\n",
            "Training GNN 671 ; Val_Acc: 0.6396047337564071 ; Test_Acc: 0.6241410055564377\n",
            "Training GNN 672 ; Val_Acc: 0.638466966357513 ; Test_Acc: 0.6241410055564377\n",
            "Training GNN 673 ; Val_Acc: 0.6508878444531869 ; Test_Acc: 0.6225410055564378\n",
            "Training GNN 674 ; Val_Acc: 0.6351125551030683 ; Test_Acc: 0.6172979783897866\n",
            "Training GNN 675 ; Val_Acc: 0.6258102271257464 ; Test_Acc: 0.6172979783897866\n",
            "Training GNN 676 ; Val_Acc: 0.6302413651839923 ; Test_Acc: 0.6150608279445438\n",
            "Training GNN 677 ; Val_Acc: 0.636686922130175 ; Test_Acc: 0.6150608279445438\n",
            "Training GNN 678 ; Val_Acc: 0.6322669224617277 ; Test_Acc: 0.6110087475262509\n",
            "Training GNN 679 ; Val_Acc: 0.6464265202977192 ; Test_Acc: 0.6176669207425441\n",
            "Training GNN 680 ; Val_Acc: 0.6221455699020964 ; Test_Acc: 0.612637920079756\n",
            "Training GNN 681 ; Val_Acc: 0.6335712383357064 ; Test_Acc: 0.612637920079756\n",
            "Training GNN 682 ; Val_Acc: 0.6188861140465783 ; Test_Acc: 0.6158639602889024\n",
            "Training GNN 683 ; Val_Acc: 0.6314301761664922 ; Test_Acc: 0.6172349596261143\n",
            "Training GNN 684 ; Val_Acc: 0.618254269203367 ; Test_Acc: 0.6172349596261143\n",
            "Training GNN 685 ; Val_Acc: 0.6379092720199436 ; Test_Acc: 0.6166238493900178\n",
            "Training GNN 686 ; Val_Acc: 0.629270495680086 ; Test_Acc: 0.6160877274370022\n",
            "Training GNN 687 ; Val_Acc: 0.6349187243182224 ; Test_Acc: 0.6063389485719832\n",
            "Training GNN 688 ; Val_Acc: 0.6375335386370985 ; Test_Acc: 0.6063389485719832\n",
            "Training GNN 689 ; Val_Acc: 0.634342783417419 ; Test_Acc: 0.6063389485719832\n",
            "Training GNN 690 ; Val_Acc: 0.642283459497093 ; Test_Acc: 0.6065061281722415\n",
            "Training GNN 691 ; Val_Acc: 0.6362375888482054 ; Test_Acc: 0.6065061281722415\n",
            "Training GNN 692 ; Val_Acc: 0.6360219389517899 ; Test_Acc: 0.6023301113969335\n",
            "Training GNN 693 ; Val_Acc: 0.6400924230772436 ; Test_Acc: 0.6012401931408027\n",
            "Training GNN 694 ; Val_Acc: 0.6399049848754856 ; Test_Acc: 0.60000913549356\n",
            "Training GNN 695 ; Val_Acc: 0.6468068107284821 ; Test_Acc: 0.60000913549356\n",
            "Training GNN 696 ; Val_Acc: 0.6292132344034572 ; Test_Acc: 0.5997368915875287\n",
            "Training GNN 697 ; Val_Acc: 0.629859659242397 ; Test_Acc: 0.5997368915875287\n",
            "Training GNN 698 ; Val_Acc: 0.6305416986148729 ; Test_Acc: 0.5960408805333975\n",
            "Training GNN 699 ; Val_Acc: 0.6394491006907917 ; Test_Acc: 0.5900367665644887\n",
            "Training GNN 700 ; Val_Acc: 0.6333001763864465 ; Test_Acc: 0.5900367665644887\n",
            "Training GNN 701 ; Val_Acc: 0.6318786969571313 ; Test_Acc: 0.5912651240205571\n",
            "Training GNN 702 ; Val_Acc: 0.6151075048687702 ; Test_Acc: 0.5814855035848877\n",
            "Training GNN 703 ; Val_Acc: 0.6129832683485561 ; Test_Acc: 0.5814855035848877\n",
            "Training GNN 704 ; Val_Acc: 0.6078508079823731 ; Test_Acc: 0.5814855035848877\n",
            "Training GNN 705 ; Val_Acc: 0.6200111301406072 ; Test_Acc: 0.5921255702978971\n",
            "Training GNN 706 ; Val_Acc: 0.6159404041229215 ; Test_Acc: 0.5921255702978971\n",
            "Training GNN 707 ; Val_Acc: 0.622513017710524 ; Test_Acc: 0.6119128692000186\n",
            "Training GNN 708 ; Val_Acc: 0.6399940878512672 ; Test_Acc: 0.6211255261120219\n",
            "Training GNN 709 ; Val_Acc: 0.6346681987132399 ; Test_Acc: 0.6211255261120219\n",
            "Training GNN 710 ; Val_Acc: 0.6517108257656127 ; Test_Acc: 0.631379447438177\n",
            "Training GNN 711 ; Val_Acc: 0.6584537228388795 ; Test_Acc: 0.641792614658728\n",
            "Training GNN 712 ; Val_Acc: 0.6526377558968554 ; Test_Acc: 0.641792614658728\n",
            "Training GNN 713 ; Val_Acc: 0.6698360605028416 ; Test_Acc: 0.6412794005705001\n",
            "Training GNN 714 ; Val_Acc: 0.658410162064481 ; Test_Acc: 0.6395872092533226\n",
            "Training GNN 715 ; Val_Acc: 0.6652413688943274 ; Test_Acc: 0.6407043654197424\n",
            "Training GNN 716 ; Val_Acc: 0.6533397068003907 ; Test_Acc: 0.6392010638664684\n",
            "Training GNN 717 ; Val_Acc: 0.6575879129128315 ; Test_Acc: 0.6392010638664684\n",
            "Training GNN 718 ; Val_Acc: 0.6442771783177156 ; Test_Acc: 0.6491920106148265\n",
            "Training GNN 719 ; Val_Acc: 0.6591049712934979 ; Test_Acc: 0.6388710347114531\n",
            "Training GNN 720 ; Val_Acc: 0.6624827097486083 ; Test_Acc: 0.6388710347114531\n",
            "Training GNN 721 ; Val_Acc: 0.6521736670086393 ; Test_Acc: 0.6388710347114531\n",
            "Training GNN 722 ; Val_Acc: 0.6465744201965683 ; Test_Acc: 0.638804883603422\n",
            "Training GNN 723 ; Val_Acc: 0.6525640540535732 ; Test_Acc: 0.6410680742578114\n",
            "Training GNN 724 ; Val_Acc: 0.6406932770767768 ; Test_Acc: 0.6418680742578114\n",
            "Training GNN 725 ; Val_Acc: 0.6562146923345867 ; Test_Acc: 0.640456964021715\n",
            "Training GNN 726 ; Val_Acc: 0.6492615741614456 ; Test_Acc: 0.640456964021715\n",
            "Training GNN 727 ; Val_Acc: 0.6459881476336696 ; Test_Acc: 0.6414329807970229\n",
            "Training GNN 728 ; Val_Acc: 0.6573097865576812 ; Test_Acc: 0.6222458537856185\n",
            "Training GNN 729 ; Val_Acc: 0.6612577862191545 ; Test_Acc: 0.6222458537856185\n",
            "Training GNN 730 ; Val_Acc: 0.6509457337850741 ; Test_Acc: 0.6222458537856185\n",
            "Training GNN 731 ; Val_Acc: 0.6555806184085313 ; Test_Acc: 0.6195647727045375\n",
            "Training GNN 732 ; Val_Acc: 0.6554915284009111 ; Test_Acc: 0.6160748544484067\n",
            "Training GNN 733 ; Val_Acc: 0.6629846526997792 ; Test_Acc: 0.6165448252933913\n",
            "Training GNN 734 ; Val_Acc: 0.653821269385447 ; Test_Acc: 0.6165448252933913\n",
            "Training GNN 735 ; Val_Acc: 0.6609032655062232 ; Test_Acc: 0.6165448252933913\n",
            "Training GNN 736 ; Val_Acc: 0.6625707862583976 ; Test_Acc: 0.6106019231497803\n",
            "Training GNN 737 ; Val_Acc: 0.6751161696898609 ; Test_Acc: 0.6117579925139423\n",
            "Training GNN 738 ; Val_Acc: 0.6642831174114059 ; Test_Acc: 0.6178725813873599\n",
            "Training GNN 739 ; Val_Acc: 0.6472223884268208 ; Test_Acc: 0.6277276222592945\n",
            "Training GNN 740 ; Val_Acc: 0.6503198881573894 ; Test_Acc: 0.637138732495391\n",
            "Training GNN 741 ; Val_Acc: 0.6541467217846186 ; Test_Acc: 0.6275038551111949\n",
            "Training GNN 742 ; Val_Acc: 0.6534678540281571 ; Test_Acc: 0.6268839077000485\n",
            "Training GNN 743 ; Val_Acc: 0.6492517399724288 ; Test_Acc: 0.6268839077000485\n",
            "Training GNN 744 ; Val_Acc: 0.6506611998974277 ; Test_Acc: 0.6243568389986749\n",
            "Training GNN 745 ; Val_Acc: 0.6523933581083332 ; Test_Acc: 0.6271301113969334\n",
            "Training GNN 746 ; Val_Acc: 0.6384126492137358 ; Test_Acc: 0.6271301113969334\n",
            "Training GNN 747 ; Val_Acc: 0.6509276057364258 ; Test_Acc: 0.6271301113969334\n",
            "Training GNN 748 ; Val_Acc: 0.6419989148026456 ; Test_Acc: 0.6196349596261144\n",
            "Training GNN 749 ; Val_Acc: 0.6438507986813196 ; Test_Acc: 0.6097755887086784\n",
            "Training GNN 750 ; Val_Acc: 0.642048632031527 ; Test_Acc: 0.6097755887086784\n",
            "Training GNN 751 ; Val_Acc: 0.6420814641740026 ; Test_Acc: 0.6123905186817284\n",
            "Training GNN 752 ; Val_Acc: 0.6429185081966093 ; Test_Acc: 0.6123905186817284\n",
            "Training GNN 753 ; Val_Acc: 0.6506831602178654 ; Test_Acc: 0.6146276691269714\n",
            "Training GNN 754 ; Val_Acc: 0.6476095944898458 ; Test_Acc: 0.6128127391539213\n",
            "Training GNN 755 ; Val_Acc: 0.6465466117757058 ; Test_Acc: 0.6105178034596944\n",
            "Training GNN 756 ; Val_Acc: 0.649992153902162 ; Test_Acc: 0.6105178034596944\n",
            "Training GNN 757 ; Val_Acc: 0.647955260650281 ; Test_Acc: 0.6185178034596944\n",
            "Training GNN 758 ; Val_Acc: 0.6455013473523382 ; Test_Acc: 0.6247160407071954\n",
            "Training GNN 759 ; Val_Acc: 0.6556814453226186 ; Test_Acc: 0.6247160407071954\n",
            "Training GNN 760 ; Val_Acc: 0.6509699626331795 ; Test_Acc: 0.6287420809163419\n",
            "Training GNN 761 ; Val_Acc: 0.6655053287940059 ; Test_Acc: 0.6288170691994226\n",
            "Training GNN 762 ; Val_Acc: 0.656050907158548 ; Test_Acc: 0.629295877219457\n",
            "Training GNN 763 ; Val_Acc: 0.6652432555816893 ; Test_Acc: 0.6304519465836188\n",
            "Training GNN 764 ; Val_Acc: 0.6572888190220391 ; Test_Acc: 0.6304519465836188\n",
            "Training GNN 765 ; Val_Acc: 0.6689638023386795 ; Test_Acc: 0.6304519465836188\n",
            "Training GNN 766 ; Val_Acc: 0.6593374742161431 ; Test_Acc: 0.6291819757386342\n",
            "Training GNN 767 ; Val_Acc: 0.6398342403133291 ; Test_Acc: 0.6169226048211984\n",
            "Training GNN 768 ; Val_Acc: 0.6416614567678856 ; Test_Acc: 0.6169226048211984\n",
            "Training GNN 769 ; Val_Acc: 0.6413051947190681 ; Test_Acc: 0.618953662468441\n",
            "Training GNN 770 ; Val_Acc: 0.63446955583997 ; Test_Acc: 0.621634743549522\n",
            "Training GNN 771 ; Val_Acc: 0.6373396476943932 ; Test_Acc: 0.6304696209337182\n",
            "Training GNN 772 ; Val_Acc: 0.6242614941911176 ; Test_Acc: 0.6214057428867339\n",
            "Training GNN 773 ; Val_Acc: 0.6362770325916046 ; Test_Acc: 0.6220517305070266\n",
            "Training GNN 774 ; Val_Acc: 0.6302091758660703 ; Test_Acc: 0.6323996500887337\n",
            "Training GNN 775 ; Val_Acc: 0.6249759237079033 ; Test_Acc: 0.6203736098795871\n",
            "Training GNN 776 ; Val_Acc: 0.6147249338427447 ; Test_Acc: 0.6173015820501481\n",
            "Training GNN 777 ; Val_Acc: 0.6295518611937577 ; Test_Acc: 0.6173015820501481\n",
            "Training GNN 778 ; Val_Acc: 0.6074660536222954 ; Test_Acc: 0.6067427683089368\n",
            "Training GNN 779 ; Val_Acc: 0.5980839375914152 ; Test_Acc: 0.6047606587356285\n",
            "Training GNN 780 ; Val_Acc: 0.5908842255076516 ; Test_Acc: 0.6047606587356285\n",
            "Training GNN 781 ; Val_Acc: 0.6051823856259859 ; Test_Acc: 0.6043568389986749\n",
            "Training GNN 782 ; Val_Acc: 0.623353422288052 ; Test_Acc: 0.6035969498975594\n",
            "Training GNN 783 ; Val_Acc: 0.6275420519468377 ; Test_Acc: 0.6035969498975594\n",
            "Training GNN 784 ; Val_Acc: 0.6261236506547074 ; Test_Acc: 0.6134691938035909\n",
            "Training GNN 785 ; Val_Acc: 0.6365613723170577 ; Test_Acc: 0.5985903857835565\n",
            "Training GNN 786 ; Val_Acc: 0.6348352244887071 ; Test_Acc: 0.6023613851207684\n",
            "Training GNN 787 ; Val_Acc: 0.6384500681228322 ; Test_Acc: 0.601504071187787\n",
            "Training GNN 788 ; Val_Acc: 0.639374238016956 ; Test_Acc: 0.601504071187787\n",
            "Training GNN 789 ; Val_Acc: 0.6399979597479944 ; Test_Acc: 0.6017851522688681\n",
            "Training GNN 790 ; Val_Acc: 0.6390392430322843 ; Test_Acc: 0.6023301113969335\n",
            "Training GNN 791 ; Val_Acc: 0.6399033022565515 ; Test_Acc: 0.6023301113969335\n",
            "Training GNN 792 ; Val_Acc: 0.6379413397613531 ; Test_Acc: 0.5966422501252572\n",
            "Training GNN 793 ; Val_Acc: 0.6407953910808777 ; Test_Acc: 0.5966422501252572\n",
            "Training GNN 794 ; Val_Acc: 0.6288107768821286 ; Test_Acc: 0.6046422501252572\n",
            "Training GNN 795 ; Val_Acc: 0.6475909651857389 ; Test_Acc: 0.6025374018960764\n",
            "Training GNN 796 ; Val_Acc: 0.6451407348456174 ; Test_Acc: 0.6025374018960764\n",
            "Training GNN 797 ; Val_Acc: 0.6469027952951021 ; Test_Acc: 0.6025374018960764\n",
            "Training GNN 798 ; Val_Acc: 0.6281566455331986 ; Test_Acc: 0.6020273201522072\n",
            "Training GNN 799 ; Val_Acc: 0.6339634740640843 ; Test_Acc: 0.6020273201522072\n",
            "Training GNN 800 ; Val_Acc: 0.6331691323956407 ; Test_Acc: 0.6020273201522072\n",
            "Training GNN 801 ; Val_Acc: 0.6426213939316688 ; Test_Acc: 0.6006162099161108\n",
            "Training GNN 802 ; Val_Acc: 0.6428605959903267 ; Test_Acc: 0.601161169044176\n",
            "Training GNN 803 ; Val_Acc: 0.6455750681075229 ; Test_Acc: 0.601161169044176\n",
            "Training GNN 804 ; Val_Acc: 0.6453793346052267 ; Test_Acc: 0.6090861807610953\n",
            "Training GNN 805 ; Val_Acc: 0.6458319000212973 ; Test_Acc: 0.6090861807610953\n",
            "Training GNN 806 ; Val_Acc: 0.6408685340324286 ; Test_Acc: 0.6096972909971918\n",
            "Training GNN 807 ; Val_Acc: 0.6450211655162384 ; Test_Acc: 0.6121321683813881\n",
            "Training GNN 808 ; Val_Acc: 0.6467996396954874 ; Test_Acc: 0.6121321683813881\n",
            "Training GNN 809 ; Val_Acc: 0.6496997124980246 ; Test_Acc: 0.6121321683813881\n",
            "Training GNN 810 ; Val_Acc: 0.6528849486843734 ; Test_Acc: 0.6049233312063382\n",
            "Training GNN 811 ; Val_Acc: 0.6595156376609558 ; Test_Acc: 0.6054682903344036\n",
            "Training GNN 812 ; Val_Acc: 0.6562797143353251 ; Test_Acc: 0.6134682903344036\n",
            "Training GNN 813 ; Val_Acc: 0.6623776406247426 ; Test_Acc: 0.6154592370827616\n",
            "Training GNN 814 ; Val_Acc: 0.6558133796137234 ; Test_Acc: 0.6170852772919082\n",
            "Training GNN 815 ; Val_Acc: 0.6655520278634492 ; Test_Acc: 0.6170852772919082\n",
            "Training GNN 816 ; Val_Acc: 0.6600149313248322 ; Test_Acc: 0.6264963875280046\n",
            "Training GNN 817 ; Val_Acc: 0.6556766665551645 ; Test_Acc: 0.6248703473188582\n",
            "Training GNN 818 ; Val_Acc: 0.6591060552156499 ; Test_Acc: 0.6239781560016806\n",
            "Training GNN 819 ; Val_Acc: 0.6549155487757365 ; Test_Acc: 0.6239781560016806\n",
            "Training GNN 820 ; Val_Acc: 0.6504309777501582 ; Test_Acc: 0.6234331968736153\n",
            "Training GNN 821 ; Val_Acc: 0.6603471572468308 ; Test_Acc: 0.6223521157925342\n",
            "Training GNN 822 ; Val_Acc: 0.6548104346235326 ; Test_Acc: 0.6223521157925342\n",
            "Training GNN 823 ; Val_Acc: 0.6617733019721886 ; Test_Acc: 0.611099131905054\n",
            "Training GNN 824 ; Val_Acc: 0.6508529220952621 ; Test_Acc: 0.6207251721142005\n",
            "Training GNN 825 ; Val_Acc: 0.6646535318668542 ; Test_Acc: 0.6207251721142005\n",
            "Training GNN 826 ; Val_Acc: 0.655758446842509 ; Test_Acc: 0.6207251721142005\n",
            "Training GNN 827 ; Val_Acc: 0.6468976116328329 ; Test_Acc: 0.622070131242266\n",
            "Training GNN 828 ; Val_Acc: 0.6449381633399144 ; Test_Acc: 0.622070131242266\n",
            "Training GNN 829 ; Val_Acc: 0.6502490113920326 ; Test_Acc: 0.6243072816875088\n",
            "Training GNN 830 ; Val_Acc: 0.6558068973341863 ; Test_Acc: 0.6243072816875088\n",
            "Training GNN 831 ; Val_Acc: 0.6532447809400536 ; Test_Acc: 0.6240610779906239\n",
            "Training GNN 832 ; Val_Acc: 0.6396508013484382 ; Test_Acc: 0.6240610779906239\n",
            "Training GNN 833 ; Val_Acc: 0.6612982875881562 ; Test_Acc: 0.6242499677545275\n",
            "Training GNN 834 ; Val_Acc: 0.6464929617717843 ; Test_Acc: 0.6242499677545275\n",
            "Training GNN 835 ; Val_Acc: 0.6569357015722334 ; Test_Acc: 0.6253310488356085\n",
            "Training GNN 836 ; Val_Acc: 0.650088360008205 ; Test_Acc: 0.6231688866734464\n",
            "Training GNN 837 ; Val_Acc: 0.6519010369925377 ; Test_Acc: 0.6231688866734464\n",
            "Training GNN 838 ; Val_Acc: 0.6486148310622133 ; Test_Acc: 0.6151688866734464\n",
            "Training GNN 839 ; Val_Acc: 0.6510709565123445 ; Test_Acc: 0.6146239275453811\n",
            "Training GNN 840 ; Val_Acc: 0.6571850915625318 ; Test_Acc: 0.6146239275453811\n",
            "Training GNN 841 ; Val_Acc: 0.6599957726675842 ; Test_Acc: 0.6146239275453811\n",
            "Training GNN 842 ; Val_Acc: 0.6371210313310707 ; Test_Acc: 0.6149451195253467\n",
            "Training GNN 843 ; Val_Acc: 0.6501111472290415 ; Test_Acc: 0.6165623225594434\n",
            "Training GNN 844 ; Val_Acc: 0.644569033813119 ; Test_Acc: 0.6165623225594434\n",
            "Training GNN 845 ; Val_Acc: 0.6444084627598462 ; Test_Acc: 0.6165711597344932\n",
            "Training GNN 846 ; Val_Acc: 0.6467824476959291 ; Test_Acc: 0.6143251721142005\n",
            "Training GNN 847 ; Val_Acc: 0.6540122156549613 ; Test_Acc: 0.6206241436219733\n",
            "Training GNN 848 ; Val_Acc: 0.6450016228573238 ; Test_Acc: 0.6218062531952816\n",
            "Training GNN 849 ; Val_Acc: 0.6461074579600486 ; Test_Acc: 0.6218062531952816\n",
            "Training GNN 850 ; Val_Acc: 0.6450175614480654 ; Test_Acc: 0.6218062531952816\n",
            "Training GNN 851 ; Val_Acc: 0.6513050952244526 ; Test_Acc: 0.6198506551471223\n",
            "Training GNN 852 ; Val_Acc: 0.6413500744635426 ; Test_Acc: 0.6191296792437491\n",
            "Training GNN 853 ; Val_Acc: 0.6414421084239006 ; Test_Acc: 0.6168748544484066\n",
            "Training GNN 854 ; Val_Acc: 0.6451456733736148 ; Test_Acc: 0.6145538785450333\n",
            "Training GNN 855 ; Val_Acc: 0.6501624842172974 ; Test_Acc: 0.6141978091808713\n",
            "Training GNN 856 ; Val_Acc: 0.640978105990094 ; Test_Acc: 0.6153627157200829\n",
            "Training GNN 857 ; Val_Acc: 0.6417256340370028 ; Test_Acc: 0.6137366755109365\n",
            "Training GNN 858 ; Val_Acc: 0.64091038625157 ; Test_Acc: 0.6137366755109365\n",
            "Training GNN 859 ; Val_Acc: 0.6360969714725162 ; Test_Acc: 0.6129366755109366\n",
            "Training GNN 860 ; Val_Acc: 0.6386250698578642 ; Test_Acc: 0.6173536624684409\n",
            "Training GNN 861 ; Val_Acc: 0.6406024754519732 ; Test_Acc: 0.6154725813873598\n",
            "Training GNN 862 ; Val_Acc: 0.6425174094504079 ; Test_Acc: 0.6253536624684409\n",
            "Training GNN 863 ; Val_Acc: 0.6497248923446286 ; Test_Acc: 0.6253536624684409\n",
            "Training GNN 864 ; Val_Acc: 0.637664711228838 ; Test_Acc: 0.6244786741853602\n",
            "Training GNN 865 ; Val_Acc: 0.6491951420532756 ; Test_Acc: 0.6232832203074536\n",
            "Training GNN 866 ; Val_Acc: 0.64531844800705 ; Test_Acc: 0.6337353007257466\n",
            "Training GNN 867 ; Val_Acc: 0.6501231308908011 ; Test_Acc: 0.6337353007257466\n",
            "Training GNN 868 ; Val_Acc: 0.6488865052167564 ; Test_Acc: 0.6365262474741047\n",
            "Training GNN 869 ; Val_Acc: 0.6477336994336539 ; Test_Acc: 0.6365262474741047\n",
            "Training GNN 870 ; Val_Acc: 0.6483441228555769 ; Test_Acc: 0.6355113175010547\n",
            "Training GNN 871 ; Val_Acc: 0.6596675955136244 ; Test_Acc: 0.6282451663930236\n",
            "Training GNN 872 ; Val_Acc: 0.6461761809299428 ; Test_Acc: 0.6264779867927652\n",
            "Training GNN 873 ; Val_Acc: 0.6552302561526704 ; Test_Acc: 0.6267330276646998\n",
            "Training GNN 874 ; Val_Acc: 0.6559780957956782 ; Test_Acc: 0.6267330276646998\n",
            "Training GNN 875 ; Val_Acc: 0.649613284565746 ; Test_Acc: 0.6218059589633261\n",
            "Training GNN 876 ; Val_Acc: 0.651327772396031 ; Test_Acc: 0.6229792313615847\n",
            "Training GNN 877 ; Val_Acc: 0.6571776631475567 ; Test_Acc: 0.6229792313615847\n",
            "Training GNN 878 ; Val_Acc: 0.651636512077274 ; Test_Acc: 0.6249353007257465\n",
            "Training GNN 879 ; Val_Acc: 0.644501802181779 ; Test_Acc: 0.6338014518337777\n",
            "Training GNN 880 ; Val_Acc: 0.6566911845486721 ; Test_Acc: 0.6364913700899085\n",
            "Training GNN 881 ; Val_Acc: 0.6585920700658806 ; Test_Acc: 0.6364913700899085\n",
            "Training GNN 882 ; Val_Acc: 0.6492849143302729 ; Test_Acc: 0.6380913700899085\n",
            "Training GNN 883 ; Val_Acc: 0.6506699341342043 ; Test_Acc: 0.6370014518337777\n",
            "Training GNN 884 ; Val_Acc: 0.638614315469732 ; Test_Acc: 0.6347982753035437\n",
            "Training GNN 885 ; Val_Acc: 0.6579846403079807 ; Test_Acc: 0.6347982753035437\n",
            "Training GNN 886 ; Val_Acc: 0.6536196465367686 ; Test_Acc: 0.6333611248583008\n",
            "Training GNN 887 ; Val_Acc: 0.657828307141766 ; Test_Acc: 0.6333611248583008\n",
            "Training GNN 888 ; Val_Acc: 0.6488625519420793 ; Test_Acc: 0.6357871650674473\n",
            "Training GNN 889 ; Val_Acc: 0.6631502436922845 ; Test_Acc: 0.6344422059393818\n",
            "Training GNN 890 ; Val_Acc: 0.6621786405866952 ; Test_Acc: 0.6355982753035438\n",
            "Training GNN 891 ; Val_Acc: 0.6682118629555545 ; Test_Acc: 0.6355982753035438\n",
            "Training GNN 892 ; Val_Acc: 0.6596715257670773 ; Test_Acc: 0.6367543446677056\n",
            "Training GNN 893 ; Val_Acc: 0.6712082402060249 ; Test_Acc: 0.6367543446677056\n",
            "Training GNN 894 ; Val_Acc: 0.6577426243384247 ; Test_Acc: 0.637299303795771\n",
            "Training GNN 895 ; Val_Acc: 0.6728002252007671 ; Test_Acc: 0.637299303795771\n",
            "Training GNN 896 ; Val_Acc: 0.6603229201135108 ; Test_Acc: 0.6340732635866245\n",
            "Training GNN 897 ; Val_Acc: 0.6634394736753564 ; Test_Acc: 0.6329573051213473\n",
            "Training GNN 898 ; Val_Acc: 0.6567852420825396 ; Test_Acc: 0.6344782810247207\n",
            "Training GNN 899 ; Val_Acc: 0.6644043617949583 ; Test_Acc: 0.6344782810247207\n",
            "Training GNN 900 ; Val_Acc: 0.6457525788215474 ; Test_Acc: 0.6322583336135745\n",
            "Training GNN 901 ; Val_Acc: 0.6484300090068922 ; Test_Acc: 0.6308472233774781\n",
            "Training GNN 902 ; Val_Acc: 0.6504130395409827 ; Test_Acc: 0.6308472233774781\n",
            "Training GNN 903 ; Val_Acc: 0.6542554688231313 ; Test_Acc: 0.628922427737151\n",
            "Training GNN 904 ; Val_Acc: 0.6449036860420816 ; Test_Acc: 0.628922427737151\n",
            "Training GNN 905 ; Val_Acc: 0.6578664310145224 ; Test_Acc: 0.6148132494624691\n",
            "Training GNN 906 ; Val_Acc: 0.651556524998462 ; Test_Acc: 0.6148132494624691\n",
            "Training GNN 907 ; Val_Acc: 0.6500465203969978 ; Test_Acc: 0.6148044122874193\n",
            "Training GNN 908 ; Val_Acc: 0.6549191713955848 ; Test_Acc: 0.6145493714154847\n",
            "Training GNN 909 ; Val_Acc: 0.6484063675084273 ; Test_Acc: 0.6158193422604693\n",
            "Training GNN 910 ; Val_Acc: 0.6514625243804135 ; Test_Acc: 0.6158193422604693\n",
            "Training GNN 911 ; Val_Acc: 0.6569327556382485 ; Test_Acc: 0.614474383132404\n",
            "Training GNN 912 ; Val_Acc: 0.6365090081423556 ; Test_Acc: 0.6164392896716155\n",
            "Training GNN 913 ; Val_Acc: 0.6515657840855458 ; Test_Acc: 0.6181403181638427\n",
            "Training GNN 914 ; Val_Acc: 0.6402966255093487 ; Test_Acc: 0.6192302364199735\n",
            "Training GNN 915 ; Val_Acc: 0.6474003861673492 ; Test_Acc: 0.6192302364199735\n",
            "Training GNN 916 ; Val_Acc: 0.6487007454913251 ; Test_Acc: 0.6192302364199735\n",
            "Training GNN 917 ; Val_Acc: 0.6481738339665124 ; Test_Acc: 0.6214501838311197\n",
            "Training GNN 918 ; Val_Acc: 0.6380602279020352 ; Test_Acc: 0.6219951429591851\n",
            "Training GNN 919 ; Val_Acc: 0.6500506828165616 ; Test_Acc: 0.6219951429591851\n",
            "Training GNN 920 ; Val_Acc: 0.653850813918909 ; Test_Acc: 0.6214100729322352\n",
            "Training GNN 921 ; Val_Acc: 0.6643729287730006 ; Test_Acc: 0.6363602655749889\n",
            "Training GNN 922 ; Val_Acc: 0.6649179942827843 ; Test_Acc: 0.6352703473188581\n",
            "Training GNN 923 ; Val_Acc: 0.6616995261023186 ; Test_Acc: 0.6352703473188581\n",
            "Training GNN 924 ; Val_Acc: 0.6618742382150806 ; Test_Acc: 0.6352703473188581\n",
            "Training GNN 925 ; Val_Acc: 0.6513827152535929 ; Test_Acc: 0.6383163349391509\n",
            "Training GNN 926 ; Val_Acc: 0.6515954132722833 ; Test_Acc: 0.6445222116605589\n",
            "Training GNN 927 ; Val_Acc: 0.6505364303353504 ; Test_Acc: 0.6445222116605589\n",
            "Training GNN 928 ; Val_Acc: 0.6499429852985502 ; Test_Acc: 0.6448121299166896\n",
            "Training GNN 929 ; Val_Acc: 0.6517988983129079 ; Test_Acc: 0.6448121299166896\n",
            "Training GNN 930 ; Val_Acc: 0.6520035272534305 ; Test_Acc: 0.6448121299166896\n",
            "Training GNN 931 ; Val_Acc: 0.6520818081184596 ; Test_Acc: 0.6354411305794778\n",
            "Training GNN 932 ; Val_Acc: 0.6448727477915025 ; Test_Acc: 0.6354411305794778\n",
            "Training GNN 933 ; Val_Acc: 0.659206416176496 ; Test_Acc: 0.6293222116605588\n",
            "Training GNN 934 ; Val_Acc: 0.6562017252539257 ; Test_Acc: 0.6215944555665902\n",
            "Training GNN 935 ; Val_Acc: 0.6554624002895183 ; Test_Acc: 0.6212644264115748\n",
            "Training GNN 936 ; Val_Acc: 0.6499591027418504 ; Test_Acc: 0.6212644264115748\n",
            "Training GNN 937 ; Val_Acc: 0.6669928667764001 ; Test_Acc: 0.6207106301084597\n",
            "Training GNN 938 ; Val_Acc: 0.6653785707805234 ; Test_Acc: 0.6237566177287523\n",
            "Training GNN 939 ; Val_Acc: 0.6555004895805111 ; Test_Acc: 0.6218666994726216\n",
            "Training GNN 940 ; Val_Acc: 0.649746572588804 ; Test_Acc: 0.6238227688367834\n",
            "Training GNN 941 ; Val_Acc: 0.6601385751784593 ; Test_Acc: 0.6238227688367834\n",
            "Training GNN 942 ; Val_Acc: 0.6609518211840982 ; Test_Acc: 0.6232778097087179\n",
            "Training GNN 943 ; Val_Acc: 0.6725574278994906 ; Test_Acc: 0.6226578622975719\n",
            "Training GNN 944 ; Val_Acc: 0.6605063961817526 ; Test_Acc: 0.6226578622975719\n",
            "Training GNN 945 ; Val_Acc: 0.6656290219986919 ; Test_Acc: 0.620420711852329\n",
            "Training GNN 946 ; Val_Acc: 0.6497794706527663 ; Test_Acc: 0.6201656709803942\n",
            "Training GNN 947 ; Val_Acc: 0.6497540267599882 ; Test_Acc: 0.6201656709803942\n",
            "Training GNN 948 ; Val_Acc: 0.6446955987450886 ; Test_Acc: 0.617449712515117\n",
            "Training GNN 949 ; Val_Acc: 0.6536181814947639 ; Test_Acc: 0.6168386022790207\n",
            "Training GNN 950 ; Val_Acc: 0.6346669285538818 ; Test_Acc: 0.6154936431509552\n",
            "Training GNN 951 ; Val_Acc: 0.6383663712493095 ; Test_Acc: 0.6147024803260048\n",
            "Training GNN 952 ; Val_Acc: 0.6406620899095449 ; Test_Acc: 0.612465329880762\n",
            "Training GNN 953 ; Val_Acc: 0.6376664078966131 ; Test_Acc: 0.612465329880762\n",
            "Training GNN 954 ; Val_Acc: 0.6344160789249792 ; Test_Acc: 0.618056964021715\n",
            "Training GNN 955 ; Val_Acc: 0.6426186826853814 ; Test_Acc: 0.6170769114328611\n",
            "Training GNN 956 ; Val_Acc: 0.6347698631544141 ; Test_Acc: 0.6170769114328611\n",
            "Training GNN 957 ; Val_Acc: 0.6419891301448003 ; Test_Acc: 0.6102153064469236\n",
            "Training GNN 958 ; Val_Acc: 0.6402893528924236 ; Test_Acc: 0.6118413466560699\n",
            "Training GNN 959 ; Val_Acc: 0.6389611725396506 ; Test_Acc: 0.6110325094810203\n",
            "Training GNN 960 ; Val_Acc: 0.6430970307874455 ; Test_Acc: 0.6104703473188582\n",
            "Training GNN 961 ; Val_Acc: 0.6458672609552345 ; Test_Acc: 0.6104703473188582\n",
            "Training GNN 962 ; Val_Acc: 0.6477974827948703 ; Test_Acc: 0.6103292079277464\n",
            "Training GNN 963 ; Val_Acc: 0.6493713986380303 ; Test_Acc: 0.6278413466560699\n",
            "Training GNN 964 ; Val_Acc: 0.6383782762015341 ; Test_Acc: 0.6261491553388925\n",
            "Training GNN 965 ; Val_Acc: 0.6423842822685732 ; Test_Acc: 0.6342501838311198\n",
            "Training GNN 966 ; Val_Acc: 0.6466298562044882 ; Test_Acc: 0.6342501838311198\n",
            "Training GNN 967 ; Val_Acc: 0.6436491837576286 ; Test_Acc: 0.6328130333858768\n",
            "Training GNN 968 ; Val_Acc: 0.6326434290711925 ; Test_Acc: 0.6344390735950233\n",
            "Training GNN 969 ; Val_Acc: 0.6341915876243424 ; Test_Acc: 0.6317579925139423\n",
            "Training GNN 970 ; Val_Acc: 0.6351619850511537 ; Test_Acc: 0.6317579925139423\n",
            "Training GNN 971 ; Val_Acc: 0.6428377082662394 ; Test_Acc: 0.6225930859747306\n",
            "Training GNN 972 ; Val_Acc: 0.6432538471977831 ; Test_Acc: 0.615665329880762\n",
            "Training GNN 973 ; Val_Acc: 0.6441864056911611 ; Test_Acc: 0.615665329880762\n",
            "Training GNN 974 ; Val_Acc: 0.6463824015321565 ; Test_Acc: 0.6245575211979395\n",
            "Training GNN 975 ; Val_Acc: 0.6451543733888545 ; Test_Acc: 0.6245575211979395\n",
            "Training GNN 976 ; Val_Acc: 0.6491474037297917 ; Test_Acc: 0.626249712515117\n",
            "Training GNN 977 ; Val_Acc: 0.6518482385645441 ; Test_Acc: 0.6281396307712479\n",
            "Training GNN 978 ; Val_Acc: 0.6562233820833656 ; Test_Acc: 0.6281396307712479\n",
            "Training GNN 979 ; Val_Acc: 0.6584612582411854 ; Test_Acc: 0.629005781879279\n",
            "Training GNN 980 ; Val_Acc: 0.6466834741482331 ; Test_Acc: 0.6312517694995715\n",
            "Training GNN 981 ; Val_Acc: 0.6487076409508915 ; Test_Acc: 0.6304517694995716\n",
            "Training GNN 982 ; Val_Acc: 0.648147986619826 ; Test_Acc: 0.6350098958481879\n",
            "Training GNN 983 ; Val_Acc: 0.6561606230267817 ; Test_Acc: 0.6350098958481879\n",
            "Training GNN 984 ; Val_Acc: 0.6499655641282388 ; Test_Acc: 0.6327639082278952\n",
            "Training GNN 985 ; Val_Acc: 0.6491521070297515 ; Test_Acc: 0.6414889199448145\n",
            "Training GNN 986 ; Val_Acc: 0.6557261554003159 ; Test_Acc: 0.642372745402945\n",
            "Training GNN 987 ; Val_Acc: 0.6522621188746539 ; Test_Acc: 0.642372745402945\n",
            "Training GNN 988 ; Val_Acc: 0.6486527319546397 ; Test_Acc: 0.6375947497985457\n",
            "Training GNN 989 ; Val_Acc: 0.6492654181406035 ; Test_Acc: 0.646139708926611\n",
            "Training GNN 990 ; Val_Acc: 0.6464731309315065 ; Test_Acc: 0.6457435286635647\n",
            "Training GNN 991 ; Val_Acc: 0.6483676838433735 ; Test_Acc: 0.6457435286635647\n",
            "Training GNN 992 ; Val_Acc: 0.6500088749053047 ; Test_Acc: 0.6457435286635647\n",
            "Training GNN 993 ; Val_Acc: 0.6523677492317249 ; Test_Acc: 0.6449564016521602\n",
            "Training GNN 994 ; Val_Acc: 0.6484984983697691 ; Test_Acc: 0.6449564016521602\n",
            "Training GNN 995 ; Val_Acc: 0.6576769166461559 ; Test_Acc: 0.6503543446677056\n",
            "Training GNN 996 ; Val_Acc: 0.6510894429865629 ; Test_Acc: 0.6432161657302354\n",
            "Training GNN 997 ; Val_Acc: 0.6507286618937446 ; Test_Acc: 0.6450972468113165\n",
            "Training GNN 998 ; Val_Acc: 0.6459225064032278 ; Test_Acc: 0.6450972468113165\n",
            "Training GNN 999 ; Val_Acc: 0.6444892598084022 ; Test_Acc: 0.6420512591910239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_cora.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pSmOYlQYxhX",
        "outputId": "8630210c-f9b1-4a81-9813-03a39fa09fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Meta-policy on Validation Set\n",
            "Training Meta-policy: 1 Val_Acc: 0.47799800652649566 Avg_reward: -0.4368660088240784\n",
            "Training Meta-policy: 2 Val_Acc: 0.5468383812759322 Avg_reward: 2.6346240162642576\n",
            "Training Meta-policy: 3 Val_Acc: 0.5777867497200859 Avg_reward: -1.7429231610131977\n",
            "Training Meta-policy: 4 Val_Acc: 0.5946103449065786 Avg_reward: -2.8136680399270393\n",
            "Training Meta-policy: 5 Val_Acc: 0.663215720611324 Avg_reward: -1.8496802558277443\n",
            "Training Meta-policy: 6 Val_Acc: 0.7015622468583692 Avg_reward: 0.4365782985570751\n",
            "Training Meta-policy: 7 Val_Acc: 0.6924345867875289 Avg_reward: -0.9811705738985707\n",
            "Training Meta-policy: 8 Val_Acc: 0.7155742369927476 Avg_reward: 1.0621787075416205\n",
            "Training Meta-policy: 9 Val_Acc: 0.7134956946002228 Avg_reward: 0.718546561352294\n",
            "Training Meta-policy: 10 Val_Acc: 0.7311569675213624 Avg_reward: -1.5091717950334815\n",
            "Training Meta-policy: 11 Val_Acc: 0.7342714381206346 Avg_reward: -0.9927672251993555\n",
            "Training Meta-policy: 12 Val_Acc: 0.7339188123724305 Avg_reward: -0.7367357986892252\n",
            "Training Meta-policy: 13 Val_Acc: 0.7593562952646766 Avg_reward: 0.28253987337056835\n",
            "Training Meta-policy: 14 Val_Acc: 0.7839893282729056 Avg_reward: 1.5892420505591063\n",
            "Training Meta-policy: 15 Val_Acc: 0.7565225397657929 Avg_reward: -1.380652469102269\n",
            "Training Meta-policy: 16 Val_Acc: 0.7809684742324717 Avg_reward: 0.012251539370919847\n",
            "Training Meta-policy: 17 Val_Acc: 0.763397999132422 Avg_reward: -0.5664365729495909\n",
            "Training Meta-policy: 18 Val_Acc: 0.7781887275121732 Avg_reward: 1.0447050248315528\n",
            "Training Meta-policy: 19 Val_Acc: 0.7777571051663069 Avg_reward: 0.20525189818819925\n",
            "Training Meta-policy: 20 Val_Acc: 0.7853327968854152 Avg_reward: -1.9930418614508136\n",
            "Training Meta-policy: 21 Val_Acc: 0.7987909258138117 Avg_reward: 0.29574451920813366\n",
            "Training Meta-policy: 22 Val_Acc: 0.7820602040742716 Avg_reward: -0.12485642963072167\n",
            "Training Meta-policy: 23 Val_Acc: 0.7837773541129306 Avg_reward: -0.25263756432579804\n",
            "Training Meta-policy: 24 Val_Acc: 0.7938407735483798 Avg_reward: -0.6363899592517611\n",
            "Training Meta-policy: 25 Val_Acc: 0.748243010172752 Avg_reward: -1.121805120313714\n",
            "Training Meta-policy: 26 Val_Acc: 0.7251628340618403 Avg_reward: -0.7875265888679089\n",
            "Training Meta-policy: 27 Val_Acc: 0.741312651799875 Avg_reward: 0.940928295972773\n",
            "Training Meta-policy: 28 Val_Acc: 0.7517090711160344 Avg_reward: -0.60904121357462\n",
            "Training Meta-policy: 29 Val_Acc: 0.7335990519896485 Avg_reward: 2.3357269448094535\n",
            "Training Meta-policy: 30 Val_Acc: 0.8209979000993219 Avg_reward: 2.5601740147155287\n",
            "Training Meta-policy: 31 Val_Acc: 0.7595622988747287 Avg_reward: -0.06718971349864473\n",
            "Training Meta-policy: 32 Val_Acc: 0.7101991074897857 Avg_reward: -0.2986231020959479\n",
            "Training Meta-policy: 33 Val_Acc: 0.6874263030889842 Avg_reward: 6.236683517036135\n",
            "Training Meta-policy: 34 Val_Acc: 0.7463264434487455 Avg_reward: -0.5067638231050319\n",
            "Training Meta-policy: 35 Val_Acc: 0.6723862568931032 Avg_reward: 1.3080908907754913\n",
            "Training Meta-policy: 36 Val_Acc: 0.6676458832933653 Avg_reward: -2.171655056906847\n",
            "Training Meta-policy: 37 Val_Acc: 0.6980753095630128 Avg_reward: -0.34357318710067986\n",
            "Training Meta-policy: 38 Val_Acc: 0.7442585840792286 Avg_reward: -0.10546276506871557\n",
            "Training Meta-policy: 39 Val_Acc: 0.7458220507368566 Avg_reward: -0.09852645870736504\n",
            "Training Meta-policy: 40 Val_Acc: 0.7051759981464419 Avg_reward: 1.2536441491399208\n",
            "Training Meta-policy: 41 Val_Acc: 0.7593946122584528 Avg_reward: -0.21134964588655938\n",
            "Training Meta-policy: 42 Val_Acc: 0.7218002071529342 Avg_reward: 0.8336029179793862\n",
            "Training Meta-policy: 43 Val_Acc: 0.7118007964591103 Avg_reward: -0.26020770942295735\n",
            "Training Meta-policy: 44 Val_Acc: 0.6968879106350137 Avg_reward: 2.198386401209679\n",
            "Training Meta-policy: 45 Val_Acc: 0.740746954050821 Avg_reward: 0.1461845833172228\n",
            "Training Meta-policy: 46 Val_Acc: 0.6935554460931095 Avg_reward: -1.246085561924501\n",
            "Training Meta-policy: 47 Val_Acc: 0.7858107598931418 Avg_reward: 0.9755736975523873\n",
            "Training Meta-policy: 48 Val_Acc: 0.7212762053232534 Avg_reward: 0.9030045331061525\n",
            "Training Meta-policy: 49 Val_Acc: 0.7869132465229656 Avg_reward: -2.7615203204456953\n",
            "Training Meta-policy: 50 Val_Acc: 0.7632431154561307 Avg_reward: -6.591369307373278\n",
            "Training Meta-policy: 51 Val_Acc: 0.7242344720714655 Avg_reward: 0.7379452578288223\n",
            "Training Meta-policy: 52 Val_Acc: 0.7002992336856043 Avg_reward: -0.714024092267693\n",
            "Training Meta-policy: 53 Val_Acc: 0.6791118106218096 Avg_reward: 1.2576289959361302\n",
            "Training Meta-policy: 54 Val_Acc: 0.6781746384478706 Avg_reward: -8.364194910964962\n",
            "Training Meta-policy: 55 Val_Acc: 0.6836853949084165 Avg_reward: 1.017581259883425\n",
            "Training Meta-policy: 56 Val_Acc: 0.6152834134076821 Avg_reward: -1.1715433189780267\n",
            "Training Meta-policy: 57 Val_Acc: 0.6420904756132559 Avg_reward: 2.836017626753214\n",
            "Training Meta-policy: 58 Val_Acc: 0.6525645754505477 Avg_reward: -1.8178236051049708\n",
            "Training Meta-policy: 59 Val_Acc: 0.7656698443857396 Avg_reward: 5.8638881637795714\n",
            "Training Meta-policy: 60 Val_Acc: 0.690740520051265 Avg_reward: -1.562003405122455\n",
            "Training Meta-policy: 61 Val_Acc: 0.6011784512494325 Avg_reward: -3.954017970643705\n",
            "Training Meta-policy: 62 Val_Acc: 0.6997905900631607 Avg_reward: -1.3905810562817218\n",
            "Training Meta-policy: 63 Val_Acc: 0.6144470784133521 Avg_reward: -17.51345503665392\n",
            "Training Meta-policy: 64 Val_Acc: 0.6901516458066423 Avg_reward: 12.510370060116296\n",
            "Training Meta-policy: 65 Val_Acc: 0.6627461972362523 Avg_reward: -13.616900520836195\n",
            "Training Meta-policy: 66 Val_Acc: 0.827328786321592 Avg_reward: -0.025322426041844932\n",
            "Training Meta-policy: 67 Val_Acc: 0.8359536094214539 Avg_reward: 6.368434713654844\n",
            "Training Meta-policy: 68 Val_Acc: 0.5675160876324066 Avg_reward: -27.012210332236727\n",
            "Training Meta-policy: 69 Val_Acc: 0.7933704210062434 Avg_reward: 12.425240016408457\n",
            "Training Meta-policy: 70 Val_Acc: 0.8981760970871052 Avg_reward: 2.886885638260433\n",
            "Training Meta-policy: 71 Val_Acc: 0.6595269239154132 Avg_reward: 10.270874209723123\n",
            "Training Meta-policy: 72 Val_Acc: 0.7311563593162168 Avg_reward: -13.388951224341644\n",
            "Training Meta-policy: 73 Val_Acc: 0.8091979010623679 Avg_reward: 0.3222285475468566\n",
            "Training Meta-policy: 74 Val_Acc: 0.8097880857843403 Avg_reward: 16.960677777657008\n",
            "Training Meta-policy: 75 Val_Acc: 0.6646951419341751 Avg_reward: 6.356715928775412\n",
            "Training Meta-policy: 76 Val_Acc: 0.8711624221141445 Avg_reward: 0.5693739608745005\n",
            "Training Meta-policy: 77 Val_Acc: 0.8272237717694229 Avg_reward: 14.55451833097184\n",
            "Training Meta-policy: 78 Val_Acc: 0.7533298484365217 Avg_reward: -0.5467360102066153\n",
            "Training Meta-policy: 79 Val_Acc: 0.7308757046866649 Avg_reward: -0.7717388215081057\n",
            "Training Meta-policy: 80 Val_Acc: 0.772528426705222 Avg_reward: 0.7789588252293262\n",
            "Training Meta-policy: 81 Val_Acc: 0.7847796950409597 Avg_reward: -0.17416082171856828\n",
            "Training Meta-policy: 82 Val_Acc: 0.761271679318374 Avg_reward: -0.3004243919813204\n",
            "Training Meta-policy: 83 Val_Acc: 0.5314108545799343 Avg_reward: -18.01791035790614\n",
            "Training Meta-policy: 84 Val_Acc: 0.7198869280383986 Avg_reward: 1.600205419536562\n",
            "Training Meta-policy: 85 Val_Acc: 0.8329202184470911 Avg_reward: 0.2294634880331087\n",
            "Training Meta-policy: 86 Val_Acc: 0.7995875771680231 Avg_reward: -0.7331361633760718\n",
            "Training Meta-policy: 87 Val_Acc: 0.8491429343849703 Avg_reward: 1.4633539812945295\n",
            "Training Meta-policy: 88 Val_Acc: 0.8796871027086854 Avg_reward: -0.8919965898383068\n",
            "Training Meta-policy: 89 Val_Acc: 0.8654623449743875 Avg_reward: -0.9403079456254333\n",
            "Training Meta-policy: 90 Val_Acc: 0.8230957502039606 Avg_reward: 0.30270216816239476\n",
            "Training Meta-policy: 91 Val_Acc: 0.7858482940840054 Avg_reward: 34.966172910893924\n",
            "Training Meta-policy: 92 Val_Acc: 0.8262681729066732 Avg_reward: -2.6462833253491174\n",
            "Training Meta-policy: 93 Val_Acc: 0.7490564925109093 Avg_reward: -14.455006486613986\n",
            "Training Meta-policy: 94 Val_Acc: 0.6665732987380587 Avg_reward: 0.33765774265832843\n",
            "Training Meta-policy: 95 Val_Acc: 0.7580916786078323 Avg_reward: -1.9690662254590514\n",
            "Training Meta-policy: 96 Val_Acc: 0.8186026127763086 Avg_reward: 0.07381363902717274\n",
            "Training Meta-policy: 97 Val_Acc: 0.618335721566484 Avg_reward: -29.87073995834133\n",
            "Training Meta-policy: 98 Val_Acc: 0.898007519909998 Avg_reward: 23.87258139616252\n",
            "Training Meta-policy: 99 Val_Acc: 0.8675640930554525 Avg_reward: 1.1653440134490431\n",
            "Training Meta-policy: 100 Val_Acc: 0.8062022431744045 Avg_reward: -8.48536574467135\n",
            "Training Meta-policy: 101 Val_Acc: 0.8516268404900297 Avg_reward: 4.85231522506421\n",
            "Training Meta-policy: 102 Val_Acc: 0.8145386795606457 Avg_reward: -0.07442977571257609\n",
            "Training Meta-policy: 103 Val_Acc: 0.5216730381385268 Avg_reward: -27.24524848740255\n",
            "Training Meta-policy: 104 Val_Acc: 0.43868890242497083 Avg_reward: -31.01586948290339\n",
            "Training Meta-policy: 105 Val_Acc: 0.7297499579953871 Avg_reward: 0.35079197788267236\n",
            "Training Meta-policy: 106 Val_Acc: 0.7579756884147855 Avg_reward: -0.15547591274009162\n",
            "Training Meta-policy: 107 Val_Acc: 0.7563190347079938 Avg_reward: 1.544109038251185\n",
            "Training Meta-policy: 108 Val_Acc: 0.731641935028827 Avg_reward: -0.6779317343089609\n",
            "Training Meta-policy: 109 Val_Acc: 0.738604364888219 Avg_reward: -0.17064102497700223\n",
            "Training Meta-policy: 110 Val_Acc: 0.738264248212661 Avg_reward: -0.8132440052277835\n",
            "Training Meta-policy: 111 Val_Acc: 0.7133284013183543 Avg_reward: -1.2963470602828118\n",
            "Training Meta-policy: 112 Val_Acc: 0.7316456256836074 Avg_reward: 0.20685378891747427\n",
            "Training Meta-policy: 113 Val_Acc: 0.7370175416017813 Avg_reward: 0.1395489235542624\n",
            "Training Meta-policy: 114 Val_Acc: 0.7663082165846269 Avg_reward: 0.016084816357443948\n",
            "Training Meta-policy: 115 Val_Acc: 0.7553898669006582 Avg_reward: 0.062433213512352086\n",
            "Training Meta-policy: 116 Val_Acc: 0.7852760736196319 Avg_reward: -6.289161554192246\n",
            "Training Meta-policy: 117 Val_Acc: 0.7818887746945301 Avg_reward: -0.382551101975561\n",
            "Training Meta-policy: 118 Val_Acc: 0.727416444126646 Avg_reward: -1.5125814155977624\n",
            "Training Meta-policy: 119 Val_Acc: 0.7935222672064778 Avg_reward: 11.854251012145752\n",
            "Training Meta-policy: 120 Val_Acc: 0.7956572393906737 Avg_reward: 0.41592636821717055\n",
            "Training Meta-policy: 121 Val_Acc: 0.781818181818182 Avg_reward: -0.20202020202021442\n",
            "Training Meta-policy: 122 Val_Acc: 0.7445511332869188 Avg_reward: -4.37553183259844\n",
            "Training Meta-policy: 123 Val_Acc: 0.7862903225806451 Avg_reward: 7.192204301075278\n",
            "Training Meta-policy: 124 Val_Acc: 0.32525786599635953 Avg_reward: -13.478229464621071\n",
            "Training Meta-policy: 125 Val_Acc: 0.37681117630945343 Avg_reward: -41.27679820071799\n",
            "Training Meta-policy: 126 Val_Acc: 0.3919493663586165 Avg_reward: -0.28402127997001225\n",
            "Training Meta-policy: 127 Val_Acc: 0.4217067227981142 Avg_reward: -35.78523954383586\n",
            "Training Meta-policy: 128 Val_Acc: 0.39819206758841424 Avg_reward: -35.93229624717059\n",
            "Training Meta-policy: 129 Val_Acc: 0.777555110220441 Avg_reward: 0.20040080160320664\n",
            "Training Meta-policy: 130 Val_Acc: 0.4096826747019218 Avg_reward: 0.6035380112743465\n",
            "Training Meta-policy: 131 Val_Acc: 0.7635270541082164 Avg_reward: -0.8016032064128266\n",
            "Training Meta-policy: 132 Val_Acc: 0.7635270541082164 Avg_reward: 0.601202404809631\n",
            "Training Meta-policy: 133 Val_Acc: 0.7815631262525049 Avg_reward: -0.601202404809631\n",
            "Training Meta-policy: 134 Val_Acc: 0.7755511022044087 Avg_reward: 0.20040080160322882\n",
            "Training Meta-policy: 135 Val_Acc: 0.7875751503006013 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 136 Val_Acc: 0.41413762777353275 Avg_reward: -35.94094664148439\n",
            "Training Meta-policy: 137 Val_Acc: 0.7855711422845691 Avg_reward: 0.20040080160319548\n",
            "Training Meta-policy: 138 Val_Acc: 0.4251812978474936 Avg_reward: -34.43577803088192\n",
            "Training Meta-policy: 139 Val_Acc: 0.7875751503006013 Avg_reward: 0.20040080160320664\n",
            "Training Meta-policy: 140 Val_Acc: 0.7835671342685372 Avg_reward: -0.20040080160320664\n",
            "Training Meta-policy: 141 Val_Acc: 0.7855711422845691 Avg_reward: 0.20040080160319548\n",
            "Training Meta-policy: 142 Val_Acc: 0.7915831663326652 Avg_reward: 0.4008016032064021\n",
            "Training Meta-policy: 143 Val_Acc: 0.7915831663326652 Avg_reward: -0.20040080160319548\n",
            "Training Meta-policy: 144 Val_Acc: 0.7975951903807614 Avg_reward: 0.0\n",
            "Training Meta-policy: 145 Val_Acc: 0.794 Avg_reward: 0.20000000000000015\n",
            "Training Meta-policy: 146 Val_Acc: 0.794 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 147 Val_Acc: 0.7960000000000002 Avg_reward: 0.4000000000000003\n",
            "Training Meta-policy: 148 Val_Acc: 0.7999999999999999 Avg_reward: -0.19999999999998908\n",
            "Training Meta-policy: 149 Val_Acc: 0.794 Avg_reward: 0.20000000000000015\n",
            "Training Meta-policy: 150 Val_Acc: 0.794 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 151 Val_Acc: 0.7960000000000002 Avg_reward: 0.0\n",
            "Training Meta-policy: 152 Val_Acc: 0.7999999999999999 Avg_reward: 0.19999999999998908\n",
            "Training Meta-policy: 153 Val_Acc: 0.7999999999999999 Avg_reward: -0.19999999999998908\n",
            "Training Meta-policy: 154 Val_Acc: 0.794 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 155 Val_Acc: 0.794 Avg_reward: -0.20000000000000015\n",
            "Training Meta-policy: 156 Val_Acc: 0.794 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 157 Val_Acc: 0.794 Avg_reward: 0.20000000000000015\n",
            "Training Meta-policy: 158 Val_Acc: 0.7960000000000002 Avg_reward: 0.0\n",
            "Training Meta-policy: 159 Val_Acc: 0.7960000000000002 Avg_reward: 0.20000000000001128\n",
            "Training Meta-policy: 160 Val_Acc: 0.798 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 161 Val_Acc: 0.7960000000000002 Avg_reward: 0.0\n",
            "Training Meta-policy: 162 Val_Acc: 0.7999999999999999 Avg_reward: 2.220446049250313e-14\n",
            "Training Meta-policy: 163 Val_Acc: 0.794 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 164 Val_Acc: 0.794 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 165 Val_Acc: 0.7960000000000002 Avg_reward: 0.20000000000001128\n",
            "Training Meta-policy: 166 Val_Acc: 0.798 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 167 Val_Acc: 0.798 Avg_reward: -0.19999999999997797\n",
            "Training Meta-policy: 168 Val_Acc: 0.788 Avg_reward: -0.20000000000000015\n",
            "Training Meta-policy: 169 Val_Acc: 0.7615230460921845 Avg_reward: -2.2044088176352834\n",
            "Training Meta-policy: 170 Val_Acc: 0.3533253557474661 Avg_reward: -41.22057063767822\n",
            "Training Meta-policy: 171 Val_Acc: 0.3725436484479751 Avg_reward: -38.89793976442094\n",
            "Training Meta-policy: 172 Val_Acc: 0.7895791583166333 Avg_reward: 0.0\n",
            "Training Meta-policy: 173 Val_Acc: 0.7735470941883766 Avg_reward: -0.4008016032064133\n",
            "Training Meta-policy: 174 Val_Acc: 0.4396995429708338 Avg_reward: -34.38675912977035\n",
            "Training Meta-policy: 175 Val_Acc: 0.7975951903807614 Avg_reward: 0.0\n",
            "Training Meta-policy: 176 Val_Acc: 0.7895791583166333 Avg_reward: 0.0\n",
            "Training Meta-policy: 177 Val_Acc: 0.7875751503006013 Avg_reward: 45.595190380761515\n",
            "Training Meta-policy: 178 Val_Acc: 0.7915831663326652 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 179 Val_Acc: 0.7975951903807614 Avg_reward: 0.0\n",
            "Training Meta-policy: 180 Val_Acc: 0.7971887550200804 Avg_reward: -0.20080321285140812\n",
            "Training Meta-policy: 181 Val_Acc: 0.7891566265060243 Avg_reward: -0.40160642570279403\n",
            "Training Meta-policy: 182 Val_Acc: 0.6497500794545087 Avg_reward: -13.338245066597322\n",
            "Training Meta-policy: 183 Val_Acc: 0.7931726907630522 Avg_reward: 13.485943775100406\n",
            "Training Meta-policy: 184 Val_Acc: 0.7871485943775102 Avg_reward: -0.20080321285141922\n",
            "Training Meta-policy: 185 Val_Acc: 0.7771084337349398 Avg_reward: 46.305220883534155\n",
            "Training Meta-policy: 186 Val_Acc: 0.627762849960995 Avg_reward: -2.9666868914506903\n",
            "Training Meta-policy: 187 Val_Acc: 0.7791164658634537 Avg_reward: 0.40160642570282734\n",
            "Training Meta-policy: 188 Val_Acc: 0.3821328479385167 Avg_reward: -39.89916500534512\n",
            "Training Meta-policy: 189 Val_Acc: 0.7891566265060243 Avg_reward: 41.03614457831326\n",
            "Training Meta-policy: 190 Val_Acc: 0.22813556383808614 Avg_reward: -54.29487735113114\n",
            "Training Meta-policy: 191 Val_Acc: 0.7855711422845691 Avg_reward: 0.0\n",
            "Training Meta-policy: 192 Val_Acc: 0.8736609910468418 Avg_reward: 72.45627946540563\n",
            "Training Meta-policy: 193 Val_Acc: 0.7715430861723447 Avg_reward: -0.2004008016031844\n",
            "Training Meta-policy: 194 Val_Acc: 0.7715430861723447 Avg_reward: -0.8016032064128155\n",
            "Training Meta-policy: 195 Val_Acc: 0.7755511022044087 Avg_reward: 1.0020040080160442\n",
            "Training Meta-policy: 196 Val_Acc: 0.7835671342685372 Avg_reward: -0.20040080160320664\n",
            "Training Meta-policy: 197 Val_Acc: 0.3786565937630657 Avg_reward: -40.49105405054714\n",
            "Training Meta-policy: 198 Val_Acc: 0.7815631262525049 Avg_reward: 0.20040080160321772\n",
            "Training Meta-policy: 199 Val_Acc: 0.7740000000000001 Avg_reward: 0.0\n",
            "Training Meta-policy: 200 Val_Acc: 0.7720000000000001 Avg_reward: 0.6000000000000116\n",
            "Training Meta-policy: 201 Val_Acc: 0.7800000000000001 Avg_reward: -0.19999999999998908\n",
            "Training Meta-policy: 202 Val_Acc: 0.7839999999999999 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 203 Val_Acc: 0.79 Avg_reward: 0.0\n",
            "Training Meta-policy: 204 Val_Acc: 0.79 Avg_reward: 0.0\n",
            "Training Meta-policy: 205 Val_Acc: 0.79 Avg_reward: 0.20000000000001128\n",
            "Training Meta-policy: 206 Val_Acc: 0.79 Avg_reward: 0.20000000000001128\n",
            "Training Meta-policy: 207 Val_Acc: 0.7819999999999999 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 208 Val_Acc: 0.7819999999999999 Avg_reward: -0.4000000000000003\n",
            "Training Meta-policy: 209 Val_Acc: 0.7839999999999999 Avg_reward: -0.20000000000000015\n",
            "Training Meta-policy: 210 Val_Acc: 0.788 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 211 Val_Acc: 0.788 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 212 Val_Acc: 0.79 Avg_reward: -0.20000000000000015\n",
            "Training Meta-policy: 213 Val_Acc: 0.778 Avg_reward: 0.0\n",
            "Training Meta-policy: 214 Val_Acc: 0.788 Avg_reward: -0.20000000000000015\n",
            "Training Meta-policy: 215 Val_Acc: 0.7839999999999999 Avg_reward: -0.3999999999999892\n",
            "Training Meta-policy: 216 Val_Acc: 0.786 Avg_reward: 0.0\n",
            "Training Meta-policy: 217 Val_Acc: 0.7800000000000001 Avg_reward: -0.3999999999999892\n",
            "Training Meta-policy: 218 Val_Acc: 0.79 Avg_reward: 0.20000000000001128\n",
            "Training Meta-policy: 219 Val_Acc: 0.7819999999999999 Avg_reward: -0.4000000000000003\n",
            "Training Meta-policy: 220 Val_Acc: 0.7819999999999999 Avg_reward: -0.19999999999998908\n",
            "Training Meta-policy: 221 Val_Acc: 0.7919999999999999 Avg_reward: 0.4000000000000115\n",
            "Training Meta-policy: 222 Val_Acc: 0.7800000000000001 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 223 Val_Acc: 0.788 Avg_reward: -0.4000000000000003\n",
            "Training Meta-policy: 224 Val_Acc: 0.79 Avg_reward: 0.20000000000001128\n",
            "Training Meta-policy: 225 Val_Acc: 0.7839999999999999 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 226 Val_Acc: 0.786 Avg_reward: 0.0\n",
            "Training Meta-policy: 227 Val_Acc: 0.786 Avg_reward: 0.4000000000000115\n",
            "Training Meta-policy: 228 Val_Acc: 0.786 Avg_reward: 0.0\n",
            "Training Meta-policy: 229 Val_Acc: 0.79 Avg_reward: 0.0\n",
            "Training Meta-policy: 230 Val_Acc: 0.788 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 231 Val_Acc: 0.788 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 232 Val_Acc: 0.7800000000000001 Avg_reward: -0.3999999999999892\n",
            "Training Meta-policy: 233 Val_Acc: 0.7819999999999999 Avg_reward: 0.4000000000000003\n",
            "Training Meta-policy: 234 Val_Acc: 0.798 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 235 Val_Acc: 0.7999999999999999 Avg_reward: 2.220446049250313e-14\n",
            "Training Meta-policy: 236 Val_Acc: 0.794 Avg_reward: -0.20000000000000015\n",
            "Training Meta-policy: 237 Val_Acc: 0.794 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 238 Val_Acc: 0.7960000000000002 Avg_reward: -0.20000000000001128\n",
            "Training Meta-policy: 239 Val_Acc: 0.77 Avg_reward: -1.1999999999999902\n",
            "Training Meta-policy: 240 Val_Acc: 0.786 Avg_reward: -0.4000000000000003\n",
            "Training Meta-policy: 241 Val_Acc: 0.7839999999999999 Avg_reward: -0.20000000000000015\n",
            "Training Meta-policy: 242 Val_Acc: 0.7839999999999999 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 243 Val_Acc: 0.786 Avg_reward: 0.0\n",
            "Training Meta-policy: 244 Val_Acc: 0.7839999999999999 Avg_reward: 0.20000000000001128\n",
            "Training Meta-policy: 245 Val_Acc: 0.788 Avg_reward: 0.4000000000000115\n",
            "Training Meta-policy: 246 Val_Acc: 0.788 Avg_reward: 0.20000000000000015\n",
            "Training Meta-policy: 247 Val_Acc: 0.786 Avg_reward: 0.0\n",
            "Training Meta-policy: 248 Val_Acc: 0.788 Avg_reward: -0.4000000000000003\n",
            "Training Meta-policy: 249 Val_Acc: 0.7800000000000001 Avg_reward: -0.19999999999998908\n",
            "Training Meta-policy: 250 Val_Acc: 0.7839999999999999 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 251 Val_Acc: 0.788 Avg_reward: 36.248\n",
            "Training Meta-policy: 252 Val_Acc: 0.788 Avg_reward: -0.20000000000000015\n",
            "Training Meta-policy: 253 Val_Acc: 0.79 Avg_reward: -0.6000000000000005\n",
            "Training Meta-policy: 254 Val_Acc: 0.788 Avg_reward: 41.168000000000006\n",
            "Training Meta-policy: 255 Val_Acc: 0.7919999999999999 Avg_reward: 0.0\n",
            "Training Meta-policy: 256 Val_Acc: 0.7855711422845691 Avg_reward: 0.4008016032064021\n",
            "Training Meta-policy: 257 Val_Acc: 0.350398639004628 Avg_reward: -43.51725032799412\n",
            "Training Meta-policy: 258 Val_Acc: 0.7715430861723447 Avg_reward: -0.6012024048096198\n",
            "Training Meta-policy: 259 Val_Acc: 0.7795591182364728 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 260 Val_Acc: 0.7815631262525049 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 261 Val_Acc: 0.7855711422845691 Avg_reward: -0.20040080160321772\n",
            "Training Meta-policy: 262 Val_Acc: 0.7955911823647295 Avg_reward: 0.20040080160321772\n",
            "Training Meta-policy: 263 Val_Acc: 0.7875751503006013 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 264 Val_Acc: 0.7815631262525049 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 265 Val_Acc: 0.777555110220441 Avg_reward: -0.20040080160319548\n",
            "Training Meta-policy: 266 Val_Acc: 0.7995991983967937 Avg_reward: 0.0\n",
            "Training Meta-policy: 267 Val_Acc: 0.7835671342685372 Avg_reward: -0.40080160320642433\n",
            "Training Meta-policy: 268 Val_Acc: 0.777555110220441 Avg_reward: -0.20040080160319548\n",
            "Training Meta-policy: 269 Val_Acc: 0.7815631262525049 Avg_reward: 0.20040080160321772\n",
            "Training Meta-policy: 270 Val_Acc: 0.7795591182364728 Avg_reward: 0.20040080160320664\n",
            "Training Meta-policy: 271 Val_Acc: 0.777555110220441 Avg_reward: -0.20040080160319548\n",
            "Training Meta-policy: 272 Val_Acc: 0.41715084845950895 Avg_reward: -36.84202938250602\n",
            "Training Meta-policy: 273 Val_Acc: 0.7855711422845691 Avg_reward: 0.20040080160319548\n",
            "Training Meta-policy: 274 Val_Acc: 0.7655310621242483 Avg_reward: -0.20040080160322882\n",
            "Training Meta-policy: 275 Val_Acc: 0.777555110220441 Avg_reward: 0.0\n",
            "Training Meta-policy: 276 Val_Acc: 0.7735470941883766 Avg_reward: -0.20040080160320664\n",
            "Training Meta-policy: 277 Val_Acc: 0.7955911823647295 Avg_reward: 42.96192384769539\n",
            "Training Meta-policy: 278 Val_Acc: 0.7995991983967937 Avg_reward: 0.4008016032064021\n",
            "Training Meta-policy: 279 Val_Acc: 0.7875751503006013 Avg_reward: 0.20040080160320664\n",
            "Training Meta-policy: 280 Val_Acc: 0.7835671342685372 Avg_reward: -0.20040080160320664\n",
            "Training Meta-policy: 281 Val_Acc: 0.7494989979959918 Avg_reward: 37.723446893787575\n",
            "Training Meta-policy: 282 Val_Acc: 0.7635270541082164 Avg_reward: 0.601202404809631\n",
            "Training Meta-policy: 283 Val_Acc: 0.7715430861723447 Avg_reward: -0.4008016032064133\n",
            "Training Meta-policy: 284 Val_Acc: 0.777555110220441 Avg_reward: 0.40080160320643543\n",
            "Training Meta-policy: 285 Val_Acc: 0.7735470941883766 Avg_reward: 2.220446049250313e-14\n",
            "Training Meta-policy: 286 Val_Acc: 0.7835671342685372 Avg_reward: -0.20040080160320664\n",
            "Training Meta-policy: 287 Val_Acc: 0.7795591182364728 Avg_reward: -0.20040080160321772\n",
            "Training Meta-policy: 288 Val_Acc: 0.7815631262525049 Avg_reward: 0.20040080160321772\n",
            "Training Meta-policy: 289 Val_Acc: 0.7555110220440882 Avg_reward: -0.20040080160319548\n",
            "Training Meta-policy: 290 Val_Acc: 0.777555110220441 Avg_reward: 0.0\n",
            "Training Meta-policy: 291 Val_Acc: 0.7755511022044087 Avg_reward: 0.20040080160322882\n",
            "Training Meta-policy: 292 Val_Acc: 0.777555110220441 Avg_reward: -0.40080160320642433\n",
            "Training Meta-policy: 293 Val_Acc: 0.7755511022044087 Avg_reward: 0.0\n",
            "Training Meta-policy: 294 Val_Acc: 0.7835671342685372 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 295 Val_Acc: 0.7795591182364728 Avg_reward: 1.1102230246251565e-14\n",
            "Training Meta-policy: 296 Val_Acc: 0.7915831663326652 Avg_reward: 0.6012024048096198\n",
            "Training Meta-policy: 297 Val_Acc: 0.7835671342685372 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 298 Val_Acc: 0.7895791583166333 Avg_reward: 0.0\n",
            "Training Meta-policy: 299 Val_Acc: 0.7875751503006013 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 300 Val_Acc: 0.7955911823647295 Avg_reward: 0.20040080160321772\n",
            "Training Meta-policy: 301 Val_Acc: 0.7835671342685372 Avg_reward: -0.20040080160320664\n",
            "Training Meta-policy: 302 Val_Acc: 0.7875751503006013 Avg_reward: 0.20040080160320664\n",
            "Training Meta-policy: 303 Val_Acc: 0.7975951903807614 Avg_reward: 0.0\n",
            "Training Meta-policy: 304 Val_Acc: 0.7835671342685372 Avg_reward: 0.6012024048096198\n",
            "Training Meta-policy: 305 Val_Acc: 0.7935871743486975 Avg_reward: 0.4008016032064133\n",
            "Training Meta-policy: 306 Val_Acc: 0.7915831663326652 Avg_reward: -0.40080160320642433\n",
            "Training Meta-policy: 307 Val_Acc: 0.7895791583166333 Avg_reward: 0.0\n",
            "Training Meta-policy: 308 Val_Acc: 0.7795591182364728 Avg_reward: 0.20040080160320664\n",
            "Training Meta-policy: 309 Val_Acc: 0.7955911823647295 Avg_reward: 0.40080160320642433\n",
            "Training Meta-policy: 310 Val_Acc: 0.7875751503006013 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 311 Val_Acc: 0.7895791583166333 Avg_reward: 0.20040080160319548\n",
            "Training Meta-policy: 312 Val_Acc: 0.7855711422845691 Avg_reward: 0.20040080160319548\n",
            "Training Meta-policy: 313 Val_Acc: 0.7895791583166333 Avg_reward: 0.0\n",
            "Training Meta-policy: 314 Val_Acc: 0.39294416170470436 Avg_reward: -39.86390046279609\n",
            "Training Meta-policy: 315 Val_Acc: 0.777555110220441 Avg_reward: 32.4248496993988\n",
            "Training Meta-policy: 316 Val_Acc: 0.7675350701402807 Avg_reward: -0.4008016032064133\n",
            "Training Meta-policy: 317 Val_Acc: 0.7815631262525049 Avg_reward: -0.20040080160321772\n",
            "Training Meta-policy: 318 Val_Acc: 0.7735470941883766 Avg_reward: -0.4008016032064133\n",
            "Training Meta-policy: 319 Val_Acc: 0.7695390781563127 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 320 Val_Acc: 0.7815631262525049 Avg_reward: 0.20040080160321772\n",
            "Training Meta-policy: 321 Val_Acc: 0.7795591182364728 Avg_reward: -0.8016032064128372\n",
            "Training Meta-policy: 322 Val_Acc: 0.7835671342685372 Avg_reward: -1.1102230246251565e-14\n",
            "Training Meta-policy: 323 Val_Acc: 0.7875751503006013 Avg_reward: -0.20040080160320664\n",
            "Training Meta-policy: 324 Val_Acc: 0.7955911823647295 Avg_reward: 0.20040080160321772\n",
            "Training Meta-policy: 325 Val_Acc: 0.7835671342685372 Avg_reward: -0.40080160320642433\n",
            "Training GNNs with learned meta-policy\n",
            "Training GNN 1 ; Val_Acc: 0.25250501002004005 ; Test_Acc: 0.266\n",
            "Training GNN 2 ; Val_Acc: 0.3527054108216432 ; Test_Acc: 0.374\n",
            "Training GNN 3 ; Val_Acc: 0.4048096192384771 ; Test_Acc: 0.427\n",
            "Training GNN 4 ; Val_Acc: 0.4288577154308618 ; Test_Acc: 0.47\n",
            "Training GNN 5 ; Val_Acc: 0.46893787575150286 ; Test_Acc: 0.502\n",
            "Training GNN 6 ; Val_Acc: 0.4829659318637275 ; Test_Acc: 0.499\n",
            "Training GNN 7 ; Val_Acc: 0.5050100200400801 ; Test_Acc: 0.523\n",
            "Training GNN 8 ; Val_Acc: 0.5410821643286574 ; Test_Acc: 0.555\n",
            "Training GNN 9 ; Val_Acc: 0.5711422845691382 ; Test_Acc: 0.587\n",
            "Training GNN 10 ; Val_Acc: 0.6072144288577155 ; Test_Acc: 0.617\n",
            "Training GNN 11 ; Val_Acc: 0.6332665330661323 ; Test_Acc: 0.639\n",
            "Training GNN 12 ; Val_Acc: 0.6573146292585169 ; Test_Acc: 0.664\n",
            "Training GNN 13 ; Val_Acc: 0.6673346693386774 ; Test_Acc: 0.681\n",
            "Training GNN 14 ; Val_Acc: 0.687374749498998 ; Test_Acc: 0.692\n",
            "Training GNN 15 ; Val_Acc: 0.6993987975951905 ; Test_Acc: 0.705\n",
            "Training GNN 16 ; Val_Acc: 0.7054108216432864 ; Test_Acc: 0.716\n",
            "Training GNN 17 ; Val_Acc: 0.719438877755511 ; Test_Acc: 0.723\n",
            "Training GNN 18 ; Val_Acc: 0.7374749498997996 ; Test_Acc: 0.729\n",
            "Training GNN 19 ; Val_Acc: 0.7394789579158316 ; Test_Acc: 0.744\n",
            "Training GNN 20 ; Val_Acc: 0.7394789579158316 ; Test_Acc: 0.753\n",
            "Training GNN 21 ; Val_Acc: 0.7454909819639278 ; Test_Acc: 0.764\n",
            "Training GNN 22 ; Val_Acc: 0.7555110220440882 ; Test_Acc: 0.772\n",
            "Training GNN 23 ; Val_Acc: 0.7595190380761521 ; Test_Acc: 0.78\n",
            "Training GNN 24 ; Val_Acc: 0.7595190380761521 ; Test_Acc: 0.786\n",
            "Training GNN 25 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.788\n",
            "Training GNN 26 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.79\n",
            "Training GNN 27 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.789\n",
            "Training GNN 28 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.789\n",
            "Training GNN 29 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.787\n",
            "Training GNN 30 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.788\n",
            "Training GNN 31 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.788\n",
            "Training GNN 32 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.788\n",
            "Training GNN 33 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.789\n",
            "Training GNN 34 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.788\n",
            "Training GNN 35 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.784\n",
            "Training GNN 36 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.784\n",
            "Training GNN 37 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.782\n",
            "Training GNN 38 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.78\n",
            "Training GNN 39 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.781\n",
            "Training GNN 40 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.781\n",
            "Training GNN 41 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.782\n",
            "Training GNN 42 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.786\n",
            "Training GNN 43 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.79\n",
            "Training GNN 44 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.793\n",
            "Training GNN 45 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.792\n",
            "Training GNN 46 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.795\n",
            "Training GNN 47 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.795\n",
            "Training GNN 48 ; Val_Acc: 0.7918570954859357 ; Test_Acc: 0.795\n",
            "Training GNN 49 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.793\n",
            "Training GNN 50 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.789\n",
            "Training GNN 51 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.787\n",
            "Training GNN 52 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.785\n",
            "Training GNN 53 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.783\n",
            "Training GNN 54 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.781\n",
            "Training GNN 55 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.782\n",
            "Training GNN 56 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.78\n",
            "Training GNN 57 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.783\n",
            "Training GNN 58 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.784\n",
            "Training GNN 59 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.785\n",
            "Training GNN 60 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.788\n",
            "Training GNN 61 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.789\n",
            "Training GNN 62 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.79\n",
            "Training GNN 63 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.793\n",
            "Training GNN 64 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.79\n",
            "Training GNN 65 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.791\n",
            "Training GNN 66 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.788\n",
            "Training GNN 67 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.788\n",
            "Training GNN 68 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.788\n",
            "Training GNN 69 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.782\n",
            "Training GNN 70 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.785\n",
            "Training GNN 71 ; Val_Acc: 0.7739507792563544 ; Test_Acc: 0.783\n",
            "Training GNN 72 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.784\n",
            "Training GNN 73 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.781\n",
            "Training GNN 74 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.78\n",
            "Training GNN 75 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.778\n",
            "Training GNN 76 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.78\n",
            "Training GNN 77 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.786\n",
            "Training GNN 78 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.783\n",
            "Training GNN 79 ; Val_Acc: 0.7819091420250575 ; Test_Acc: 0.782\n",
            "Training GNN 80 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.787\n",
            "Training GNN 81 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.788\n",
            "Training GNN 82 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.788\n",
            "Training GNN 83 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.787\n",
            "Training GNN 84 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.784\n",
            "Training GNN 85 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.78\n",
            "Training GNN 86 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.782\n",
            "Training GNN 87 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.786\n",
            "Training GNN 88 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.787\n",
            "Training GNN 89 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.789\n",
            "Training GNN 90 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.786\n",
            "Training GNN 91 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.79\n",
            "Training GNN 92 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.789\n",
            "Training GNN 93 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.788\n",
            "Training GNN 94 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.788\n",
            "Training GNN 95 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.79\n",
            "Training GNN 96 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.788\n",
            "Training GNN 97 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.785\n",
            "Training GNN 98 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.786\n",
            "Training GNN 99 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.791\n",
            "Training GNN 100 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.79\n",
            "Training GNN 101 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.79\n",
            "Training GNN 102 ; Val_Acc: 0.7659924164876516 ; Test_Acc: 0.792\n",
            "Training GNN 103 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.792\n",
            "Training GNN 104 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.793\n",
            "Training GNN 105 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.791\n",
            "Training GNN 106 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.787\n",
            "Training GNN 107 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.783\n",
            "Training GNN 108 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.781\n",
            "Training GNN 109 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.781\n",
            "Training GNN 110 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.781\n",
            "Training GNN 111 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.783\n",
            "Training GNN 112 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.785\n",
            "Training GNN 113 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.788\n",
            "Training GNN 114 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.789\n",
            "Training GNN 115 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.792\n",
            "Training GNN 116 ; Val_Acc: 0.7659924164876516 ; Test_Acc: 0.791\n",
            "Training GNN 117 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.793\n",
            "Training GNN 118 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.792\n",
            "Training GNN 119 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.792\n",
            "Training GNN 120 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.792\n",
            "Training GNN 121 ; Val_Acc: 0.7600236444111242 ; Test_Acc: 0.791\n",
            "Training GNN 122 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.789\n",
            "Training GNN 123 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.788\n",
            "Training GNN 124 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.788\n",
            "Training GNN 125 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.787\n",
            "Training GNN 126 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.79\n",
            "Training GNN 127 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.791\n",
            "Training GNN 128 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.792\n",
            "Training GNN 129 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.796\n",
            "Training GNN 130 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.795\n",
            "Training GNN 131 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.796\n",
            "Training GNN 132 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.798\n",
            "Training GNN 133 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.801\n",
            "Training GNN 134 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.801\n",
            "Training GNN 135 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.8\n",
            "Training GNN 136 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.798\n",
            "Training GNN 137 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.794\n",
            "Training GNN 138 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.794\n",
            "Training GNN 139 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.792\n",
            "Training GNN 140 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.787\n",
            "Training GNN 141 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.786\n",
            "Training GNN 142 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.788\n",
            "Training GNN 143 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.788\n",
            "Training GNN 144 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.79\n",
            "Training GNN 145 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.787\n",
            "Training GNN 146 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.791\n",
            "Training GNN 147 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.794\n",
            "Training GNN 148 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.796\n",
            "Training GNN 149 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.796\n",
            "Training GNN 150 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.799\n",
            "Training GNN 151 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.8\n",
            "Training GNN 152 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.799\n",
            "Training GNN 153 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.795\n",
            "Training GNN 154 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.795\n",
            "Training GNN 155 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.794\n",
            "Training GNN 156 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.795\n",
            "Training GNN 157 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.794\n",
            "Training GNN 158 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.8\n",
            "Training GNN 159 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.796\n",
            "Training GNN 160 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.798\n",
            "Training GNN 161 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.797\n",
            "Training GNN 162 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.792\n",
            "Training GNN 163 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.792\n",
            "Training GNN 164 ; Val_Acc: 0.7615230460921845 ; Test_Acc: 0.785\n",
            "Training GNN 165 ; Val_Acc: 0.7575150300601202 ; Test_Acc: 0.784\n",
            "Training GNN 166 ; Val_Acc: 0.7575150300601202 ; Test_Acc: 0.783\n",
            "Training GNN 167 ; Val_Acc: 0.7575150300601202 ; Test_Acc: 0.786\n",
            "Training GNN 168 ; Val_Acc: 0.7595190380761521 ; Test_Acc: 0.786\n",
            "Training GNN 169 ; Val_Acc: 0.7595190380761521 ; Test_Acc: 0.791\n",
            "Training GNN 170 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.79\n",
            "Training GNN 171 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.796\n",
            "Training GNN 172 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.795\n",
            "Training GNN 173 ; Val_Acc: 0.7640028257954758 ; Test_Acc: 0.794\n",
            "Training GNN 174 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.792\n",
            "Training GNN 175 ; Val_Acc: 0.7615230460921845 ; Test_Acc: 0.786\n",
            "Training GNN 176 ; Val_Acc: 0.7615230460921845 ; Test_Acc: 0.787\n",
            "Training GNN 177 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.791\n",
            "Training GNN 178 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.789\n",
            "Training GNN 179 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.792\n",
            "Training GNN 180 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.793\n",
            "Training GNN 181 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.789\n",
            "Training GNN 182 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.79\n",
            "Training GNN 183 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.79\n",
            "Training GNN 184 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.791\n",
            "Training GNN 185 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.794\n",
            "Training GNN 186 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.798\n",
            "Training GNN 187 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.804\n",
            "Training GNN 188 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.804\n",
            "Training GNN 189 ; Val_Acc: 0.7699715978720029 ; Test_Acc: 0.802\n",
            "Training GNN 190 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.802\n",
            "Training GNN 191 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.802\n",
            "Training GNN 192 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.801\n",
            "Training GNN 193 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.799\n",
            "Training GNN 194 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.799\n",
            "Training GNN 195 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.796\n",
            "Training GNN 196 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.793\n",
            "Training GNN 197 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.797\n",
            "Training GNN 198 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.796\n",
            "Training GNN 199 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.795\n",
            "Training GNN 200 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.793\n",
            "Training GNN 201 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.798\n",
            "Training GNN 202 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.8\n",
            "Training GNN 203 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.799\n",
            "Training GNN 204 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.801\n",
            "Training GNN 205 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.802\n",
            "Training GNN 206 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.802\n",
            "Training GNN 207 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.801\n",
            "Training GNN 208 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.801\n",
            "Training GNN 209 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.801\n",
            "Training GNN 210 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.803\n",
            "Training GNN 211 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.802\n",
            "Training GNN 212 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.802\n",
            "Training GNN 213 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.805\n",
            "Training GNN 214 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.805\n",
            "Training GNN 215 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.803\n",
            "Training GNN 216 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.805\n",
            "Training GNN 217 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.804\n",
            "Training GNN 218 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.803\n",
            "Training GNN 219 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.804\n",
            "Training GNN 220 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.805\n",
            "Training GNN 221 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.808\n",
            "Training GNN 222 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.81\n",
            "Training GNN 223 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.811\n",
            "Training GNN 224 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.806\n",
            "Training GNN 225 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.804\n",
            "Training GNN 226 ; Val_Acc: 0.7615230460921845 ; Test_Acc: 0.803\n",
            "Training GNN 227 ; Val_Acc: 0.7560444630267731 ; Test_Acc: 0.801\n",
            "Training GNN 228 ; Val_Acc: 0.7615230460921845 ; Test_Acc: 0.799\n",
            "Training GNN 229 ; Val_Acc: 0.7615230460921845 ; Test_Acc: 0.799\n",
            "Training GNN 230 ; Val_Acc: 0.7615230460921845 ; Test_Acc: 0.8\n",
            "Training GNN 231 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.802\n",
            "Training GNN 232 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.801\n",
            "Training GNN 233 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.805\n",
            "Training GNN 234 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.811\n",
            "Training GNN 235 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.812\n",
            "Training GNN 236 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.817\n",
            "Training GNN 237 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.808\n",
            "Training GNN 238 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.806\n",
            "Training GNN 239 ; Val_Acc: 0.7620132351033003 ; Test_Acc: 0.799\n",
            "Training GNN 240 ; Val_Acc: 0.7595190380761521 ; Test_Acc: 0.798\n",
            "Training GNN 241 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.796\n",
            "Training GNN 242 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.799\n",
            "Training GNN 243 ; Val_Acc: 0.7615230460921845 ; Test_Acc: 0.798\n",
            "Training GNN 244 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.8\n",
            "Training GNN 245 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.803\n",
            "Training GNN 246 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.805\n",
            "Training GNN 247 ; Val_Acc: 0.7679820071798271 ; Test_Acc: 0.805\n",
            "Training GNN 248 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.807\n",
            "Training GNN 249 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.802\n",
            "Training GNN 250 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.801\n",
            "Training GNN 251 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.796\n",
            "Training GNN 252 ; Val_Acc: 0.7575150300601202 ; Test_Acc: 0.793\n",
            "Training GNN 253 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.794\n",
            "Training GNN 254 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.8\n",
            "Training GNN 255 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.803\n",
            "Training GNN 256 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.804\n",
            "Training GNN 257 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.806\n",
            "Training GNN 258 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.805\n",
            "Training GNN 259 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.805\n",
            "Training GNN 260 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.802\n",
            "Training GNN 261 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.805\n",
            "Training GNN 262 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.804\n",
            "Training GNN 263 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.804\n",
            "Training GNN 264 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.8\n",
            "Training GNN 265 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.8\n",
            "Training GNN 266 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.803\n",
            "Training GNN 267 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.802\n",
            "Training GNN 268 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.801\n",
            "Training GNN 269 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.801\n",
            "Training GNN 270 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.802\n",
            "Training GNN 271 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.802\n",
            "Training GNN 272 ; Val_Acc: 0.7635270541082164 ; Test_Acc: 0.804\n",
            "Training GNN 273 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.807\n",
            "Training GNN 274 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.81\n",
            "Training GNN 275 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.807\n",
            "Training GNN 276 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.808\n",
            "Training GNN 277 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.807\n",
            "Training GNN 278 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.803\n",
            "Training GNN 279 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.802\n",
            "Training GNN 280 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.804\n",
            "Training GNN 281 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.801\n",
            "Training GNN 282 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.803\n",
            "Training GNN 283 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.803\n",
            "Training GNN 284 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.799\n",
            "Training GNN 285 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.8\n",
            "Training GNN 286 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.803\n",
            "Training GNN 287 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.803\n",
            "Training GNN 288 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.804\n",
            "Training GNN 289 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.807\n",
            "Training GNN 290 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.806\n",
            "Training GNN 291 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.809\n",
            "Training GNN 292 ; Val_Acc: 0.7739507792563544 ; Test_Acc: 0.81\n",
            "Training GNN 293 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.81\n",
            "Training GNN 294 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.805\n",
            "Training GNN 295 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.806\n",
            "Training GNN 296 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.805\n",
            "Training GNN 297 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.803\n",
            "Training GNN 298 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.803\n",
            "Training GNN 299 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.803\n",
            "Training GNN 300 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.805\n",
            "Training GNN 301 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.804\n",
            "Training GNN 302 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.804\n",
            "Training GNN 303 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.804\n",
            "Training GNN 304 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.803\n",
            "Training GNN 305 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.805\n",
            "Training GNN 306 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.807\n",
            "Training GNN 307 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.806\n",
            "Training GNN 308 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.808\n",
            "Training GNN 309 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.812\n",
            "Training GNN 310 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.807\n",
            "Training GNN 311 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.809\n",
            "Training GNN 312 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.811\n",
            "Training GNN 313 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.81\n",
            "Training GNN 314 ; Val_Acc: 0.7878779141015845 ; Test_Acc: 0.811\n",
            "Training GNN 315 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.808\n",
            "Training GNN 316 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.807\n",
            "Training GNN 317 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.805\n",
            "Training GNN 318 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 319 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.807\n",
            "Training GNN 320 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.81\n",
            "Training GNN 321 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.814\n",
            "Training GNN 322 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.814\n",
            "Training GNN 323 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.811\n",
            "Training GNN 324 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.81\n",
            "Training GNN 325 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.81\n",
            "Training GNN 326 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.808\n",
            "Training GNN 327 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.809\n",
            "Training GNN 328 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.811\n",
            "Training GNN 329 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.811\n",
            "Training GNN 330 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.811\n",
            "Training GNN 331 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.81\n",
            "Training GNN 332 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.811\n",
            "Training GNN 333 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.81\n",
            "Training GNN 334 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.812\n",
            "Training GNN 335 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.811\n",
            "Training GNN 336 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.807\n",
            "Training GNN 337 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.802\n",
            "Training GNN 338 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.799\n",
            "Training GNN 339 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.801\n",
            "Training GNN 340 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.804\n",
            "Training GNN 341 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.801\n",
            "Training GNN 342 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.802\n",
            "Training GNN 343 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.801\n",
            "Training GNN 344 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.802\n",
            "Training GNN 345 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.804\n",
            "Training GNN 346 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.805\n",
            "Training GNN 347 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.804\n",
            "Training GNN 348 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.805\n",
            "Training GNN 349 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.808\n",
            "Training GNN 350 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.809\n",
            "Training GNN 351 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.801\n",
            "Training GNN 352 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.798\n",
            "Training GNN 353 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.802\n",
            "Training GNN 354 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.8\n",
            "Training GNN 355 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.799\n",
            "Training GNN 356 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.801\n",
            "Training GNN 357 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.802\n",
            "Training GNN 358 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.801\n",
            "Training GNN 359 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.801\n",
            "Training GNN 360 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.801\n",
            "Training GNN 361 ; Val_Acc: 0.7759403699485301 ; Test_Acc: 0.806\n",
            "Training GNN 362 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.805\n",
            "Training GNN 363 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.806\n",
            "Training GNN 364 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.808\n",
            "Training GNN 365 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.809\n",
            "Training GNN 366 ; Val_Acc: 0.7858883234094086 ; Test_Acc: 0.808\n",
            "Training GNN 367 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.806\n",
            "Training GNN 368 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.806\n",
            "Training GNN 369 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.809\n",
            "Training GNN 370 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.804\n",
            "Training GNN 371 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.806\n",
            "Training GNN 372 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.805\n",
            "Training GNN 373 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.805\n",
            "Training GNN 374 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.805\n",
            "Training GNN 375 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.802\n",
            "Training GNN 376 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.804\n",
            "Training GNN 377 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.801\n",
            "Training GNN 378 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.803\n",
            "Training GNN 379 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.803\n",
            "Training GNN 380 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.804\n",
            "Training GNN 381 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.804\n",
            "Training GNN 382 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.804\n",
            "Training GNN 383 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.805\n",
            "Training GNN 384 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.807\n",
            "Training GNN 385 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.806\n",
            "Training GNN 386 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.806\n",
            "Training GNN 387 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.803\n",
            "Training GNN 388 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.804\n",
            "Training GNN 389 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.804\n",
            "Training GNN 390 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.802\n",
            "Training GNN 391 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.802\n",
            "Training GNN 392 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.807\n",
            "Training GNN 393 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.807\n",
            "Training GNN 394 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.805\n",
            "Training GNN 395 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.803\n",
            "Training GNN 396 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.801\n",
            "Training GNN 397 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.802\n",
            "Training GNN 398 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.803\n",
            "Training GNN 399 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.806\n",
            "Training GNN 400 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.807\n",
            "Training GNN 401 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.807\n",
            "Training GNN 402 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.807\n",
            "Training GNN 403 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.806\n",
            "Training GNN 404 ; Val_Acc: 0.7719611885641788 ; Test_Acc: 0.805\n",
            "Training GNN 405 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.805\n",
            "Training GNN 406 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.806\n",
            "Training GNN 407 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.807\n",
            "Training GNN 408 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.81\n",
            "Training GNN 409 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.806\n",
            "Training GNN 410 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.799\n",
            "Training GNN 411 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.798\n",
            "Training GNN 412 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.799\n",
            "Training GNN 413 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.803\n",
            "Training GNN 414 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.808\n",
            "Training GNN 415 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.804\n",
            "Training GNN 416 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 417 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.806\n",
            "Training GNN 418 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.806\n",
            "Training GNN 419 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.807\n",
            "Training GNN 420 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.809\n",
            "Training GNN 421 ; Val_Acc: 0.7898675047937602 ; Test_Acc: 0.808\n",
            "Training GNN 422 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.807\n",
            "Training GNN 423 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.807\n",
            "Training GNN 424 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.807\n",
            "Training GNN 425 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.805\n",
            "Training GNN 426 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.807\n",
            "Training GNN 427 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.805\n",
            "Training GNN 428 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.802\n",
            "Training GNN 429 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.802\n",
            "Training GNN 430 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.801\n",
            "Training GNN 431 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.8\n",
            "Training GNN 432 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.804\n",
            "Training GNN 433 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.804\n",
            "Training GNN 434 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.804\n",
            "Training GNN 435 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.803\n",
            "Training GNN 436 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.801\n",
            "Training GNN 437 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.801\n",
            "Training GNN 438 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.804\n",
            "Training GNN 439 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.807\n",
            "Training GNN 440 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.804\n",
            "Training GNN 441 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.796\n",
            "Training GNN 442 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.792\n",
            "Training GNN 443 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.794\n",
            "Training GNN 444 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.797\n",
            "Training GNN 445 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.803\n",
            "Training GNN 446 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.808\n",
            "Training GNN 447 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.807\n",
            "Training GNN 448 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.803\n",
            "Training GNN 449 ; Val_Acc: 0.8016032064128257 ; Test_Acc: 0.801\n",
            "Training GNN 450 ; Val_Acc: 0.8016032064128257 ; Test_Acc: 0.799\n",
            "Training GNN 451 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.797\n",
            "Training GNN 452 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.798\n",
            "Training GNN 453 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.801\n",
            "Training GNN 454 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.801\n",
            "Training GNN 455 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.804\n",
            "Training GNN 456 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.802\n",
            "Training GNN 457 ; Val_Acc: 0.7600236444111242 ; Test_Acc: 0.799\n",
            "Training GNN 458 ; Val_Acc: 0.7615230460921845 ; Test_Acc: 0.8\n",
            "Training GNN 459 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.801\n",
            "Training GNN 460 ; Val_Acc: 0.7675350701402807 ; Test_Acc: 0.798\n",
            "Training GNN 461 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.801\n",
            "Training GNN 462 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.804\n",
            "Training GNN 463 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.799\n",
            "Training GNN 464 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.801\n",
            "Training GNN 465 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.796\n",
            "Training GNN 466 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.794\n",
            "Training GNN 467 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.798\n",
            "Training GNN 468 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.802\n",
            "Training GNN 469 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.804\n",
            "Training GNN 470 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.803\n",
            "Training GNN 471 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.809\n",
            "Training GNN 472 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.807\n",
            "Training GNN 473 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.806\n",
            "Training GNN 474 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.804\n",
            "Training GNN 475 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.808\n",
            "Training GNN 476 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.809\n",
            "Training GNN 477 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.807\n",
            "Training GNN 478 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.809\n",
            "Training GNN 479 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.808\n",
            "Training GNN 480 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.81\n",
            "Training GNN 481 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.808\n",
            "Training GNN 482 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.807\n",
            "Training GNN 483 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.806\n",
            "Training GNN 484 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 485 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 486 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.809\n",
            "Training GNN 487 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.809\n",
            "Training GNN 488 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.809\n",
            "Training GNN 489 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.809\n",
            "Training GNN 490 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.808\n",
            "Training GNN 491 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.81\n",
            "Training GNN 492 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.808\n",
            "Training GNN 493 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.807\n",
            "Training GNN 494 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.804\n",
            "Training GNN 495 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.805\n",
            "Training GNN 496 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.805\n",
            "Training GNN 497 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.809\n",
            "Training GNN 498 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.809\n",
            "Training GNN 499 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.807\n",
            "Training GNN 500 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.808\n",
            "Training GNN 501 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.807\n",
            "Training GNN 502 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.807\n",
            "Training GNN 503 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.809\n",
            "Training GNN 504 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.808\n",
            "Training GNN 505 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.806\n",
            "Training GNN 506 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.807\n",
            "Training GNN 507 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.806\n",
            "Training GNN 508 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.807\n",
            "Training GNN 509 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.806\n",
            "Training GNN 510 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.807\n",
            "Training GNN 511 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.808\n",
            "Training GNN 512 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.808\n",
            "Training GNN 513 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.807\n",
            "Training GNN 514 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.807\n",
            "Training GNN 515 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.805\n",
            "Training GNN 516 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.806\n",
            "Training GNN 517 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 518 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.808\n",
            "Training GNN 519 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.804\n",
            "Training GNN 520 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 521 ; Val_Acc: 0.7819091420250575 ; Test_Acc: 0.809\n",
            "Training GNN 522 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.807\n",
            "Training GNN 523 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 524 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.803\n",
            "Training GNN 525 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.802\n",
            "Training GNN 526 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.802\n",
            "Training GNN 527 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.797\n",
            "Training GNN 528 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.798\n",
            "Training GNN 529 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.798\n",
            "Training GNN 530 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.798\n",
            "Training GNN 531 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.806\n",
            "Training GNN 532 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.81\n",
            "Training GNN 533 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.807\n",
            "Training GNN 534 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.806\n",
            "Training GNN 535 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.807\n",
            "Training GNN 536 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.808\n",
            "Training GNN 537 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.809\n",
            "Training GNN 538 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.805\n",
            "Training GNN 539 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.802\n",
            "Training GNN 540 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.8\n",
            "Training GNN 541 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.802\n",
            "Training GNN 542 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.802\n",
            "Training GNN 543 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.804\n",
            "Training GNN 544 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.803\n",
            "Training GNN 545 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.802\n",
            "Training GNN 546 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.804\n",
            "Training GNN 547 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.806\n",
            "Training GNN 548 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.806\n",
            "Training GNN 549 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.807\n",
            "Training GNN 550 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.807\n",
            "Training GNN 551 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.804\n",
            "Training GNN 552 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.802\n",
            "Training GNN 553 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.803\n",
            "Training GNN 554 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.806\n",
            "Training GNN 555 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.806\n",
            "Training GNN 556 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.806\n",
            "Training GNN 557 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.804\n",
            "Training GNN 558 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.806\n",
            "Training GNN 559 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.801\n",
            "Training GNN 560 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.803\n",
            "Training GNN 561 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.803\n",
            "Training GNN 562 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.802\n",
            "Training GNN 563 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.801\n",
            "Training GNN 564 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.802\n",
            "Training GNN 565 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.801\n",
            "Training GNN 566 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.803\n",
            "Training GNN 567 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.803\n",
            "Training GNN 568 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.805\n",
            "Training GNN 569 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.805\n",
            "Training GNN 570 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.803\n",
            "Training GNN 571 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.803\n",
            "Training GNN 572 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.803\n",
            "Training GNN 573 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.804\n",
            "Training GNN 574 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.805\n",
            "Training GNN 575 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.8\n",
            "Training GNN 576 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.8\n",
            "Training GNN 577 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.8\n",
            "Training GNN 578 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.799\n",
            "Training GNN 579 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.801\n",
            "Training GNN 580 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.801\n",
            "Training GNN 581 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.8\n",
            "Training GNN 582 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.802\n",
            "Training GNN 583 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.803\n",
            "Training GNN 584 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.802\n",
            "Training GNN 585 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.803\n",
            "Training GNN 586 ; Val_Acc: 0.7878779141015845 ; Test_Acc: 0.802\n",
            "Training GNN 587 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.805\n",
            "Training GNN 588 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.8\n",
            "Training GNN 589 ; Val_Acc: 0.7898675047937602 ; Test_Acc: 0.801\n",
            "Training GNN 590 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.803\n",
            "Training GNN 591 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.803\n",
            "Training GNN 592 ; Val_Acc: 0.7878779141015845 ; Test_Acc: 0.806\n",
            "Training GNN 593 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.806\n",
            "Training GNN 594 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.807\n",
            "Training GNN 595 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.805\n",
            "Training GNN 596 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.805\n",
            "Training GNN 597 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.803\n",
            "Training GNN 598 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.806\n",
            "Training GNN 599 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.808\n",
            "Training GNN 600 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.81\n",
            "Training GNN 601 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.817\n",
            "Training GNN 602 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.812\n",
            "Training GNN 603 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.813\n",
            "Training GNN 604 ; Val_Acc: 0.7858883234094086 ; Test_Acc: 0.812\n",
            "Training GNN 605 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.8\n",
            "Training GNN 606 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.796\n",
            "Training GNN 607 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.792\n",
            "Training GNN 608 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.794\n",
            "Training GNN 609 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.799\n",
            "Training GNN 610 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.796\n",
            "Training GNN 611 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.799\n",
            "Training GNN 612 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.797\n",
            "Training GNN 613 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.796\n",
            "Training GNN 614 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.801\n",
            "Training GNN 615 ; Val_Acc: 0.7838987327172331 ; Test_Acc: 0.804\n",
            "Training GNN 616 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.802\n",
            "Training GNN 617 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.803\n",
            "Training GNN 618 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.807\n",
            "Training GNN 619 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.81\n",
            "Training GNN 620 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 621 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.811\n",
            "Training GNN 622 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.81\n",
            "Training GNN 623 ; Val_Acc: 0.803607214428858 ; Test_Acc: 0.811\n",
            "Training GNN 624 ; Val_Acc: 0.8016032064128257 ; Test_Acc: 0.81\n",
            "Training GNN 625 ; Val_Acc: 0.8016032064128257 ; Test_Acc: 0.811\n",
            "Training GNN 626 ; Val_Acc: 0.803607214428858 ; Test_Acc: 0.812\n",
            "Training GNN 627 ; Val_Acc: 0.803607214428858 ; Test_Acc: 0.812\n",
            "Training GNN 628 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.814\n",
            "Training GNN 629 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.813\n",
            "Training GNN 630 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 631 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.809\n",
            "Training GNN 632 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.804\n",
            "Training GNN 633 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.804\n",
            "Training GNN 634 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.806\n",
            "Training GNN 635 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.806\n",
            "Training GNN 636 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 637 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.804\n",
            "Training GNN 638 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.803\n",
            "Training GNN 639 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.807\n",
            "Training GNN 640 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.807\n",
            "Training GNN 641 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 642 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.81\n",
            "Training GNN 643 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.809\n",
            "Training GNN 644 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.809\n",
            "Training GNN 645 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.812\n",
            "Training GNN 646 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.814\n",
            "Training GNN 647 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.811\n",
            "Training GNN 648 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.811\n",
            "Training GNN 649 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.809\n",
            "Training GNN 650 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.806\n",
            "Training GNN 651 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.804\n",
            "Training GNN 652 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.806\n",
            "Training GNN 653 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.806\n",
            "Training GNN 654 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.806\n",
            "Training GNN 655 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 656 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 657 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.806\n",
            "Training GNN 658 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.805\n",
            "Training GNN 659 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.805\n",
            "Training GNN 660 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.809\n",
            "Training GNN 661 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.806\n",
            "Training GNN 662 ; Val_Acc: 0.7918570954859357 ; Test_Acc: 0.803\n",
            "Training GNN 663 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.805\n",
            "Training GNN 664 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.805\n",
            "Training GNN 665 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.807\n",
            "Training GNN 666 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.802\n",
            "Training GNN 667 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.797\n",
            "Training GNN 668 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.798\n",
            "Training GNN 669 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.794\n",
            "Training GNN 670 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.796\n",
            "Training GNN 671 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.797\n",
            "Training GNN 672 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.802\n",
            "Training GNN 673 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.803\n",
            "Training GNN 674 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.8\n",
            "Training GNN 675 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.803\n",
            "Training GNN 676 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.804\n",
            "Training GNN 677 ; Val_Acc: 0.7838987327172331 ; Test_Acc: 0.803\n",
            "Training GNN 678 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 679 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.813\n",
            "Training GNN 680 ; Val_Acc: 0.7699715978720029 ; Test_Acc: 0.811\n",
            "Training GNN 681 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.802\n",
            "Training GNN 682 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.801\n",
            "Training GNN 683 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.803\n",
            "Training GNN 684 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.804\n",
            "Training GNN 685 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.806\n",
            "Training GNN 686 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.807\n",
            "Training GNN 687 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.804\n",
            "Training GNN 688 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.799\n",
            "Training GNN 689 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.795\n",
            "Training GNN 690 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.796\n",
            "Training GNN 691 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.8\n",
            "Training GNN 692 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.807\n",
            "Training GNN 693 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.805\n",
            "Training GNN 694 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.805\n",
            "Training GNN 695 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.805\n",
            "Training GNN 696 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.809\n",
            "Training GNN 697 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.809\n",
            "Training GNN 698 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.81\n",
            "Training GNN 699 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.809\n",
            "Training GNN 700 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.81\n",
            "Training GNN 701 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.81\n",
            "Training GNN 702 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.812\n",
            "Training GNN 703 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.808\n",
            "Training GNN 704 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.811\n",
            "Training GNN 705 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.811\n",
            "Training GNN 706 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.811\n",
            "Training GNN 707 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.81\n",
            "Training GNN 708 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.804\n",
            "Training GNN 709 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.803\n",
            "Training GNN 710 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.805\n",
            "Training GNN 711 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.801\n",
            "Training GNN 712 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.805\n",
            "Training GNN 713 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.807\n",
            "Training GNN 714 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.803\n",
            "Training GNN 715 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.795\n",
            "Training GNN 716 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.795\n",
            "Training GNN 717 ; Val_Acc: 0.7655310621242483 ; Test_Acc: 0.794\n",
            "Training GNN 718 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.809\n",
            "Training GNN 719 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.814\n",
            "Training GNN 720 ; Val_Acc: 0.803607214428858 ; Test_Acc: 0.813\n",
            "Training GNN 721 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.813\n",
            "Training GNN 722 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.814\n",
            "Training GNN 723 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.807\n",
            "Training GNN 724 ; Val_Acc: 0.803607214428858 ; Test_Acc: 0.805\n",
            "Training GNN 725 ; Val_Acc: 0.8016032064128257 ; Test_Acc: 0.805\n",
            "Training GNN 726 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.812\n",
            "Training GNN 727 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.813\n",
            "Training GNN 728 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.802\n",
            "Training GNN 729 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.802\n",
            "Training GNN 730 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.798\n",
            "Training GNN 731 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.798\n",
            "Training GNN 732 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.805\n",
            "Training GNN 733 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.807\n",
            "Training GNN 734 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.812\n",
            "Training GNN 735 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.808\n",
            "Training GNN 736 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.807\n",
            "Training GNN 737 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.807\n",
            "Training GNN 738 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.809\n",
            "Training GNN 739 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.81\n",
            "Training GNN 740 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.806\n",
            "Training GNN 741 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.809\n",
            "Training GNN 742 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.809\n",
            "Training GNN 743 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.805\n",
            "Training GNN 744 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.802\n",
            "Training GNN 745 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.797\n",
            "Training GNN 746 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.8\n",
            "Training GNN 747 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.798\n",
            "Training GNN 748 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.799\n",
            "Training GNN 749 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.796\n",
            "Training GNN 750 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.795\n",
            "Training GNN 751 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.799\n",
            "Training GNN 752 ; Val_Acc: 0.7898675047937602 ; Test_Acc: 0.802\n",
            "Training GNN 753 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.804\n",
            "Training GNN 754 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.807\n",
            "Training GNN 755 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.81\n",
            "Training GNN 756 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.813\n",
            "Training GNN 757 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.81\n",
            "Training GNN 758 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.809\n",
            "Training GNN 759 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 760 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.807\n",
            "Training GNN 761 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.804\n",
            "Training GNN 762 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 763 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.803\n",
            "Training GNN 764 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.801\n",
            "Training GNN 765 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.804\n",
            "Training GNN 766 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.802\n",
            "Training GNN 767 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.805\n",
            "Training GNN 768 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.807\n",
            "Training GNN 769 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.808\n",
            "Training GNN 770 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.806\n",
            "Training GNN 771 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 772 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 773 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.809\n",
            "Training GNN 774 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.809\n",
            "Training GNN 775 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.812\n",
            "Training GNN 776 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.812\n",
            "Training GNN 777 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.81\n",
            "Training GNN 778 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.807\n",
            "Training GNN 779 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 780 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.808\n",
            "Training GNN 781 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.802\n",
            "Training GNN 782 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.799\n",
            "Training GNN 783 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.799\n",
            "Training GNN 784 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.801\n",
            "Training GNN 785 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.797\n",
            "Training GNN 786 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.796\n",
            "Training GNN 787 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.799\n",
            "Training GNN 788 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.799\n",
            "Training GNN 789 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.801\n",
            "Training GNN 790 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.803\n",
            "Training GNN 791 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.808\n",
            "Training GNN 792 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.806\n",
            "Training GNN 793 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.809\n",
            "Training GNN 794 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.809\n",
            "Training GNN 795 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.806\n",
            "Training GNN 796 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.806\n",
            "Training GNN 797 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.805\n",
            "Training GNN 798 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.806\n",
            "Training GNN 799 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.805\n",
            "Training GNN 800 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.803\n",
            "Training GNN 801 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.805\n",
            "Training GNN 802 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.804\n",
            "Training GNN 803 ; Val_Acc: 0.7719611885641788 ; Test_Acc: 0.802\n",
            "Training GNN 804 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.801\n",
            "Training GNN 805 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.804\n",
            "Training GNN 806 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.806\n",
            "Training GNN 807 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.804\n",
            "Training GNN 808 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.803\n",
            "Training GNN 809 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.802\n",
            "Training GNN 810 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.801\n",
            "Training GNN 811 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.805\n",
            "Training GNN 812 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.804\n",
            "Training GNN 813 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.802\n",
            "Training GNN 814 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.801\n",
            "Training GNN 815 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.803\n",
            "Training GNN 816 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.804\n",
            "Training GNN 817 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 818 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.803\n",
            "Training GNN 819 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.805\n",
            "Training GNN 820 ; Val_Acc: 0.7918570954859357 ; Test_Acc: 0.809\n",
            "Training GNN 821 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.81\n",
            "Training GNN 822 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.81\n",
            "Training GNN 823 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.808\n",
            "Training GNN 824 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.808\n",
            "Training GNN 825 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.807\n",
            "Training GNN 826 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.809\n",
            "Training GNN 827 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.804\n",
            "Training GNN 828 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 829 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.803\n",
            "Training GNN 830 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.801\n",
            "Training GNN 831 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.8\n",
            "Training GNN 832 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.803\n",
            "Training GNN 833 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.798\n",
            "Training GNN 834 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.795\n",
            "Training GNN 835 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.798\n",
            "Training GNN 836 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.802\n",
            "Training GNN 837 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.8\n",
            "Training GNN 838 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.799\n",
            "Training GNN 839 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.798\n",
            "Training GNN 840 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.801\n",
            "Training GNN 841 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.809\n",
            "Training GNN 842 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.812\n",
            "Training GNN 843 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.815\n",
            "Training GNN 844 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.815\n",
            "Training GNN 845 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.817\n",
            "Training GNN 846 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.815\n",
            "Training GNN 847 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.813\n",
            "Training GNN 848 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.81\n",
            "Training GNN 849 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.809\n",
            "Training GNN 850 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.802\n",
            "Training GNN 851 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.8\n",
            "Training GNN 852 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.797\n",
            "Training GNN 853 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.798\n",
            "Training GNN 854 ; Val_Acc: 0.7695390781563127 ; Test_Acc: 0.792\n",
            "Training GNN 855 ; Val_Acc: 0.7739507792563544 ; Test_Acc: 0.79\n",
            "Training GNN 856 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.797\n",
            "Training GNN 857 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.803\n",
            "Training GNN 858 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.801\n",
            "Training GNN 859 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.803\n",
            "Training GNN 860 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.807\n",
            "Training GNN 861 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.806\n",
            "Training GNN 862 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.807\n",
            "Training GNN 863 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.808\n",
            "Training GNN 864 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.804\n",
            "Training GNN 865 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.808\n",
            "Training GNN 866 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.81\n",
            "Training GNN 867 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.809\n",
            "Training GNN 868 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.806\n",
            "Training GNN 869 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.804\n",
            "Training GNN 870 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.802\n",
            "Training GNN 871 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.8\n",
            "Training GNN 872 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.797\n",
            "Training GNN 873 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.794\n",
            "Training GNN 874 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.793\n",
            "Training GNN 875 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.793\n",
            "Training GNN 876 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.8\n",
            "Training GNN 877 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.803\n",
            "Training GNN 878 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.805\n",
            "Training GNN 879 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.808\n",
            "Training GNN 880 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.808\n",
            "Training GNN 881 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.807\n",
            "Training GNN 882 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.806\n",
            "Training GNN 883 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.805\n",
            "Training GNN 884 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 885 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 886 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.806\n",
            "Training GNN 887 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.807\n",
            "Training GNN 888 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.81\n",
            "Training GNN 889 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.808\n",
            "Training GNN 890 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.806\n",
            "Training GNN 891 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.806\n",
            "Training GNN 892 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.808\n",
            "Training GNN 893 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.808\n",
            "Training GNN 894 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.807\n",
            "Training GNN 895 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.805\n",
            "Training GNN 896 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.804\n",
            "Training GNN 897 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.801\n",
            "Training GNN 898 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.8\n",
            "Training GNN 899 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.799\n",
            "Training GNN 900 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.799\n",
            "Training GNN 901 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.802\n",
            "Training GNN 902 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.801\n",
            "Training GNN 903 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.802\n",
            "Training GNN 904 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.802\n",
            "Training GNN 905 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.8\n",
            "Training GNN 906 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.799\n",
            "Training GNN 907 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.8\n",
            "Training GNN 908 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.803\n",
            "Training GNN 909 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 910 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.806\n",
            "Training GNN 911 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.806\n",
            "Training GNN 912 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.805\n",
            "Training GNN 913 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.804\n",
            "Training GNN 914 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.806\n",
            "Training GNN 915 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.804\n",
            "Training GNN 916 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.805\n",
            "Training GNN 917 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.805\n",
            "Training GNN 918 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.804\n",
            "Training GNN 919 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.8\n",
            "Training GNN 920 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.8\n",
            "Training GNN 921 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.8\n",
            "Training GNN 922 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.804\n",
            "Training GNN 923 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.806\n",
            "Training GNN 924 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.803\n",
            "Training GNN 925 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.804\n",
            "Training GNN 926 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.8\n",
            "Training GNN 927 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.8\n",
            "Training GNN 928 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.797\n",
            "Training GNN 929 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.797\n",
            "Training GNN 930 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.8\n",
            "Training GNN 931 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.798\n",
            "Training GNN 932 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.797\n",
            "Training GNN 933 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.797\n",
            "Training GNN 934 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.798\n",
            "Training GNN 935 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.796\n",
            "Training GNN 936 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.794\n",
            "Training GNN 937 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.794\n",
            "Training GNN 938 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.798\n",
            "Training GNN 939 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.799\n",
            "Training GNN 940 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.802\n",
            "Training GNN 941 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.8\n",
            "Training GNN 942 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.803\n",
            "Training GNN 943 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.802\n",
            "Training GNN 944 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.803\n",
            "Training GNN 945 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.8\n",
            "Training GNN 946 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.8\n",
            "Training GNN 947 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.8\n",
            "Training GNN 948 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.796\n",
            "Training GNN 949 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.8\n",
            "Training GNN 950 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.802\n",
            "Training GNN 951 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.804\n",
            "Training GNN 952 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.807\n",
            "Training GNN 953 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.803\n",
            "Training GNN 954 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.807\n",
            "Training GNN 955 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.81\n",
            "Training GNN 956 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.81\n",
            "Training GNN 957 ; Val_Acc: 0.8056112224448897 ; Test_Acc: 0.811\n",
            "Training GNN 958 ; Val_Acc: 0.803607214428858 ; Test_Acc: 0.807\n",
            "Training GNN 959 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.807\n",
            "Training GNN 960 ; Val_Acc: 0.7995991983967937 ; Test_Acc: 0.808\n",
            "Training GNN 961 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.813\n",
            "Training GNN 962 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.812\n",
            "Training GNN 963 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.815\n",
            "Training GNN 964 ; Val_Acc: 0.7835671342685372 ; Test_Acc: 0.813\n",
            "Training GNN 965 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.814\n",
            "Training GNN 966 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.813\n",
            "Training GNN 967 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.809\n",
            "Training GNN 968 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.807\n",
            "Training GNN 969 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.803\n",
            "Training GNN 970 ; Val_Acc: 0.7875751503006013 ; Test_Acc: 0.803\n",
            "Training GNN 971 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.799\n",
            "Training GNN 972 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.796\n",
            "Training GNN 973 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.794\n",
            "Training GNN 974 ; Val_Acc: 0.7918570954859357 ; Test_Acc: 0.801\n",
            "Training GNN 975 ; Val_Acc: 0.7955911823647295 ; Test_Acc: 0.809\n",
            "Training GNN 976 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.813\n",
            "Training GNN 977 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.817\n",
            "Training GNN 978 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.814\n",
            "Training GNN 979 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.812\n",
            "Training GNN 980 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.814\n",
            "Training GNN 981 ; Val_Acc: 0.7735470941883766 ; Test_Acc: 0.816\n",
            "Training GNN 982 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.813\n",
            "Training GNN 983 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.808\n",
            "Training GNN 984 ; Val_Acc: 0.7755511022044087 ; Test_Acc: 0.804\n",
            "Training GNN 985 ; Val_Acc: 0.7715430861723447 ; Test_Acc: 0.802\n",
            "Training GNN 986 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.797\n",
            "Training GNN 987 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.8\n",
            "Training GNN 988 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.799\n",
            "Training GNN 989 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.797\n",
            "Training GNN 990 ; Val_Acc: 0.777555110220441 ; Test_Acc: 0.798\n",
            "Training GNN 991 ; Val_Acc: 0.7759403699485301 ; Test_Acc: 0.796\n",
            "Training GNN 992 ; Val_Acc: 0.7935871743486975 ; Test_Acc: 0.797\n",
            "Training GNN 993 ; Val_Acc: 0.7975951903807614 ; Test_Acc: 0.802\n",
            "Training GNN 994 ; Val_Acc: 0.7915831663326652 ; Test_Acc: 0.809\n",
            "Training GNN 995 ; Val_Acc: 0.7895791583166333 ; Test_Acc: 0.811\n",
            "Training GNN 996 ; Val_Acc: 0.7855711422845691 ; Test_Acc: 0.813\n",
            "Training GNN 997 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.811\n",
            "Training GNN 998 ; Val_Acc: 0.7815631262525049 ; Test_Acc: 0.81\n",
            "Training GNN 999 ; Val_Acc: 0.7795591182364728 ; Test_Acc: 0.809\n"
          ]
        }
      ]
    }
  ]
}